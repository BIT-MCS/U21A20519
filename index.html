<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8"/>
    <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
    <title>
      边缘环境群体智能感知与能力增强关键技术结项成果展示
    </title>
    <script src="https://cdn.tailwindcss.com">
  </script>
    <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@300;400;500;700&amp;display=swap" rel="stylesheet"/>
    <style>
   body { font-family: 'Noto Sans SC', sans-serif; }
        .bit-green { color: #006439; }
        .bg-bit-green { background-color: #006439; }
        .section-title { position: relative; display: inline-block; margin-bottom: 2rem; }
        .section-title::after { content: ''; display: block; width: 60px; height: 4px; background: #006439; margin-top: 8px; }
        .img-placeholder { background-color: #e2e8f0; display: flex; align-items: center; justify-content: center; color: #64748b; font-weight: bold; border: 2px dashed #cbd5e1; }
        .timeline-item { position: relative; padding-left: 1.5rem; border-left: 2px solid #e5e7eb; padding-bottom: 1.5rem; }
        .timeline-item::before { content: ''; position: absolute; left: -0.4rem; top: 0.2rem; width: 0.8rem; height: 0.8rem; background: #006439; border-radius: 50%; }

        /* -------- Visual readability improvements -------- */
        html { scroll-behavior: smooth; }
        body { -webkit-font-smoothing: antialiased; text-rendering: optimizeLegibility; font-size: 16px; line-height: 1.75; }
        @media (min-width: 768px) { body { font-size: 16.5px; } }
        @media (min-width: 1024px) { body { font-size: 17px; } }
        p, li { line-height: 1.75; }
        .text-bit-green { color: #006439; }
        .border-bit-green { border-color: #006439; }
        .hover\:text-bit-green:hover { color: #006439; }

        /* -------- Custom Scrollbar for Lists -------- */
        .custom-scrollbar::-webkit-scrollbar {
            width: 6px;
        }
        .custom-scrollbar::-webkit-scrollbar-track {
            background: #f1f1f1;
            border-radius: 4px;
        }
        .custom-scrollbar::-webkit-scrollbar-thumb {
            background: #cbd5e1;
            border-radius: 4px;
        }
        .custom-scrollbar::-webkit-scrollbar-thumb:hover {
            background: #94a3b8;
        }

        /* Sticky headers within the paper list */
        .sticky-venue-header {
            position: sticky;
            top: 0;
            background-color: #f9fafb; /* match bg-gray-50/white context */
            backdrop-filter: blur(8px);
            background-color: rgba(255, 255, 255, 0.95);
            z-index: 10;
            padding-top: 0.5rem;
            padding-bottom: 0.5rem;
            border-bottom: 1px solid #e5e7eb;
        }

        /* Long text wrapping */
        .break-words { overflow-wrap: anywhere; word-break: break-word; }
  
        /* -------- 
        /* -------- Reference-style ordered list: [1] [2] ... -------- */
        ol.ref-list { list-style: none; counter-reset: refitem; padding-left: 0; margin: 0; }
        ol.ref-list > li { position: relative; padding-left: 2.2rem; }
        ol.ref-list > li::before {
          counter-increment: refitem;
          content: "[" counter(refitem) "]";
          position: absolute;
          left: 0;
          top: 0;
          width: 1.8rem;
          text-align: right;
          color: #9ca3af;
          font-weight: 600;
        }
        /*------- Figure reference superscripts -------- */
        .fig-ref-sup { font-size: 0.75em; vertical-align: super; color: #006439; margin-left: 0.25rem; }
        .icon-btn { display: inline-flex; align-items: center; justify-content: center; width: 42px; height: 42px; border-radius: 9999px; border: 1px solid #e5e7eb; background: rgba(255,255,255,0.9); transition: transform 120ms ease, background 120ms ease; }
        .icon-btn-lg { width: 52px; height: 52px; }
        @media (min-width: 768px) { .icon-btn-lg { width: 56px; height: 56px; } }
        .icon-btn:hover { background: rgba(249,250,251,1); transform: translateY(-1px); }
        .icon-btn:active { transform: translateY(0px); }
        .icon-btn:focus { outline: none; box-shadow: 0 0 0 3px rgba(0,100,57,0.15); border-color: #006439; }
</style>
    <link href="site_assets/BIT.png" id="site-favicon" rel="icon"/>
    <script id="site-asset-config">
   window.SITE_ASSETS = window.SITE_ASSETS || {};
window.SITE_ASSETS.favicon = window.SITE_ASSETS.favicon || 'site_assets/BIT.png';
window.PROJECT_DEMO_VIDEO_URL = window.PROJECT_DEMO_VIDEO_URL || 'site_assets/videos/display_video.mp4';

// ======================== 视频展示配置（推荐：GitHub Releases 托管）========================
// 说明：GitHub 仓库本体禁止推送 >100 MiB 的单文件；500MB 视频不适合放在仓库里。
// 建议将视频作为 Release asset 上传（单文件 <2 GiB），然后把下方直链填进去。
// 直链格式：https://github.com/<org>/<repo>/releases/download/<tag>/<file>.mp4
// 例子：   https://github.com/BIT-MCS/Hangzhou/releases/download/v1/demo.mp4
window.PROJECT_DEMO_VIDEO_DIRECT_URL = 'https://github.com/BIT-MCS/Hangzhou/releases/download/v1/1080.mp4 ';

// 若视频无法播放，可提供一个“打开原视频/下载”的兜底链接（可填同一个 Release 直链或公开视频页）
window.PROJECT_DEMO_VIDEO_FALLBACK_OPEN = 'https://github.com/BIT-MCS/Hangzhou/releases/download/v1/1080.mp4 ';

// ======================== 项目概况“总体框架图”尺寸配置 =========================
// 说明：以下两个参数仅影响“项目概况”部分的“图片+边框整体”尺寸，便于你在不改动布局的情况下快速微调。
// - MAX_WIDTH_REM：整体最大宽度（单位 rem）。示例：80 = 80rem（约1280px，取决于根字体大小）
// - MAX_HEIGHT_PX：图片最大高度（单位 px）。
window.PROJECT_OVERVIEW_FIGURE_MAX_WIDTH_REM = window.PROJECT_OVERVIEW_FIGURE_MAX_WIDTH_REM || 84;
window.PROJECT_OVERVIEW_FIGURE_MAX_HEIGHT_PX = window.PROJECT_OVERVIEW_FIGURE_MAX_HEIGHT_PX || 560;
// ============================================================================

// =========================================================================================
// 说明：该链接使用 B 站移动端嵌入播放器（界面更简洁，通常不会触发点击跳转）。
  // 如需改用 PC 端播放器，可使用：https://player.bilibili.com/player.html?aid=115836425603516&bvid=BV1diiEBTE6D&cid=35184971540&p=1&autoplay=0&danmaku=0

window.SITE_ASSETS.achievementFallback = window.SITE_ASSETS.achievementFallback || 'site_assets/images/overview.png';
window.SITE_ASSETS.achievementImages = Object.assign({}, {
  "res01_method": "site_assets/images/res01_method.png",
  "res01_effect": "site_assets/images/res01_effect.png",
  "res02_method": "site_assets/images/res02_method.png",
  "res02_effect": "site_assets/images/res02_effect.png",
  "res03_method": "site_assets/images/res03_method.png",
  "res03_effect": "site_assets/images/res03_effect.png",
  "res04_method": "site_assets/images/res04_method.png",
  "res04_effect": "site_assets/images/res04_effect.png",
  "res05_method": "site_assets/images/res05_method.png",
  "res05_effect": "site_assets/images/res05_effect.png",
  "res06_method": "site_assets/images/res06_method.png",
  "res06_effect": "site_assets/images/res06_effect.png",
  "res07_method": "site_assets/images/res07_method.png",
  "res07_effect": "site_assets/images/res07_effect.png",
  "res08_method": "site_assets/images/res08_method.png",
  "res08_effect": "site_assets/images/res08_effect.png"
}, window.SITE_ASSETS.achievementImages || {});
  </script>
  </head>
  <body class="bg-gray-50 text-gray-800">
    <nav class="bg-white shadow-md fixed w-full z-50">
      <div class="container mx-auto px-6 h-20 flex justify-between items-center">
        <div class="flex items-center space-x-3">
          <div>
            <img class="w-14 h-14 rounded-full flex items-center justify-center text-white font-bold" src="site_assets/BIT.png" alt="Logo 1"/>
          </div>
          <div>
            <img class="w-14 h-14 rounded-full flex items-center justify-center text-white font-bold" src="site_assets/ZJU.png" alt="Logo 2"/>
          </div>
          <div>
            <img class="w-14 h-14 rounded-full flex items-center justify-center text-white font-bold" src="site_assets/SJTU.png" alt="Logo 3"/>
          </div>
        </div>
        <div class="hidden md:flex space-x-8 text-gray-600 font-medium">
          <a class="hover:text-bit-green transition" href="#info">
            项目概况
          </a>
          <a class="hover:text-bit-green transition" href="#achievements">学术贡献</a>
          <a class="hover:text-bit-green transition" href="#applications">
            应用演示
          </a>
          <a class="hover:text-bit-green transition" href="#exchange">
            学术交流
          </a>
          <a class="hover:text-bit-green transition" href="#talent">
            人才培养
          </a>
          <a class="hover:text-bit-green transition" href="#papers">
            学术成果
          </a>
        </div>
      </div>
    </nav>
    <header class="relative h-[500px] flex items-center justify-center bg-gray-900 text-white pt-20 overflow-hidden">
      <div class="absolute inset-0 bg-gradient-to-r from-green-900 to-black opacity-80 z-10">
      </div>
      <!-- Header background: three gate images (replace the src paths with your school gate photos) -->
      <!-- NOTE: Use flex + 1px overlap to eliminate hairline seams on some browsers/zoom levels -->
      <div class="absolute inset-0 z-0 flex bg-gray-900">
        <img alt="校门 1（可替换）" class="block w-1/3 h-full object-cover" src="site_assets/images/gate_3.png"/>
        <img alt="校门 2（可替换）" class="block w-1/3 h-full object-cover -ml-px" src="site_assets/images/gate_2.png"/>
        <img alt="校门 3（可替换）" class="block w-1/3 h-full object-cover -ml-px" src="site_assets/images/gate_1.png"/>
      </div>
      <div class="relative z-20 text-center container px-6">
        <span class="bg-bit-green px-3 py-1 text-sm rounded uppercase tracking-wider mb-4 inline-block">
          国家自然科学基金｜区域创新发展联合基金｜重点支持项目
        </span>
        <h1 class="text-4xl md:text-5xl font-bold mb-6 leading-tight">
          边缘环境群体智能感知与能力增强关键技术
        </h1>
        <p class="text-base text-gray-300 max-w-3xl mx-auto mb-2">
          Key Technologies for Intelligent Mobile Crowdsensing and Capability Enhancement on Edge
        </p>
        <div class="mt-4 max-w-5xl mx-auto text-gray-300">
          <div class="flex flex-col md:flex-row md:items-center md:justify-center gap-2 md:gap-4 text-base md:text-lg leading-relaxed">
            <span class="inline-flex items-center justify-center px-3 py-1 rounded-full bg-white/5 border border-white/10">
              牵头单位：北京理工大学
            </span>
            <span class="hidden md:inline text-gray-500">
              |
            </span>
            <span class="inline-flex items-center justify-center px-3 py-1 rounded-full bg-white/5 border border-white/10">
              参与单位：浙江大学、上海交通大学
            </span>
            <span class="hidden md:inline text-gray-500">
              |
            </span>
            <span class="inline-flex items-center justify-center px-3 py-1 rounded-full bg-white/5 border border-white/10">
              项目编号：U21A20519
            </span>
          </div>
        </div>
      </div>
    </header>
    
    <section class="py-20 bg-white" id="info">
      <div class="container mx-auto px-6">
        <h2 class="text-4xl font-bold text-gray-900 mb-2 section-title">01 项目概况</h2>
        <div class="mt-2">
<div class="inline-flex flex-wrap items-center gap-x-2 gap-y-1 rounded-full bg-gray-50 border border-gray-200 px-4 py-2">
<span class="text-sm text-gray-600">项目周期</span>
<span class="text-sm font-semibold text-gray-900">2022年01月01日 - 2025年12月31日</span>
</div>
</div>

        <div class="mt-10 flex flex-col gap-10">
          <div class="max-w-5xl mx-auto">
<p class="mb-4">
            本项目紧扣浙江省提升数字治理能力及反恐防暴应急处置的核心需求，聚焦复杂边缘环境中的“移动群体感知”与能力增强关键课题，成功突破了群体部署难、数据感知繁、计算能力弱三大技术瓶颈，解决了公共安全事件应急处置中跨场景适配、资源协同调度、复杂数据高效处理等核心问题。
            </p>
<p class="mb-4">
            本网站为国家自然科学基金区域创新发展联合基金重点支持项目“边缘环境群体智能感知与能力增强关键技术”（项目编号：U21A20519）的结项成果展示平台。项目围绕<strong>“移动群体部署—移动群体感知—移动群体计算”</strong>主线，形成4大研究内容与8项关键技术创新突破，构建了覆盖传感器研制、算法建模到系统验证的完整技术体系。网站集成典型示范场景“杭州世纪中心异常包裹应急处置仿真”，直观展示人机协同移动群体感知与边缘智能在反恐防暴及公共安全事件处置中的全流程实证效果，并系统汇总项目论文、专利与软件著作权等学术与知识产权产出，为成果对外交流与推广提供便捷渠道。项目执行期间，累计发表论文47篇（期刊论文20篇、会议论文27篇），其中包括TPAMI、TIP、TKDE等顶级期刊论文以及INFOCOM、AAAI、CVPR、MM等CCF-A类高水平会议论文20篇；申请/授权国家发明专利15项。
            </p>
<p>
            项目相关技术研发形成的应急处置系统，严格遵循多项公共安全领域国家标准，为省级应急指挥平台技术支撑、市县级应急预案推演及跨部门救援协同提供关键技术支撑，有效提升省—市两级应急协同能力，为浙江全域应急响应智能化建设及反恐防暴工作提供坚实技术保障。
            </p>
</div>


          <div id="projectOverviewFigureCard" class="bg-white p-4 md:p-6 rounded-xl border border-gray-200 shadow-sm w-auto mx-auto">
            <img alt="项目总图" id="projectOverviewFigureImg" class="w-auto h-auto mx-auto object-contain rounded-md border border-dashed border-gray-300 bg-white" data-asset="project_overview" onerror="this.style.display='none'; this.insertAdjacentHTML('afterend','&lt;div class=&quot;w-full rounded-md border border-dashed border-gray-300 bg-gray-50 text-gray-500 text-sm flex items-center justify-center py-16&quot;&gt;此处放置项目总图（请替换图片资源）&lt;/div&gt;');" src="site_assets/images/overview.png" style="max-height: 560px;">
            <p class="mt-3 text-center text-sm text-gray-500">图1：项目总体框架图</p>
          </div>

        </div>
      </div>
    </section>
    <section class="py-20 bg-gray-100" id="achievements">
      <div class="container mx-auto px-6">
        <h2 class="text-3xl font-bold text-gray-900 section-title">
          02 重要学术贡献
        </h2>
        <div class="space-y-16">
          <div class="bg-white/0">
            <div class="mb-5">
              <h3 class="text-xl font-bold text-gray-900">
                学术贡献一：大规模移动人机群体部署技术
              </h3>
              <p class="text-base text-gray-600 mt-2 leading-relaxed">提出了面向群体高效部署的关键方法，聚焦于人机互补的优选机制与复杂约束下的协同轨迹规划，并在典型城市级网格化应急部署场景中完成验证，体现出在覆盖收益、部署效率与可执行性方面的综合优势。</p>
            </div>
            <div class="space-y-12">
              <div class="bg-white rounded-xl shadow-lg overflow-hidden border border-gray-200">
                <div class="p-6 border-b border-gray-100">
                  <div class="flex items-center mb-2">
                    <span class="bg-bit-green text-white text-xs font-bold px-2 py-1 rounded mr-3">
                      成果 01
                    </span>
                    <h3 class="text-xl font-bold text-gray-800">
                      互补增强的最小经验熵鲁棒人机优选
                    </h3>
                  </div>
                  <p class="text-gray-600 text-base leading-relaxed mt-3">提出了经验熵驱动的迭代趋优人群选择与部署方法，引入演员–评论家网络结构与迭代趋优训练算法，理论上证明了该非凸优化过程在样本数和迭代次数增加时近似收敛到局部最优解，在系统感知收益和经验熵指标上分别较现有最优方法提升 10.2% 和 11.9%；提出了长期目标导向的分布鲁棒机群选择方法，构建同时考虑环境出现概率、感知需求变化和平台偏好的鲁棒优化指标，实现了在不同环境分布和偏好条件下的鲁棒协同决策，在平均感知收益方面较现有最优方法提升 8%–14%。</p>
                </div>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-0">
                  <div class="p-4 bg-gray-50 border-r border-gray-100">
                    <img alt="成果01 方法示意" class="h-64 w-full object-contain bg-white rounded" data-asset="res01_method" src="site_assets/images/placeholder.png"/>
                    <p class="text-center text-sm text-gray-500 mt-2">
                      图2-1：迭代趋优人群选择与部署策略框架 <sup class="fig-ref-sup">[1]</sup>
                    </p>
                  </div>
                  <div class="p-4 bg-gray-50">
                    <img alt="成果01 效果示意" class="h-64 w-full object-contain bg-white rounded" data-asset="res01_effect" src="site_assets/images/placeholder.png"/>
                    <p class="text-center text-sm text-gray-500 mt-2">
                      图2-2：分布式鲁棒机群选择框架 <sup class="fig-ref-sup">[5]</sup>
                    </p>
                  </div>
                </div>
                <div class="p-6 bg-white border-t border-gray-100">
                  <h4 class="text-sm font-bold text-gray-900 mb-3">
                    代表性学术成果
                  </h4>
                  <ul class="text-sm text-gray-700 space-y-4 leading-relaxed">
                    <li>
                      <ol class="mt-2 ref-list pl-0 space-y-2">
                        <li class="break-words"><strong class="font-semibold text-gray-900">(CCF-A)</strong> Jiahui Sun; Haiming Jin; Zhaoxing Yang; Lu Su; Xinbing Wang; Optimizing Long-Term Efficiency and Fairness in Ride-Hailing via Joint Order Dispatching and Driver Repositioning, ACM SIGKDD 2022, Washington, DC, USA, 2022-8-14至2022-8-18. 第一标注 </li>
                        <li class="break-words"><strong class="font-semibold text-gray-900">(CCF-A)</strong> Guiyun Fan; Haiming Jin; Yiran Zhao; Yiwen Song; Xiaoying Gan; Jiaxin Ding; Lu Su; Xinbing Wang; Joint Order Dispatch and Charging for Electric Self-Driving Taxi Systems, IEEE INFOCOM 2022, Virtual Conference, 2022-5-2至2022-5-5. EI. 第一标注</li>
                        <li class="break-words"><strong class="font-semibold text-gray-900">(CCF-A)</strong> Haoyi You; Beichen Yu; Haiming Jin; Zhaoxing Yang; Jiahui Sun; User-Oriented Robust Reinforcement Learning, AAAI 2023, Washington DC, USA, 2023-2-7至2023-2-14. 第一标注</li>
                        <li class="break-words"><strong class="font-semibold text-gray-900">(CCF-A)</strong> Zhaoxing Yang; Haiming Jin; Rong Ding; Haoyi You; Guiyun Fan; Xinbing Wang; Chenghu Zhou; DeCOM: Decomposed Policy for Constrained Cooperative Multi-Agent Reinforcement Learning, AAAI 2023, Washington DC, USA, 2023-2-7至2023-2-14. EI. 第一标注</li>
                        <li class="break-words"><strong class="font-semibold text-gray-900">(CCF-A)</strong> Jiahui Sun; Haiming Jin; Rong Ding; Guiyun Fan; Yifei Wei; Lu Su; Multi-Objective Order Dispatch for Urban Crowd Sensing with For-Hire Vehicles, IEEE INFOCOM 2023, New York City, NY, USA, 2023-5-17至2023-5-20. EI. 第一标注 </li>
                      </ol>
                    </li>
                  </ul>
                </div>
              </div>
              <div class="bg-white rounded-xl shadow-lg overflow-hidden border border-gray-200">
                <div class="p-6 border-b border-gray-100">
                  <div class="flex items-center mb-2">
                    <span class="bg-bit-green text-white text-xs font-bold px-2 py-1 rounded mr-3">
                      成果 02
                    </span>
                    <h3 class="text-xl font-bold text-gray-800">
                      智能协同的分布式动态群体轨迹规划
                    </h3>
                  </div>
                  <p class="text-gray-600 text-base leading-relaxed mt-3">提出了多任务约束多智能体强化学习群体轨迹规划方法，以长期群体感知效益最大化为目标，同时显式引入系统充电成本约束；采用原始–对偶优化机制在策略学习过程中动态调节充电约束权重，从而在满足系统长期能量预算约束的同时提升多任务覆盖效率；所提出方法在严格满足充电成本约束，在长期感知效益指标上相比多种对比策略取得了约 12%–25% 的提升；在多任务并存与任务切换场景中，未出现明显的预算违背或覆盖退化现象，验证了该方法在复杂动态环境下进行大规模移动群体部署的有效性与鲁棒性。</p>
                </div>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-0">
                  <div class="p-4 bg-gray-50 border-r border-gray-100">
                    <img alt="成果02 方法示意" class="h-64 w-full object-contain bg-white rounded" data-asset="res02_method" src="site_assets/images/placeholder.png"/>
                    <p class="text-center text-sm text-gray-500 mt-2">
                      图2-3：多任务约束多智能体强化学习群体轨迹规划策略框架 <sup class="fig-ref-sup">[2]</sup>
                    </p>
                  </div>
                  <div class="p-4 bg-gray-50">
                    <img alt="成果02 效果示意" class="h-64 w-full object-contain bg-white rounded" data-asset="res02_effect" src="site_assets/images/placeholder.png"/>
                    <p class="text-center text-sm text-gray-500 mt-2">
                      图2-4：不同预算下策略训练收敛曲线对比图 <sup class="fig-ref-sup">[2]</sup>
                    </p>
                  </div>
                </div>
                <div class="p-6 bg-white border-t border-gray-100">
                  <h4 class="text-sm font-bold text-gray-900 mb-3">
                    代表性学术成果
                  </h4>
                  <ul class="text-sm text-gray-700 space-y-4 leading-relaxed">
                    <li>
                      <ol class="mt-2 ref-list pl-0 space-y-2">
                        <li class="break-words"><strong class="font-semibold text-gray-900">(CCF-A)</strong> Jiahui Sun; Haiming Jin; Zhaoxing Yang; Lu Su; Optimizing Long-Term Efficiency and Fairness in Ride-Hailing under Budget Constraint via Joint Order Dispatching and Driver Repositioning, IEEE Transactions on Knowledge and Data Engineering, 2024, 36(7)：1-14. SCIE. 第一标注</li>
                        <li class="break-words">Jiahui Sun; Guiyun Fan; Haiming Jin; Yiwen Song; Tianyuan Liu; Chenhao Ying; Yuan Luo; Jie Li; Multi-Task-Oriented UAV Crowd Sensing with Charging Budget Constraint, ACM MOBIHOC 2024, Athens, Greece, 2024-10-14至2024-10-17. EI. 第一标注</li>
                        <li class="break-words"><strong class="font-semibold text-gray-900">(CCF-A)</strong> Zhangxing Yang; Haiming Jin; Guiyun Fan; Min Lu; Yiran Liu; Xinlang Yue; Hao Pan; Zhe Xu; Guobin Wu;Qun Li; Xiaotong Wang; Jiecheng Guo; Rethinking Order Dispatching in Online Ride-Hailing Platforms, ACM SIGKDD 2024, Barcelona, Spain, 2024-8-25至2024-8-29. EI. 第一标注</li>
                        <li class="break-words"><strong class="font-semibold text-gray-900">(CCF-A)</strong> Guiyun Fan; Rong Ding; Xiaocheng Wang; Yichen Zhu; Haiming Jin; m3ASL: ASL Gesture Recognition with Moving mmWave Radar, INFOCOM 2025, London, United Kingdom, 2025-5-19至2025-5-22. EI. 第一标注</li>
                        <li class="break-words"><strong class="font-semibold text-gray-900">(CCF-A)</strong> Jiaxi Lv; Guiyun Fan; Xinyue Fu; Jiahui Sun; Rong Ding; Haiming Jin; mmWave-Based Relay Reflector Reconstruction for LiDAR-Free Around-Corner Human Sensing, INFOCOM 2025, London, United Kingdom, 2025-5-19至2025-5-22. EI. 第一标注</li>
                      </ol>
                    </li>
                  </ul>
                </div>
              </div>
            </div>
          </div>
          <div class="bg-white/0">
            <div class="mb-5">
              <h3 class="text-xl font-bold text-gray-900">
                学术贡献二：面向场景迁移的多模数据融合与压缩感知
              </h3>
              <p class="text-base text-gray-600 mt-2 leading-relaxed">提出了面向复杂数据感知的关键技术体系，聚焦于跨域特征对齐、模型迁移与高鲁棒性压缩感知，并在多源异构数据与跨域任务上开展系统性评测，提升跨场景泛化能力与抗噪鲁棒性。</p>
            </div>
            <div class="space-y-12">
              <div class="bg-white rounded-xl shadow-lg overflow-hidden border border-gray-200">
                <div class="p-6 border-b border-gray-100">
                  <div class="flex items-center mb-2">
                    <span class="bg-bit-green text-white text-xs font-bold px-2 py-1 rounded mr-3">
                      成果 03
                    </span>
                    <h3 class="text-xl font-bold text-gray-800">
                      面向场景模型迁移的多模态数据融合
                    </h3>
                  </div>
                  <p class="text-gray-600 text-base leading-relaxed mt-3">提出了语言-视觉联合学习范式和基于区域纯度与预测不确定性的主动迁移学习方法，通过引导视觉模型将其图像表征与文本分布对齐，从而融合文本与图像模态的知识，提升少样本下的视觉感知模型性能；同时，设计联合区域不纯度与预测不确定性的跨域采样策略，实现高效的区域级与像素级标注机制，提升模型在复杂多变场景下的泛化能力与鲁棒性。</p>
                </div>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-0">
                  <div class="p-4 bg-gray-50 border-r border-gray-100">
                    <img alt="成果03 方法示意" class="h-64 w-full object-contain bg-white rounded" data-asset="res03_method" src="site_assets/images/placeholder.png"/>
                    <p class="text-center text-sm text-gray-500 mt-2">
                      图2-5：感知模型的跨场景迁移框架 <sup class="fig-ref-sup">[1]</sup>
                    </p>
                  </div>
                  <div class="p-4 bg-gray-50">
                    <img alt="成果03 效果示意" class="h-64 w-full object-contain bg-white rounded" data-asset="res03_effect" src="site_assets/images/placeholder.png"/>
                    <p class="text-center text-sm text-gray-500 mt-2">
                      图2-6：跨场景语义分割效果 <sup class="fig-ref-sup">[2]</sup>
                    </p>
                  </div>
                </div>
                <div class="p-6 bg-white border-t border-gray-100">
                  <h4 class="text-sm font-bold text-gray-900 mb-3">
                    代表性学术成果
                  </h4>
                  <ul class="text-sm text-gray-700 space-y-4 leading-relaxed">
                    <li>
                      <ol class="mt-2 ref-list pl-0 space-y-2">
                        <li class="break-words"><strong class="font-semibold text-gray-900">(CCF-A)</strong> Binhui Xie; Longhui Yuan; Shuang Li; Chi Harold Liu; Xinjing Cheng; Towards Fewer Annotations: Active Learning via Region Impurity and Prediction Uncertainty for Domain Adaptive Semantic Segmentation, IEEE CVPR 2022, New Orleans, 2022-6-19至2022-6-24. 第一标注</li>
                        <li class="break-words"> 叶语霄; 刘驰; 王昊, 一种保障元宇宙应用信息质量的无人群体感知方法，2023-8-2，中国， 202311056761.4.</li>
                      </ol>
                    </li>
                  </ul>
                </div>
              </div>
              <div class="bg-white rounded-xl shadow-lg overflow-hidden border border-gray-200">
                <div class="p-6 border-b border-gray-100">
                  <div class="flex items-center mb-2">
                    <span class="bg-bit-green text-white text-xs font-bold px-2 py-1 rounded mr-3">
                      成果 04
                    </span>
                    <h3 class="text-xl font-bold text-gray-800">
                      数据/算法复杂度降维的基于GAN异常共生压缩感知
                    </h3>
                  </div>
                  <p class="text-gray-600 text-base leading-relaxed mt-3">提出了因果启发的表征学习框架和内存超参数自适应的集成优化方法，通过因果干预机制与掩码对抗生成模块，迭代检测包含较少因果信息的维度并强制这些维度包含更多新颖的因果信息，确保压缩后的特征表示能够保留任务相关的关键信息；同时借助在线轻量级估算模块预估模型重训练阶段的内存、时间资源消耗以及精度提升效果，实现内存最优规则下的感知模型重训练，解决多模响应迟缓的挑战。</p>
                </div>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-0">
                  <div class="p-4 bg-gray-50 border-r border-gray-100">
                    <img alt="成果04 方法示意" class="h-64 w-full object-contain bg-white rounded" data-asset="res04_method" src="site_assets/images/placeholder.png"/>
                    <p class="text-center text-sm text-gray-500 mt-2">
                      图2-7：因果启发的表征学习框架 <sup class="fig-ref-sup">[1]</sup>
                    </p>
                  </div>
                  <div class="p-4 bg-gray-50">
                    <img alt="成果04 效果示意" class="h-64 w-full object-contain bg-white rounded" data-asset="res04_effect" src="site_assets/images/placeholder.png"/>
                    <p class="text-center text-sm text-gray-500 mt-2">
                      图2-8：内存超参数自适应的集成优化方法 <sup class="fig-ref-sup">[5]</sup>
                    </p>
                  </div>
                </div>
                <div class="p-6 bg-white border-t border-gray-100">
                  <h4 class="text-sm font-bold text-gray-900 mb-3">
                    代表性学术成果
                  </h4>
                  <ul class="text-sm text-gray-700 space-y-4 leading-relaxed">
                    <li>
                      <ol class="mt-2 ref-list pl-0 space-y-2">
                        <li class="break-words"><strong class="font-semibold text-gray-900">(CCF-A)</strong> Fangrui Lv; Jian Liang; Shuang Li; Bin Zang; Chi Harold Liu; Ziteng Wang; Di Liu; Causality Inspired Representation Learning for Domain Generalization, IEEE CVPR 2022, New Orleans, 2022-6-19至2022-6-24. EI. 第一标注</li>
                        <li class="break-words"><strong class="font-semibold text-gray-900">(CCF-A)</strong> Yuxiao Ye; Chi Harold Liu; Zipeng Dai; Jianxin Zhao; Ye Yuan; Guoren Wang; Jian Tang; Exploring both Individuality and Cooperation for Air-Ground Spatial Crowdsourcing by Multi-Agent Deep Reinforcement Learning, I EEE ICDE 2023, Anaheim, CA, 2023-4-3至2023-4-7. EI. 第一标注</li>
                        <li class="break-words"><strong class="font-semibold text-gray-900">(CCF-A)</strong> Yu Wang; Jingfei Wu; Xingyuan Hua; Chi Harold Liu; Guozheng Li; Jianxin Zhao; Ye Yuan; Guoren Wang; Air-Ground Collaborative Spatial Crowdsourcing with UAV Carriers by Geometric Graph Convolutional Multi-Agent Deep Reinforcement Learning, IEEE ICDE 2023, Anaheim, CA, 2023-4-3至2023-4-7. EI. 第一标注</li>
                        <li class="break-words"><strong class="font-semibold text-gray-900">(CCF-A, SCI Q1)</strong> Yinuo Zhao; Chi Harold Liu; Tianjiao Yi; Guozheng Li; Dapeng Wu; Energy-Efficient Ground-Air-Space Vehicular Crowdsensing by Hierarchical Multi-Agent Deep Reinforcement Learning With Diffusion Models, IEEE Journal on Selected Areas in Communications, 2024, 42 (12): 3566-3580. SCIE. 第一标注</li>
                        <li class="break-words"> 徐奕东; 韩锐; 刘驰, 一种面向深度学习模型的边缘端重训练内存配置优化方法，2023-10-26，中国，202311396860.7.</li>
                      </ol>
                    </li>
                  </ul>
                </div>
              </div>
            </div>
          </div>
          <div class="bg-white/0">
            <div class="mb-5">
              <h3 class="text-xl font-bold text-gray-900">
                学术贡献三：边缘异构设备联邦学习与群体特征识别
              </h3>
              <p class="text-base text-gray-600 mt-2 leading-relaxed">提出了面向边缘计算能力提升的协同优化方法，聚焦于多目标协同优化与时空关联的群体行为识别，并在群体行为理解与端侧推理部署设置下验证，体现出在准确率、实时性与可扩展性之间的良好平衡。</p>
            </div>
            <div class="space-y-12">
              <div class="bg-white rounded-xl shadow-lg overflow-hidden border border-gray-200">
                <div class="p-6 border-b border-gray-100">
                  <div class="flex items-center mb-2">
                    <span class="bg-bit-green text-white text-xs font-bold px-2 py-1 rounded mr-3">
                      成果 05
                    </span>
                    <h3 class="text-xl font-bold text-gray-800">
                      基于异构设备资源多目标优化的联邦学习技术
                    </h3>
                  </div>
                  <p class="text-gray-600 text-base leading-relaxed mt-3">提出了协同计算，能够实现多个异构设备的迁移训练，提升识别精度。本方法采用子梯度下降算法进行优化，并应用模型蒸馏的调整方法提升异构设备的训练精度。本方法与已有去中心化训练方法D-PSGD、PENS和中心化数据增强训练方法Hybrid-FL在图像分类准确度指标上进行对比。实验结果表明，在所有不同的移动终端设置总数下，本方法比已有方法均获得了更高的准确度，相比PENS方法准确度提升最高，平均提升6%。</p>
                </div>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-0">
                  <div class="p-4 bg-gray-50 border-r border-gray-100">
                    <img alt="成果05 方法示意" class="h-64 w-full object-contain bg-white rounded" data-asset="res05_method" src="site_assets/images/placeholder.png"/>
                    <p class="text-center text-sm text-gray-500 mt-2">
                      图2-9：基于边缘异构设备匹配与多目标优化的联邦学习技术示意图 <sup class="fig-ref-sup">[1]</sup>
                    </p>
                  </div>
                  <div class="p-4 bg-gray-50">
                    <img alt="成果05 效果示意" class="h-64 w-full object-contain bg-white rounded" data-asset="res05_effect" src="site_assets/images/placeholder.png"/>
                    <p class="text-center text-sm text-gray-500 mt-2">
                      图2-10：基于边缘异构设备匹配与多目标优化的联邦学习技术成果示意图 <sup class="fig-ref-sup">[1]</sup>
                    </p>
                  </div>
                </div>
                <div class="p-6 bg-white border-t border-gray-100">
                  <h4 class="text-sm font-bold text-gray-900 mb-3">
                    代表性学术成果
                  </h4>
                  <ul class="text-sm text-gray-700 space-y-4 leading-relaxed">
                    <li>
                      <ol class="mt-2 ref-list pl-0 space-y-2">
                        <li class="break-words"> Jianxin Zhao; Xinyu Chang; Yanhao Feng; Chi Harold Liu; Ningbo Liu; Participant Selection for Federated Learning With Heterogeneous Data in Intelligent Transport System, IEEE Transactions on Intelligent Transportation Systems, 2023, 24(1): 1106-1115. 第一标注</li>
                      </ol>
                    </li>
                  </ul>
                </div>
              </div>
              <div class="bg-white rounded-xl shadow-lg overflow-hidden border border-gray-200">
                <div class="p-6 border-b border-gray-100">
                  <div class="flex items-center mb-2">
                    <span class="bg-bit-green text-white text-xs font-bold px-2 py-1 rounded mr-3">
                      成果 06
                    </span>
                    <h3 class="text-xl font-bold text-gray-800">
                      群体高阶张量建模与时空动态特征识别
                    </h3>
                  </div>
                  <p class="text-gray-600 text-base leading-relaxed mt-3">提出了基于群体高阶张量建模与时空动态特征识别的目标有害物质特征气体精准识别技术。该技术以分子特异性吸附与质量负载效应的协同作用为基础，提取目标气体分子的多维本征特征并构建群体高阶张量模型；结合扩散模型反演其在复杂环境中的动态演化规律，创新性融合时空动态特征匹配与自适应阈值优化算法，突破了开放环境下目标气体识别精度不足、溯源能力缺失的技术瓶颈，有效解决了复杂场景下的精准识别与溯源难题。基于该技术研制的小型化移动感知终端，可实现复杂环境中多目标特征气体的高灵敏定性定量检测，其多元混合物分类准确率达 94.6%，检出限低至 0.34 ppm，能够精准识别爆炸物挥发性气体等有毒有害气体，为反恐防暴工作提供关键技术支撑，对保障公共安全具有重要的实际应用价值。</p>
                </div>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-0">
                  <div class="p-4 bg-gray-50 border-r border-gray-100">
                    <img alt="成果06 方法示意" class="h-64 w-full object-contain bg-white rounded" data-asset="res06_method" src="site_assets/images/placeholder.png"/>
                    <p class="text-center text-sm text-gray-500 mt-2">
                      图2-11：基于单芯片FBAR的特征提取方法 <sup class="fig-ref-sup">[1]</sup>
                    </p>
                  </div>
                  <div class="p-4 bg-gray-50">
                    <img alt="成果06 效果示意" class="h-64 w-full object-contain bg-white rounded" data-asset="res06_effect" src="site_assets/images/placeholder.png"/>
                    <p class="text-center text-sm text-gray-500 mt-2">
                      图2-12：基于多模态感知与特征识别的多气体分类能力 <sup class="fig-ref-sup">[2]</sup>
                    </p>
                  </div>
                </div>
                <div class="p-6 bg-white border-t border-gray-100">
                  <h4 class="text-sm font-bold text-gray-900 mb-3">
                    代表性学术成果
                  </h4>
                  <ul class="text-sm text-gray-700 space-y-4 leading-relaxed">
                    <li>
                      <ol class="mt-2 ref-list pl-0 space-y-2">
                        <li class="break-words"><strong class="font-semibold text-gray-900">(SCI Q1)</strong> Yunqi Cao; Mengyao Fu; Shuyu Fan; Chenyang Gao; Zhiqiang Ma; Dibo Hou; Hydrophobic MOF/PDMS-Based QCM Sensors for VOCs Identification and Quantitative Detection in High-Humidity Environments, ACS Applied Materials & Interfaces, 2024, 16(6): 7721–7731. SCIE. 第二标注</li>
                        <li class="break-words"><strong class="font-semibold text-gray-900">(SCI Q1)</strong> Zhiqiang Ma; Mengyao Fu; Chenyang Gao; Shuyu Fan; Haozhen Chi; Wei Li; Dibo Hou; Yunqi Cao; Trenched microwave resonator integrated with porous PDMS for detection and classification of VOCs with enhanced performance, Journal of Hazardous Materials, 2024, 472: 134553. SCIE. 第一标注</li>
                        <li class="break-words"><strong class="font-semibold text-gray-900">(SCI Q1)</strong> Mengyao Fu; Zhiqiang Ma; Chenyang Gao; Yi Shen; Xiaoyan Song; Dibo Hou; Yunqi Cao. Detection of Volatile Organic Compounds and Their Mixtures Using an E-nose with Cascaded QCM-based Multi-Virtual Sensor Array, Measurement Science and Technology, 2025, 36, 115109.  SCIE 第一标注</li>
                        <li class="break-words"> Mengyao Fu; Dongsheng Li; Chenyang Gao; Zhiqiang Ma; Dibo Hou; Yunqi Cao. MOF/PDMS Hybrid Nanofilm-Based QCM for VOC Selective Virtual Sensing in High-Humidity Environments, 2023 22nd International Conference on Solid-State Sensors, Actuators and Microsystems (Transducers), Kyoto, 2023-6-25至2023-6-29，EI.第二标注</li>
                      </ol>
                    </li>
                  </ul>
                </div>
              </div>
            </div>
          </div>
          <div class="bg-white/0">
            <div class="mb-5">
              <h3 class="text-xl font-bold text-gray-900">
                学术贡献四：面向泛在边缘环境的感知与计算系统
              </h3>
              <p class="text-base text-gray-600 mt-2 leading-relaxed">提出了面向反恐防暴应用的新型MEMS传感终端研制与端到端系统集成方案，覆盖传感器研制、算法建模与系统验证，并完成从器件—算法—系统的闭环联调与环境适配验证，支撑现场快速部署与稳定运行。</p>
            </div>
            <div class="space-y-12">
              <div class="bg-white rounded-xl shadow-lg overflow-hidden border border-gray-200">
                <div class="p-6 border-b border-gray-100">
                  <div class="flex items-center mb-2">
                    <span class="bg-bit-green text-white text-xs font-bold px-2 py-1 rounded mr-3">
                      成果 07
                    </span>
                    <h3 class="text-xl font-bold text-gray-800">
                      基于MEMS阵列的多模态生化类危险品终端传感器研发
                    </h3>
                  </div>
                  <p class="text-gray-600 text-base leading-relaxed mt-3">研发了一种基于薄膜体声波谐振器（FBAR）的大气污染物原位检测传感器，该传感器基于压电效应工作，当外部交流电流频率与FBAR的固有谐振频率相匹配时，会发生厚度伸缩振动模式（TE模式）的共振，该模式具有高机电耦合系数。这种模式对谐振器表面负载的质量非常敏感，表现为负频率偏移。本工作中开发的裸FBAR具有约1.25 GHz的自然谐振频率和超过1400的品质因数，大约是该领域其他工作的1.5-2倍，提高了信噪比和传感分辨率，最终实现了多种污染物的高准确率定性分类及高灵敏度定量检测。</p>
                </div>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-0">
                  <div class="p-4 bg-gray-50 border-r border-gray-100">
                    <img alt="成果07 方法示意" class="h-64 w-full object-contain bg-white rounded" data-asset="res07_method" src="site_assets/images/placeholder.png"/>
                    <p class="text-center text-sm text-gray-500 mt-2">
                      图2-13：基于FBAR技术MEMS多模态传感器原理图 <sup class="fig-ref-sup">[1]</sup>
                    </p>
                  </div>
                  <div class="p-4 bg-gray-50">
                    <img alt="成果07 效果示意" class="h-64 w-full object-contain bg-white rounded" data-asset="res07_effect" src="site_assets/images/placeholder.png"/>
                    <p class="text-center text-sm text-gray-500 mt-2">
                      图2-14：MEMS传感器检测原理及其SEM图像 <sup class="fig-ref-sup">[2]</sup>
                    </p>
                  </div>
                </div>
                <div class="p-6 bg-white border-t border-gray-100">
                  <h4 class="text-sm font-bold text-gray-900 mb-3">
                    代表性学术成果
                  </h4>
                  <ul class="text-sm text-gray-700 space-y-4 leading-relaxed">
                    <li>
                      <ol class="mt-2 ref-list pl-0 space-y-2">
                        <li class="break-words"><strong class="font-semibold text-gray-900">(SCI Q1)</strong> Chenyang Gao; Mengyao Fu; Shuyu Fan; Zhiqiang Ma; Yongkui Tang; Dibo Hou; Yunqi Cao. High-performance virtual sensors array based on a single-chip FBAR for volatile organic compounds (VOCs) detection and classification, Sensors and Actuators:B. Chemical, 2025, 422: 136687. SCIE 第二标注</li>
                        <li class="break-words"> Mengyao Fu; Zhiqiang Ma; Chenyang Gao; Yongping Ye; Wei Li; Dibo Hou; Yunqi Cao. A Multi-Functional VOC Sensor Based on Cascaded Quartz Crystal Resonators, IEEE Electron Device Letters, 2025, 46(3): 476-479. SCIE 第一标注</li>
                        <li class="break-words"> Chengyang Gao; Shuyu Fan; Wei Li; Yongbing Wang; Qianwen Xia; Dibo Hou; Yunqi Cao; A high-performance miniaturized frequency shift detection system for QCM-based mass sensing, Advanced Sensor Research, 2024, 0(0): 2400148. SCIE. 第一标注</li>
                        <li class="break-words"> Chenyang Gao; Mengyao Fu; Zhiqiang Ma; Shuyu Fan; Dibo Hou; Yunqi Cao; Metal-organic framework (MOF) based film bulk acoustic resonator (FBAR) sensor for volatile organic compounds (VOCs) detection, IEEE IECON 2024, Chicago, USA, 2024-11-3至2024-11-6. EI. 第一标注</li>
                        <li class="break-words"> Chenyang Gao; Shuyu Fan; Haozhen Chi; Yipei Yao; Dibo Hou; Yunqi Cao; A high-sensitivity frequency shift detector for QCM-based miniaturized sensing system, CAC 2024, Qingdao, China, 2024-11-1至2024-11-3. EI 第二标注</li>
                      </ol>
                    </li>
                  </ul>
                </div>
              </div>
              <div class="bg-white rounded-xl shadow-lg overflow-hidden border border-gray-200">
                <div class="p-6 border-b border-gray-100">
                  <div class="flex items-center mb-2">
                    <span class="bg-bit-green text-white text-xs font-bold px-2 py-1 rounded mr-3">
                      成果 08
                    </span>
                    <h3 class="text-xl font-bold text-gray-800">
                      面向反恐防暴等泛在边缘环境的移动群体感知与计算系统
                    </h3>
                  </div>
                  <p class="text-gray-600 text-base leading-relaxed mt-3">提出了面向公共安全事件应急处置全流程的边侧移动群体感知与能力增强端到端系统。集成人机资源优选调度、车—机协同轨迹规划、目标/环境感知、边缘压缩与联邦学习在线优化等关键能力，形成可演示、可验证的系统级解决方案，并通过端—边—云协同链路的闭环演示验证，具备工程化落地条件。</p>
                </div>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-0">
                  <div class="p-4 bg-gray-50 border-r border-gray-100">
                    <img alt="成果08 方法示意" class="h-64 w-full object-contain bg-white rounded" data-asset="res08_method" src="site_assets/images/placeholder.png"/>
                    <p class="text-center text-sm text-gray-500 mt-2">
                      图2-15：系统整体架构与模块交互
                    </p>
                  </div>
                  <div class="p-4 bg-gray-50">
                    <img alt="成果08 效果示意" class="h-64 w-full object-contain bg-white rounded" data-asset="res08_effect" src="site_assets/images/placeholder.png"/>
                    <p class="text-center text-sm text-gray-500 mt-2">
                      图2-16：反恐防暴场景系统运行界面
                    </p>
                  </div>
                </div>
                <div class="p-6 bg-white border-t border-gray-100">
                  <h4 class="text-sm font-bold text-gray-900 mb-3">
                    代表性学术成果
                  </h4>
                  <ul class="text-sm text-gray-700 space-y-4 leading-relaxed">
                    <li>
                      <ol class="mt-2 ref-list pl-0 space-y-2">
                        <li class="break-words"> Jiahui Sun; Guiyun Fan; Haiming Jin; Yiwen Song; Tianyuan Liu; Chenhao Ying; Yuan Luo; Jie Li; Multi-Task-Oriented UAV Crowd Sensing with Charging Budget Constraint, ACM MOBIHOC 2024, Athens, Greece, 2024-10-14至2024-10-17. EI. 第一标注</li>
                        <li class="break-words"><strong class="font-semibold text-gray-900">(CCF-A)</strong> Chenhao Ying; Fuyuan Xia; David S. L. Wei; Xinchun Yu; Yibin Xu; Weiting Zhang; Xikun Jiang; Haiming Jin; Yuan Luo; Tao Zhang; Dacheng Tao; BIT-FL: Blockchain-Enabled Incentivized and Secure Federated Learning Framework, ACM Transactions on Mobile Computing, 2025, 24(2)：1212-1229. SCIE, EI. 第三标注</li>
                        <li class="break-words"><strong class="font-semibold text-gray-900">(CCF-A)</strong> Yu Wang; Jingfei Wu; Xingyuan Hua; Chi Harold Liu; Guozheng Li; Jianxin Zhao; Ye Yuan; Guoren Wang; Air-Ground Collaborative Spatial Crowdsourcing with UAV Carriers by Geometric Graph Convolutional Multi-Agent Deep Reinforcement Learning, IEEE ICDE 2023, Anaheim, CA, 2023-4-3至2023-4-7. EI. 第一标注</li>
                      </ol>
                    </li>
                  </ul>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>
    <section class="py-20 bg-white" id="applications">
      <div class="container mx-auto px-6">
        <h2 class="text-3xl font-bold text-gray-900 section-title">
          03 应用演示
        </h2>
        <div class="space-y-8">
          <div class="w-full max-w-5xl mx-auto">
            <div class="aspect-video bg-gray-900 rounded-lg flex items-center justify-center relative shadow-2xl overflow-hidden">
              <video class="w-full h-full bg-black" id="demoVideo" controls preload="metadata" playsinline>
                <source id="demoVideoSource" src="" type="video/mp4" />
                您的浏览器不支持 HTML5 video 标签。
              </video>
              <div id="demoVideoPlaceholder" class="absolute inset-0 flex items-center justify-center bg-gray-900/95 text-gray-200 text-sm px-6 text-center">
                演示视频将以外部直链方式播放（推荐：GitHub Releases 作为 Release asset 托管）。若当前网络环境无法加载或链接尚未配置，请
                <a id="demoVideoOpenLink" class="text-blue-300 underline ml-1" href="#" target="_blank" rel="noopener">点击打开/下载视频</a>。
              </div>
            </div>
          </div>
        </div>
          <div class="w-full max-w-5xl mx-auto">
            <h3 class="text-2xl font-bold mb-4 text-gray-800"> </h3>
            <h3 class="text-2xl font-bold mb-4 text-gray-800">
              杭州世纪中心异常包裹应急处置仿真
            </h3>
            <div class="prose text-gray-600 leading-relaxed text-base">
              <p class="mb-3">
                本次演示基于浙江省杭州市“世纪中心”周边街区构建仿真场景，模拟夜间发现疑似爆炸物包裹后的应急处置闭环。系统在接收警情后自动生成处置目标与双线任务（“包裹排查/处置”与“嫌疑人追踪/封控”），联动多警力单位、无人机与无人车集群完成资源优选调度、协同轨迹规划、现场侦查与目标跟踪。在边缘侧，系统对视频流进行低时延压缩回传（环境/目标视频传输量分别降低约53%与54%），并通过联邦学习在线自适应提升识别模型在当前场景与光照条件下的准确性；最终融合视觉轨迹特征与气体组分分类结果，完成爆炸物指纹比对与嫌疑目标关联分析，生成处置报告并给出收网指引。本演示所依托的核心技术载体——面向公共安全事件应急处置的边侧移动群体智能感知与协同计算系统，已获得浙江省应急管理数字与技术中心的高度评价与充分认可。
              </p>
              <p class="mb-2 font-bold text-gray-800">
                处置流程关键节点：
              </p>
              <ul class="space-y-2 mb-4 list-disc pl-4">
                <li>
                  <span class="font-semibold text-bit-green">
                    T+10s 警情研判：
                  </span>
                  系统接收警情并启动爆炸物响应预案，自动生成处置目标与双线任务（包裹处置/嫌疑人追踪）。
                </li>
                <li>
                  <span class="font-semibold text-bit-green">
                    T+25s 人机资源优选与智能调度：
                  </span>
                  综合距离、到场时延、载荷能力与协同约束，在多警局与多平台中优选无人机/无人车编组并给出出动方案。
                </li>
                <li>
                  <span class="font-semibold text-bit-green">
                    T+90s 车—机协同轨迹规划与到场侦查：
                  </span>
                  计算无碰撞航迹与地面路线，设备抵达后开展现场视频侦查与目标跟踪，形成初步风险评估。
                </li>
                <li>
                  <span class="font-semibold text-bit-green">
                    T+180s 低时延压缩回传：
                  </span>
                  对环境与目标感知视频流执行边缘压缩，传输量分别降低约53%与54%，保障链路拥塞条件下的实时回传。
                </li>
                <li>
                  <span class="font-semibold text-bit-green">
                    T+240s 联邦学习在线自适应：
                  </span>
                  在不交换原始视频数据的前提下启动联邦学习与轻量更新，快速提升识别模型对当前场景的适配性（精度曲线收敛至0.92+）。
                </li>
                <li>
                  <span class="font-semibold text-bit-green">
                    T+300s 多模态精细锁定与报告输出：
                  </span>
                  融合视觉轨迹特征与气体组分分类结果完成爆炸物指纹比对并关联嫌疑人B，协助警力封控收网，同时自动生成处置报告与过程留痕。
                </li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </section>

    
    <section class="py-20 bg-gray-50" id="exchange">
      <div class="container mx-auto px-6">
        <h2 class="text-3xl font-bold text-gray-900 section-title">
          04 学术交流
        </h2>

        <div class="max-w-6xl mx-auto space-y-6">
          <!-- Carousel (side navigation) -->
          <div class="flex items-stretch gap-3 md:gap-4">
            <button id="exchangePrev" class="icon-btn icon-btn-lg shrink-0 self-center" type="button" aria-label="上一条">
              <span class="text-gray-700 text-2xl leading-none">‹</span>
            </button>

            <div class="group flex-1 min-w-0 bg-white rounded-xl shadow-sm border border-gray-100 overflow-hidden transition-shadow duration-200 hover:shadow-md">
              <div class="relative">
                <img id="exchangeImage" class="w-full h-[280px] sm:h-[360px] md:h-[550px] object-cover transition-transform duration-300 ease-out group-hover:scale-[1.01]" src="site_assets/images/placeholder.png" alt="学术交流照片"/>
                <div class="absolute inset-x-0 bottom-0 bg-gradient-to-t from-black/55 to-transparent h-28"></div>

                <div class="absolute left-4 top-4 inline-flex items-center gap-2 px-3 py-1 rounded-full bg-white/90 backdrop-blur-md border border-white/30 text-xs text-gray-700">
                  <span class="font-semibold" id="exchangeCounter">1 / 7</span>
                </div>
              </div>

              <div class="p-5 md:p-6">
                <p id="exchangeText" class="text-gray-800 text-base leading-relaxed">
                  参加国内外重要学术会议并作专题报告
                </p>
              </div>
            </div>

            <button id="exchangeNext" class="icon-btn icon-btn-lg shrink-0 self-center" type="button" aria-label="下一条">
              <span class="text-gray-700 text-2xl leading-none">›</span>
            </button>
          </div>

          <!-- Collapsible full list -->
          <details class="bg-white rounded-xl shadow-sm border border-gray-100 overflow-hidden">
            <summary class="cursor-pointer select-none px-5 py-4 font-semibold text-gray-900">
              学术交流列表
            </summary>
            <div class="px-5 pb-5">
              <ul class="space-y-6 text-gray-700 leading-relaxed">
<li class="rounded-lg border border-gray-100 bg-gray-50/50 p-4">
  <div class="font-semibold text-gray-900">参加国际学术会议</div>
  <ol class="list-decimal pl-5 mt-3 space-y-2 text-gray-700 leading-relaxed marker:text-gray-400">
    <li>2025年11月，项目组成员金海明、丁榕参加了在香港的2025年MOBICOM会议。</li>
    <li>2025年5月，项目组成员金海明、范桂云参加了在英国伦敦的2025年INFOCOM会议。</li>
    <li>2024年10月，项目组成员金海明参加了在希腊雅典的2024年MOBIHOC会议。</li>
    <li>2024年8月，项目组成员杨兆星参加了在西班牙巴塞罗那的2024年KDD会议。</li>
    <li>2024年5月，项目组成员金海明、丁榕、祝宁之参加了在香港的2024年IPSN会议。</li>
    <li>2024年5月，项目组成员杨兆星参加了在新西兰奥克兰的2024年AAMAS会议。</li>
    <li>2023年11月，项目组成员金海明、丁榕参加了在土耳其伊斯坦布尔的2023年SenSys会议。</li>
    <li>2023年7月，项目组成员杨兆星参加了在香港的2023年ICDCS会议。</li>
    <li>2023年5月，项目组成员金海明参加了在美国新泽西的2023年INFOCOM会议。</li>
    <li>2023年2月，项目组成员杨兆星线上参加了2023年AAAI会议。</li>
    <li>2022年5月，项目组成员范桂云参加了在线举办的2022年INFOCOM会议。</li>
    <li>2022年6月，项目组成员谢斌辉线上参加了2022年CVPR会议。</li>
    <li>2022年6月，项目组成员吕芳蕊线上参加了2022年CVPR会议。</li>
    <li>2023年4月，项目组成员叶语霄参加了2023年ICDE会议。</li>
    <li>2023年4月，项目组成员王宇线上参加了2023年ICDE会议。</li>
    <li>2023年6月，项目组成员傅梦瑶参加了在日本的2023年Transducers会议。</li>
    <li>2023年10月，项目组成员范舒羽参加了在新加坡的2023年IECON会议。</li>
    <li>2024年11月，项目组成员高晨阳线上参加了在芝加哥的2024年IECON会议。</li>
    <li>2024年10月，项目组成员曹云琦研究员受邀参加了在日本神户的2024年IEEE SENSORS会议，并担任分会场主席。</li>
  </ol>
</li>
<li class="rounded-lg border border-gray-100 bg-gray-50/50 p-4">
  <div class="font-semibold text-gray-900">学术互访</div>
  <ol class="list-decimal pl-5 mt-3 space-y-2 text-gray-700 leading-relaxed marker:text-gray-400">
    <li>2025年12月22日-25日，美国纽约州立大学布法罗分校谢亚雄教授访问上海交通大学。</li>
    <li>2025年11月15日-20日，新加坡南洋理工大学Chee Wei Tan教授访问上海交通大学。</li>
    <li>2023年5月，赴美国与普渡大学的宿陆老师课题组交流，并对项目相关移动群体感知问题进行讨论。</li>
    <li>2022年，邀请华盛顿大学Akshay Gadre教授、香港中文大学邢国良教授、北京大学许辰人教授做线上学术报告。</li>
    <li>2024年6月27日，邀请香港城市大学吴大鹏教授访问北京理工大学，深入开展线下学术研讨会议，并对项目相关问题进行讨论。</li>
    <li>2025年6月，赴美国密歇根州立大学与Xiaobo Tan教授（IEEE Fellow、ASME Fellow）与Yiming Deng教授（ASNT Fellow）课题组交流，对本项目多模态传感器问题进行深入探讨。</li>
  </ol>
</li>
</ul>
            </div>
          </details>
        </div>
      </div>
    </section>

    
    <section class="py-20 bg-white" id="talent">
      <div class="container mx-auto px-6">
        <h2 class="text-3xl font-bold text-gray-900 section-title">
          05 人才培养
        </h2>

        <div class="w-full">
          <div class="grid grid-cols-1 md:grid-cols-3 gap-8 md:gap-12">
            <!-- Postdoc -->
            <div class="flex flex-col h-full">
              <div class="bg-green-50 p-6 rounded-xl border border-green-100 text-center mb-6">
                <div class="text-4xl font-bold text-bit-green mb-1">
                  <span id="talent-postdoc-total">1</span>
                </div>
                <div class="text-sm font-medium text-gray-600">
                  博士后培养人数（名）
                </div>
              </div>

              <div class="bg-white rounded-xl border border-gray-200 shadow-sm flex flex-col" style="height: 520px;">
                <div class="p-5 border-b border-gray-100 bg-gray-50/50 shrink-0">
                  <h3 class="text-xl font-bold text-gray-900 mb-3">教师与团队建设</h3>
                </div>
                <div class="flex-1 overflow-y-auto min-h-0 custom-scrollbar p-5" id="talent-postdoc-list">
                  <ol class="list-decimal pl-5 space-y-2 text-sm text-gray-700 leading-relaxed marker:text-gray-400">
                    <li>北京理工大学刘驰教授入选为2025年长江学者特聘教授，2026年度IEEE Fellow，入选全球前2%顶尖科学家榜单（终身科学影响力榜单、年度科学影响力榜单）、爱思唯尔中国高被引科学家。 （长江学者特聘教授，IEEE Fellow, 爱思唯尔中国高被引）</li>
                    <li>北京理工大学刘驰教授指导项目“城市环境无人群体空地协同感知技术与仿真平台”（参与学生：叶语霄、刘嘉辉、焦鹏屹）获2022年“中国高校计算机大赛——人工智能创意赛”全国总决赛特等奖。</li>
                    <li>上海交通大学金海明于2025年晋升为长聘副教授，2022年-2025年连续4年入选全球前2%顶尖科学家榜单，于2024年获中国指挥与控制学会科学技术进步奖（技术发明类）一等奖（第5完成人）。</li>
                    <li>上海交通大学向立瑶于2024年晋升为长聘副教授，获2024年ACM中国上海新星奖。</li>
                    <li>上海交通大学叶南阳获2022年ACM中国上海新星奖。</li>
                    <li>浙江大学曹云琦研究员获2025年浙江省高等教育教学成果一等奖。</li>
                    <li>浙江大学曹云琦研究员于2024年受聘为全国工业过程测量控制和自动化标准化委员会智能记录仪表分技术委员会委员。</li>
                    <li>浙江大学曹云琦教授指导项目“面向白酒检测的射频式机器嗅觉（电子鼻）系统”（参与学生：毕研成、傅梦瑶、马志强、高晨阳、付逸飞）获第九届中国（国际）传感器创新创业大赛决赛高校组创新应用类三等奖。</li>
                    <li>浙江大学曹云琦教授指导项目“'Micro-SmartCar'面向大型动力设备的微型智能检修机器人”（参与学生：于浩洋、洪德隆、付逸飞）获2025年中国大学生智能装备创新设计大赛(区域赛)一等奖。</li>
                    <li>浙江大学曹云琦教授指导项目“基于自感知密封垫片的螺栓法兰密封状态智能监测系统”（参与学生：付逸飞、洪德隆、于浩洋）获2025年中国大学生智能装备创新设计大赛(区域赛)一等奖。</li>
                    <li>浙江大学曹云琦研究员指导项目“针对大型发电设备检修的微小型机器人应用研究”（参与学生：单绮玮、汪舒迅、张逸诚、陈炫）获2024年第十九届“挑战杯”全国大学生课外学术科技作品竞赛“揭榜挂帅”专项赛一等奖。</li>
                  </ol>
                </div>
              </div>
            </div>

            <!-- PhD -->
            <div class="flex flex-col h-full">
              <div class="bg-indigo-50 p-6 rounded-xl border border-indigo-100 text-center mb-6">
                <div class="text-4xl font-bold text-indigo-800 mb-1">
                  <span id="talent-phd-total">14</span>
                </div>
                <div class="text-sm font-medium text-gray-600">
                  博士研究生培养人数（名）
                </div>
              </div>

              <div class="bg-white rounded-xl border border-gray-200 shadow-sm flex flex-col" style="height: 520px;">
                <div class="p-5 border-b border-gray-100 bg-gray-50/50 shrink-0">
                  <h3 class="text-xl font-bold text-gray-900 mb-3">博士</h3>
                </div>
                <div class="flex-1 overflow-y-auto min-h-0 custom-scrollbar p-5" id="talent-phd-list">
                  <div class="space-y-5">
                    <div class="rounded-lg border border-gray-100 bg-gray-50/60 p-4">
                      <div class="text-sm font-semibold text-gray-900 mb-3">博士后</div>
                        <ol class="list-decimal pl-5 space-y-2 text-sm text-gray-700 leading-relaxed marker:text-gray-400">
                          <li>培养上海交通大学博士后范桂云，在站期间获得国自然青年基金资助，出站后赴同济大学任助理教授。</li>
                        </ol>
                    </div>

                    <div class="rounded-lg border border-gray-100 bg-gray-50/60 p-4">
                      <div class="text-sm font-semibold text-gray-900 mb-3">博士研究生</div>
                        <ol class="list-decimal pl-5 space-y-3 text-sm text-gray-700 leading-relaxed marker:text-gray-400">
                          <li>培养北京理工大学博士研究生谢斌辉，获得2024年北京理工大学“优秀博士学位论文育苗基金”、2023年博士研究生国家奖学金，毕业后赴腾讯就业。</li>
                          <li>培养北京理工大学博士研究生赵一诺，获得ICLR 2022国际比赛“Generalizable Policy Learning in the Physical World”第一名、2020年硕士研究生国家奖学金，毕业后赴香港城市大学进站从事博士后研究。</li>
                          <li>培养上海交通大学博士研究生杨兆星，于2024年获得国家奖学金。</li>
                          <li>培养上海交通大学博士研究生丁榕，于2021-2025年获得吴文俊人工智能荣誉博士奖学金。</li>
                          <li>培育上海交通大学博士研究生孙嘉徽，毕业后赴中国移动研究院就业。</li>
                          <li>培养上海交通大学博士研究生欧俊杰，毕业后赴百度就业。</li>
                          <li>培养上海交通大学博士研究生朱一晨，毕业后赴华为就业。</li>
                          <li>培养浙江大学博士研究生周禹杉，获CSC资助前往南洋理工大学交流。</li>
                          <li>培养浙江大学博士研究生高晨阳，获2025年国家奖学金。</li>
                          <li>培养浙江大学博士研究生范舒羽，获得2024年浙江大学优秀博士生资助项目。</li>
                          <li>培养浙江大学博士研究生池豪镇，毕业后赴浙江科技大学担任讲师。</li>
                          <li>培养浙江大学博士研究生傅梦瑶，毕业后赴中国移动杭州研发中心就业。</li>
                          <li>培养浙江大学博士研究生马志强、单绮玮。</li>
                        </ol>
                    </div>
                  </div>
                </div>
              </div>
            </div>

            <!-- Master -->
            <div class="flex flex-col h-full">
              <div class="bg-amber-50 p-6 rounded-xl border border-amber-100 text-center mb-6">
                <div class="text-4xl font-bold text-amber-800 mb-1">
                  <span id="talent-master-total">13</span>
                </div>
                <div class="text-sm font-medium text-gray-600">
                  硕士研究生培养人数（名）
                </div>
              </div>

              <div class="bg-white rounded-xl border border-gray-200 shadow-sm flex flex-col" style="height: 520px;">
                <div class="p-5 border-b border-gray-100 bg-gray-50/50 shrink-0">
                  <h3 class="text-xl font-bold text-gray-900 mb-3">硕士</h3>
                </div>
                <div class="flex-1 overflow-y-auto min-h-0 custom-scrollbar p-5" id="talent-master-list">
<ol class="list-decimal pl-5 space-y-3 text-sm text-gray-700 leading-relaxed marker:text-gray-400">
  <li>培养北京理工大学硕士研究生王宇，获得2023年度中国电子学会硕士学位论文。</li>
<li>培养北京理工大学硕士研究生叶语霄，获得2022年“中国高校计算机大赛——人工智能创意赛”全国总决赛特等奖、2023年和2024年硕士研究生国家奖学金、2025年北京理工大学优秀硕士学位论文，毕业后赴香港科技大学攻读博士学位。</li>
<li>培养北京理工大学硕士研究生吕芳蕊，获得2021年硕士研究生国家奖学金，毕业后赴清华大学攻读博士学位。</li>
<li>培养北京理工大学硕士研究生徐奕东，于2024年毕业，毕业后赴中海油研究总院就业。</li>
<li>培养北京理工大学硕士毕业生常欣煜，与2024年毕业，毕业后赴字节跳动就业。</li>
<li>培养上海交通大学硕士研究生王孝成，于2024年获得上海市优秀毕业生。</li>
<li>培养上海交通大学硕士研究生农汉琦，于2024年获得上海市优秀毕业生。</li>
<li>培养上海交通大学硕士研究生吕嘉溪，毕业后赴拼多多就业。</li>
<li>培养上海交通大学硕士研究生余北辰，毕业后赴中兴就业。</li>
<li>培养浙江大学硕士研究生苏珊茜、汪舒迅、毕研成。</li>
</ol>
</div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="py-20 bg-white" id="papers">
      <div class="container mx-auto px-6">
        <h2 class="text-3xl font-bold text-gray-900 section-title">
          06 学术成果
        </h2>

        <div class="grid grid-cols-1 lg:grid-cols-2 gap-8 md:gap-12">
          <div class="flex flex-col h-full">
            <div class="bg-green-50 p-6 rounded-xl border border-green-100 text-center mb-6">
              <div class="text-4xl font-bold text-bit-green mb-1">
                <span id="paper-total">47</span>
              </div>
              <div class="text-sm font-medium text-gray-600">
                发表高水平论文 (篇)
              </div>
            </div>

            <div class="bg-white rounded-xl border border-gray-200 shadow-sm flex flex-col" style="height: 800px;">
              <div class="p-5 border-b border-gray-100 bg-gray-50/50 shrink-0">
                <h3 class="text-xl font-bold text-gray-900 mb-3">论文发表</h3>
                <input class="w-full px-3 py-2 rounded border border-gray-300 bg-white text-base focus:outline-none focus:ring-2 focus:ring-green-600/20 focus:border-green-600 transition" id="paper-search" placeholder="搜索论文..." type="search"/>
              </div>

              <div class="flex-1 overflow-y-auto min-h-0 custom-scrollbar p-5" id="paper-list">
              </div>
            </div>
          </div>

          <div class="flex flex-col h-full">
            <div class="bg-blue-50 p-6 rounded-xl border border-blue-100 text-center mb-6">
              <div class="text-4xl font-bold text-blue-800 mb-1">
                <span id="patent-total">15</span>
              </div>
              <div class="text-sm font-medium text-gray-600">
                专利申请与授权 (项)
              </div>
            </div>

            <div class="bg-white rounded-xl border border-gray-200 shadow-sm flex flex-col" style="height: 800px;">
              <div class="p-5 border-b border-gray-100 bg-gray-50/50 shrink-0">
                <h3 class="text-xl font-bold text-gray-900 mb-3">专利申请与授权</h3>
                <input class="w-full px-3 py-2 rounded border border-gray-300 bg-white text-base focus:outline-none focus:ring-2 focus:ring-blue-600/20 focus:border-blue-600 transition" id="patent-search" placeholder="搜索专利..." type="search"/>
              </div>

              <div class="flex-1 overflow-y-auto min-h-0 custom-scrollbar p-5" id="patent-list">
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <footer class="bg-gray-900 text-gray-400 py-10">
      <div class="container mx-auto px-6 text-center">
        <p class="mb-2">
          Copyright © 2025 北京理工大学 LINC All Rights Reserved.
        </p>
        <p class="text-sm">
          地址：北京市海淀区中关村南大街5号
        </p>
      </div>
    </footer>
    <script>
(function () {
  function $(id) { return document.getElementById(id); }

  var video = null;
  var placeholder = null;
  var openLink = null;

  function ensure() {
    video = $("demoVideo");
    placeholder = $("demoVideoPlaceholder");
    openLink = $("demoVideoOpenLink");
  }

  function showPlaceholder(show) {
    if (!placeholder) return;
    placeholder.style.display = show ? "flex" : "none";
  }

  function setOpenLink(url) {
    if (!openLink) return;
    if (!url) {
      openLink.removeAttribute("href");
      return;
    }
    openLink.href = url;
  }

  function setVideoSource(url) {
    ensure();
    if (!video) return;

    if (!url) {
      try { video.removeAttribute("src"); video.load(); } catch (e) {}
      showPlaceholder(true);
      return;
    }

    // 先显示占位，等 loadeddata 再隐藏
    showPlaceholder(true);

    try { video.pause(); } catch (e) {}
    video.src = url;
    try { video.load(); } catch (e) {}

    // 尝试自动预热（不自动播放，避免浏览器策略拦截）
    // 注意：preload=metadata 只拉取元数据，不会马上下载整段视频
  }

  document.addEventListener("DOMContentLoaded", function () {
    ensure();

    var direct = (window.PROJECT_DEMO_VIDEO_DIRECT_URL || "").trim();
    var local = (window.PROJECT_DEMO_VIDEO_URL || "").trim();
    var chosen = direct || local;

    var fallbackOpen = (window.PROJECT_DEMO_VIDEO_FALLBACK_OPEN || "").trim();
    setOpenLink(fallbackOpen || chosen);

    setVideoSource(chosen);

    if (video) {
      video.addEventListener("loadeddata", function () {
        showPlaceholder(false);
      });
      video.addEventListener("error", function () {
        // 加载失败：保持占位层，并建议用户点击打开/下载
        showPlaceholder(true);
      });
    }
  });
})();
</script>
    <script id="site-asset-apply">
   (function () {
  try {
    var cfg = window.SITE_ASSETS || {};
    var faviconLink = document.getElementById('site-favicon');
    if (faviconLink && cfg.favicon) faviconLink.href = cfg.favicon;

    var fallback = cfg.achievementFallback || 'site_assets/images/placeholder.png';
    var map = cfg.achievementImages || {};
    document.querySelectorAll('img[data-asset]').forEach(function (img) {
      var key = img.getAttribute('data-asset');
      var src = map[key] || fallback;
      img.src = src;
      img.onerror = function () { img.src = fallback; };
    });
  } catch (e) {
  }
})();
  </script>
    <script id="outputs-render-script">
(function () {
  // ============================
  // Data (from Final Report Template)
  // ============================
  const paperGroups = {
  "期刊｜ACM Transactions on Knowledge Discovery from Data": [
    "Junjie Ou; Haiming Jin; Xiaocheng Wang; Hao Jiang; Xinbing Wang; Chenghu Zhou; STA-TCN: Spatial-Temporal Attention over Temporal Convolutional Network for Next Point-of-Interest Recommendation, ACM Transactions on Knowledge Discovery from Data, 2023, 17(9)：1-19. SCIE, EI. 第三标注"
  ],
  "期刊｜ACM Transactions on Mobile Computing": [
    "(CCF-A) Chenhao Ying; Fuyuan Xia; David S. L. Wei; Xinchun Yu; Yibin Xu; Weiting Zhang; Xikun Jiang; Haiming Jin; Yuan Luo; Tao Zhang; Dacheng Tao; BIT-FL: Blockchain-Enabled Incentivized and Secure Federated Learning Framework, ACMTransactions on Mobile Computing, 2025, 24(2)：1212-1229. SCIE, EI. 第三标 注"
  ],
  "期刊｜ACS Applied Materials & Interfaces": [
    "Yunqi Cao; Mengyao Fu; Shuyu Fan; Chenyang Gao; Zhiqiang Ma; Dibo Hou; Hydrophobic MOF/PDMS-Based QCM Sensors for VOCs Identification and Quantitative Detection in High-Humidity Environments, ACS Applied Materials & Interfaces, 2024, 16(6): 7721–7731. SCIE. 第二标注"
  ],
  "期刊｜Advanced Sensor Research": [
    "Chengyang Gao; Shuyu Fan; Wei Li; Yongbing Wang; Qianwen Xia; Dibo Hou; Yunqi Cao; A high-performance miniaturized frequency shift detection system for QCM-based mass sensing, Advanced Sensor Research, 2024, 0(0): 2400148. SCIE. 第一标注"
  ],
  "期刊｜Cell Reports Physical Science": [
    "Yunqi Cao; Shuyu Fan; Yongkui Tang; Qiwei Shan; Chengyang Gao; Nelson Sepúlveda; Dibo Hou; Guangxin Zhang; Human-motion adaptability enhancement of wearable electromagnetic vibration energy harvesters toward self-sustained body sensornetworks, Cell Reports Physical Science, 2024, 5(9). SCIE. 第一标注"
  ],
  "期刊｜Energy Conversion and Management": [
    "Shuyu Fan;YongkuiTang; Lurui Zhao; Hai Liu;Yufeng Wang; Dibo Hou;Yunqi Cao; Design optimization of microfabricated coils for volume-limited miniaturized broadband electromagnetic vibration energy harvester, Energy Conversion and Management, 2022, 271(1). SCIE 第一标注"
  ],
  "期刊｜IEEE Electron Device Letters": [
    "Mengyao Fu; Zhiqiang Ma; Chenyang Gao; Yongping Ye; Wei Li; Dibo Hou; Yunqi Cao. A Multi-Functional VOC Sensor Based on Cascaded Quartz Crystal Resonators,IEEE Electron DeviceLetters, 2025, 46(3): 476-479. SCIE 第一标注"
  ],
  "期刊｜IEEE Journal on Selected Areas in Communications": [
    "(CCF-A)Yinuo Zhao; Chi Harold Liu; TianjiaoYi; Guozheng Li; Dapeng Wu; Energy-Efficient Ground-Air-Space Vehicular Crowdsensing by Hierarchical Multi-Agent Deep Reinforcement Learning With Diffusion Models, IEEE Journal on SelectedAreas in Communications, 2024, 42 (12): 3566-3580. SCIE. 第一标注"
  ],
  "期刊｜IEEE Sensors Letters": [
    "Yunqi Cao; Hongyang Shi; Xiaobo Tan; Nelson Sepúlveda; Enabling Negative Pressure Sensing Through Ferroelectret Device, IEEE Sensors Letters, 2022, 6(8). SCIE, EI. 第一标注"
  ],
  "期刊｜IEEE Transactions on Electron Devices": [
    "Yushan Zhou; Shuyu Fan; Ziying Zhu; Shanqian Su, Dibo Hou; Hongjian Zhang,; Yunqi Cao.Enabling High-Sensitivity Calorimetric Flow Sensor Using Vanadium Dioxide Phase-Change Material With Predictable Hysteretic Behavior, IEEETransactions on Electron Devices, 2025, 72(3): 1360-1367. SCIE 第二标注"
  ],
  "期刊｜IEEE Transactions on Instrumentation and Measurement": [
    "Shuyu Fan; Mengyao Fu;Yushan Zhou; Dibo Hou; Guangxin Zhang;Yunqi Cao; Ultralow-frequency biomechanical energy scavenging and human activity recognition at different positions using a multifunctional wearable energy harvester, IEEE Transactions on Instrumentation and Measurement, 2024, 73(0). SCIE，第一标注"
  ],
  "期刊｜IEEE Transactions on Intelligent Transportation Systems": [
    "Jianxin Zhao; Xinyu Chang; Yanhao Feng; Chi Harold Liu; Ningbo Liu; Participant Selection for Federated Learning With Heterogeneous Data in Intelligent Transport System, IEEE Transactions on Intelligent Transportation Systems, 2023, 24(1): 1106-1115. 第一标注."
  ],
  "期刊｜IEEE Transactions on Knowledge and Data Engineering": [
    "(CCF-A) Jiahui Sun; Haiming Jin; Zhaoxing Yang; Lu Su; Optimizing Long-Term Efficiency and Fairness in Ride-Hailing under Budget Constraint via Joint Order Dispatching and Driver Repositioning, IEEE Transactions on Knowledge and Data Engineering, 2024, 36(7)：1-14. SCIE. 第一标注"
  ],
  "期刊｜IEEE/ASME Transactions on Mechatronics": [
    "Shuyu Fan; Haozhen Chi; Yipei Yao; Chenyang Gao; Dibo Hou; Wei Li; Yunqi Cao. A High-Power-Density Ultralow-Frequency Energy Harvester Based on a Magnetic Rotor With Built-In Eccentricity and Ferromagnetic Fillers, IEEE/ASME Transactions on Mechatronics, 2025.(EarlyAccess)SCIE 第二标注"
  ],
  "期刊｜Journal of Hazardous Materials": [
    "Zhiqiang Ma; Mengyao Fu; Chenyang Gao; Shuyu Fan; Haozhen Chi; Wei Li; Dibo Hou; Yunqi Cao; Trenched microwave resonator integrated with porous PDMS for detection and classification of VOCs with enhanced performance, Journal of Hazardous Materials, 2024, 472: 134553. SCIE. 第一标注"
  ],
  "期刊｜Measurement Science andTechnology": [
    "Mengyao Fu; Zhiqiang Ma; Chenyang Gao; Yi Shen; Xiaoyan Song; Dibo Hou; Yunqi Cao. Detection of Volatile Organic Compounds and Their Mixtures Using an E-nose with Cascaded QCM-based Multi-Virtual SensorArray, Measurement Science andTechnology, 2025, 36, 115109. SCIE 第一标注"
  ],
  "期刊｜Nano Research": [
    "Yunqi Cao; Hongyang Shi; Xiaobo Tan; Nelson Sepúlveda; Nanogenerator-based bidirectional pressure sensor array and its demonstration in underwater invasive species detection, Nano Research, 2023, 16: 11822–11831. SCIE. 第一标注"
  ],
  "期刊｜Sensors andActuators:B. Chemical": [
    "Chenyang Gao; Mengyao Fu; Shuyu Fan; Zhiqiang Ma; Yongkui Tang; Dibo Hou; Yunqi Cao. High-performance virtual sensors array based on a single-chip FBAR for volatile organic compounds (VOCs) detection and classification, Sensors andActuators:B. Chemical, 2025, 422: 136687. SCIE 第二标注"
  ],
  "期刊｜Wearable and Ubiquitous Technologies (IMWUT)": [
    "(CCF-A) Rong Ding; Haiming Jin; Dong Xiang; Xiaocheng Wang; Yongkui Zhang; Dingman Shen; Lu Su;Wentian Hao; MingyuanTao; XinbingWang; Chenghu Zhou; Soil Moisture Sensing with UAV-Mounted IR-UWB Radar and Deep Learning, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT), 2023, 7(1)：1-25. EI. 第二标注"
  ],
  "期刊｜SCIE": [
    "Qiwei Shan; Yunqi Cao; Haozhen Chi; Shuyu Fan; Ziying Zhu; Dibo Hou. A Star-Nose-Inspired Bionic Soft Robot for Nonvisual Spatial Detection and Reconstruction, 2025, 7: 2400601. SCIE 第二标注"
  ],
  "会议｜SIGKDD": [
    "(CCF-A) Jiahui Sun; Haiming Jin; Zhaoxing Yang; Lu Su; Xinbing Wang; Optimizing Long-Term Efficiency and Fairness in Ride-Hailing via Joint Order Dispatching and Driver Repositioning, ACM SIGKDD 2022, Washington, DC, USA, 2022-8-14 至2022-8-18. 第一标注",
    "(CCF-A) Zhangxing Yang; Haiming Jin; Guiyun Fan; Min Lu; Yiran Liu; Xinlang Yue; Hao Pan; Zhe Xu; Guobin Wu;Qun Li; Xiaotong Wang; Jiecheng Guo; Rethinking Order Dispatching in Online Ride-Hailing Platforms, ACM SIGKDD 2024, Barcelona, Spain, 2024-8-25 至2024-8-29. EI. 第一标注"
  ],
  "会议｜INFOCOM": [
    "(CCF-A) Guiyun Fan; Haiming Jin; Yiran Zhao; Yiwen Song; Xiaoying Gan; Jiaxin Ding; Lu Su; Xinbing Wang; Joint Order Dispatch and Charging for Electric Self-Driving Taxi Systems, IEEE INFOCOM 2022, Virtual Conference, 2022-5-2 至 2022-5-5. EI. 第一标注",
    "(CCF-A) Jiahui Sun; Haiming Jin; Rong Ding; Guiyun Fan; Yifei Wei; Lu Su; Multi-Objective Order Dispatch for Urban Crowd Sensing with For-Hire Vehicles, IEEE INFOCOM 2023, NewYork City, NY, USA, 2023-5-17 至2023-5-20. EI. 第一 标注",
    "(CCF-A) Rong Ding; Haiming Jin; Dingman Shen; Rotation Speed Sensing with mmWave Radar, IEEE INFOCOM 2023, New York City, NY, USA, 2023-5-17 至 2023-5-20. EI. 第二标注",
    "(CCF-A) Guiyun Fan; Rong Ding; Xiaocheng Wang; Yichen Zhu; Haiming Jin; m3ASL: ASL Gesture Recognition with Moving mmWave Radar, INFOCOM 2025, London, UnitedKingdom, 2025-5-19 至2025-5-22. EI. 第一标注",
    "(CCF-A) Jiaxi Lv; Guiyun Fan; Xinyue Fu; Jiahui Sun; RongDing; Haiming Jin; mmWave-Based Relay Reflector Reconstruction for LiDAR-Free Around-Corner Human Sensing, INFOCOM 2025, London, United Kingdom, 2025-5-19 至 2025-5-22. EI. 第一标注",
    "(CCF-A) Zhaoxing Yang; Guiyun Fan; Anjie Cao; Yuchen Guo; Wenlong Li; Tianyuan Liu; Haiming Jin, Learning to Accelerate Traffic Allocation over Large-Scale Networks, INFOCOM 2025, London, United Kingdom, 2025-5-19 至 2025-5-22. EI. 第一标注"
  ],
  "会议｜ICDE": [
    "(CCF-A) Yuxiao Ye; Chi Harold Liu; Zipeng Dai; Jianxin Zhao; Ye Yuan; Guoren Wang; Jian Tang; Exploring both Individuality and Cooperation for Air-Ground Spatial Crowdsourcing by Multi-Agent Deep Reinforcement Learning, I EEEICDE 2023,Anaheim, CA, 2023-4-3 至2023-4-7. EI. 第一标注",
    "(CCF-A) Yu Wang; Jingfei Wu; Xingyuan Hua; Chi Harold Liu; Guozheng Li; Jianxin Zhao; Ye Yuan; Guoren Wang; Air-Ground Collaborative Spatial Crowdsourcing with UAV Carriers by Geometric Graph Convolutional Multi-Agent Deep Reinforcement Learning, IEEE ICDE 2023, Anaheim, CA, 2023-4-3 至 2023-4-7. EI. 第一标注"
  ],
  "会议｜ICDCS": [
    "Haiming Jin; Yifei Wei; Zhaoxing Yang; Zirui Liu; Guiyun Fan; Multi-Intersection Management for Connected Autonomous Vehicles by Reinforcement Learning, IEEE ICDCS 2023, Hong Kong, 2023-7-18 至 2023-7-21. EI. 第二标注"
  ],
  "会议｜AAAI": [
    "(CCF-A) Haoyi You; Beichen Yu; Haiming Jin; Zhaoxing Yang; Jiahui Sun; User-Oriented Robust Reinforcement Learning, AAAI 2023, Washington DC, USA, 2023-2-7 至2023-2-14. 第一标注",
    "(CCF-A) Zhaoxing Yang; Haiming Jin; Rong Ding; Haoyi You; Guiyun Fan; Xinbing Wang; Chenghu Zhou; DeCOM: Decomposed Policy for Constrained Cooperative Multi-Agent Reinforcement Learning, AAAI 2023, Washington DC, USA, 2023-2-7 至2023-2-14. EI. 第一标注"
  ],
  "会议｜IJCAI": [
    "(CCF-A)Yichen Zhu; JianYuan; Bo Jiang;Tao Lin; Haiming Jin; Xinbing Wang; Chenghu Zhou; Prediction with Incomplete Data under Agnostic Mask Distribution Shift, IJCAI 2023 ,Macao, S.A.R, 2023-8-19 至2023-8-25. EI. 第三标注"
  ],
  "会议｜CVPR": [
    "(CCF-A) Binhui Xie; Longhui Yuan; Shuang Li; Chi Harold Liu; Xinjing Cheng; Towards Fewer Annotations: Active Learning via Region Impurity and Prediction Uncertainty for Domain Adaptive Semantic Segmentation, IEEE CVPR 2022, New Orleans, 2022-6-19 至 2022-6-24. 第一标注",
    "(CCF-A) Fangrui Lv; Jian Liang; Shuang Li; Bin Zang; Chi Harold Liu; Ziteng Wang; Di Liu; Causality Inspired Representation Learning for Domain Generalization, IEEE CVPR 2022, New Orleans, 2022-6-19 至2022-6-24. EI. 第一标注"
  ],
  "会议｜MobiCom": [
    "(CCF-A) Rong Ding; Haiming Jin; Ningzhi Zhu; Zijie Chen; Yi Fu; Fengyuan Zhu; Guiyun Fan; Xiaohua Tian; Linghe Kong; Bluetooth-Enabled Transparent RF Sensing, MobiCom2025, Hong Kong, China, 2025-11-4 至2025-11-8. EI. 第一标注"
  ],
  "会议｜SenSys": [
    "Rong Ding; Haiming Jin; Jianrong Ding; Xiaocheng Wang; Guiyun Fan; Fengyuan Zhu,; Xiaohua Tian; Linghe Kong; Push the Limit of Single-Chip mmWave Radar-Based Egomotion Estimation with Moving Objects in FoV,ACM Sensys 2023, Istanbul,Turkiye, 2023-11-13 至2023-11-15. EI. 第一标注"
  ],
  "会议｜MobiHoc": [
    "Jiahui Sun; Guiyun Fan; Haiming Jin; Yiwen Song; Tianyuan Liu; Chenhao Ying; Yuan Luo; Jie Li; Multi-Task-Oriented UAV Crowd Sensing with Charging Budget Constraint, ACM MOBIHOC 2024, Athens, Greece, 2024-10-14 至 2024-10-17. EI. 第一标注"
  ],
  "会议｜AAMAS": [
    "Zhaoxing Yang; Haiming Jin; Yao Tang; Guiyun Fan; Risk-Aware Constrained Reinforcement Learning with Non-Stationary Policies, AAMAS 2024, Auckland, New Zealand, 2024-5-6 至2024-5-10. EI. 第一标注"
  ],
  "会议｜IECON": [
    "Shuyu Fan; Haozhen Chi; Chenyang Gao; Wangdi Du; Dibo Hou; Yunqi Cao;A Brake Pair Misalignment Detection Scheme Based on A Battery-Free Electromagnetic-Based Gap Sensor, IEEE IECON 2023, Singapore, 2023-10-16 至 2023-10-19，EI，第一标注",
    "Chenyang Gao; Mengyao Fu; Zhiqiang Ma; Shuyu Fan; Dibo Hou; Yunqi Cao; Metal-organic framework (MOF) based film bulk acoustic resonator (FBAR) sensor for volatile organic compounds (VOCs) detection, IEEE IECON 2024, Chicago, USA, 2024-11-3 至2024-11-6. EI. 第一标注"
  ],
  "会议｜CPCC": [
    "Shanqian Su; Minghao Ding; Ziying Zhu; Yushan Zhou; Shuyu Fan; Dibo Hou; Yunqi Cao. Microfluidic-Based Coplanar Capacitive Micro-Displacement Sensors with High Sensitivity and Large Measurement Range. CPCC 2025, Yibin Sichuan, 2025-7-25 至2025-7-27. EI 第二标注",
    "Shuxun Wang; Haozhen Chi; Shuyu Fan;Yicheng Zhang;Yunqi Cao; Dibo Hou. IoT-Enabled Capacitive Sensing System for Real-Time Detection of Minor Leaks in Bolted Flange Connections. CPCC 2025, Yibin Sichuan, 2025-7-25 至 2025-7-27. EI 第二标注",
    "Yancheng Bi; Zhiqiang Ma; Zhen Zhou; Chenyang Gao; Xiaoyan Song; Dibo Hou; Yunqi Cao. AFalse Alarm-Free Dual-Wavelength Optical Smoke Detector for High-Humidity Underground Pipeline Galleries.CPCC 2025, Yibin Sichuan, 2025-7-25 至2025-7-27. EI 第二标注"
  ],
  "会议｜CAC": [
    "Chenyang Gao; Shuyu Fan; Haozhen Chi; Yipei Yao; Dibo Hou; Yunqi Cao; A high-sensitivity frequency shift detector for QCM-based miniaturized sensing system, CAC 2024, Qingdao, China, 2024-11-1 至2024-11-3. EI 第二标注"
  ],
  "会议｜Transducers": [
    "Mengyao Fu; Dongsheng Li; Chenyang Gao; Zhiqiang Ma; Dibo Hou; Yunqi Cao. MOF/PDMS Hybrid Nanofilm-Based QCM for VOC Selective Virtual Sensing in High-Humidity Environments, 2023 22nd International Conference on Solid-State Sensors, Actuators and Microsystems (Transducers), Kyoto, 2023-6-25至2023-6-29，EI.第二标注"
  ],
};

  const patents = [
  "孙嘉徽; 金海明; 范桂云, 无人机群智感知调度方法、系统、设备及介质，2022-6-1，中国,202211445408.0.",
  "金海明; 范桂云; 张永奎; 王孝诚, 一种基于智能小车和 IR-UWB 雷达的沙地浅埋垃圾检测方法及系统，2023-8-10，中国,202311008795.6.",
  "金海明; 丁榕; 范桂云; 沈定满, 一种基于 FMCW 毫米波雷达的旋转物体转速感知方法和系统，2023-5-15，中国,202310547197.X.",
  "金海明; 丁榕; 范桂云; 王孝诚; 张永奎, 一种土壤湿度感知方法、系统、设备及介质，2023-3-2，中国,202310202422.6.",
  "金海明; 丁榕; 范桂云; 王孝诚, 一种基于 FMCW 毫米波雷达和惯性测量单元的自位姿估计方法和系统，2023-11-7，中国,202311479645.3.",
  "金海明; 范桂云; 吕嘉溪, 基于毫米波雷达的中继反射面重建方法和系统，2024-12-27，中国,202411951313.5.",
  "余北辰；金海明；范桂云，基于非视距感知增强的移动机器人转角导航方法及系统，申请号：CN202511742901.2",
  "金海明；范桂云；丁榕，低功耗、全栈式、多功能无线射频感知系统及方法，申请号：CN202510298821.6",
  "叶语霄; 刘驰; 王昊, 一种保障元宇宙应用信息质量的无人群体感知方法，2023-8-2，中国, 202311056761.4.",
  "徐奕东; 韩锐; 刘驰, 一种面向深度学习模型的边缘端重训练内存配置优化方法，2023-10-26，中国, 202311396860.7.",
  "曹云琦; 傅梦瑶; 高晨阳等, 一种面向高湿度环境的基于石英晶体微天平的挥发性有机化合物传感器，2024-11-26，中国, CN116482187B.",
  "曹云琦; 马志强; 傅梦瑶等, 基于互补开口谐振环结构的挥发性有机物液体、气体传感器及其检测方法，2024-10-01，中国, CN117705828B.",
  "曹云琦; 高晨阳; 范舒羽; 池豪镇; 侯迪波, 一种基于锁相环的谐振器频移检测装置，2025-04-01，中国, CN118631246B.",
  "曹云琦; 姚一培; 范舒羽; 侯迪波; 张光新, 一种能源自持的集成化微型气象监测系统，2025-09-05，中国, CN118837974B.",
  "曹云琦; 傅梦瑶; 高晨阳等, 一种基于级联结构的物理虚拟混合式挥发性有机化合物传感阵列，申请号：202411558186.2"
];

  // ============================
  // Helpers
  // ============================
  function normalize(str) {
    return (str || '').toLowerCase();
  }

  function escapeHtml(str) {
    return String(str)
      .replace(/&/g, "&amp;")
      .replace(/</g, "&lt;")
      .replace(/>/g, "&gt;")
      .replace(/"/g, "&quot;")
      .replace(/'/g, "&#39;");
  }

  function formatPaperText(str) {
    let safe = escapeHtml(str);
    safe = safe.replace(/([（(])\s*CCF\s*[- ]\s*A\s*([)）])/gi, '<strong class="font-extrabold text-bit-green">$1CCF-A$2</strong>');
    safe = safe.replace(/\bCCF\s*[- ]\s*A\b/gi, '<strong class="font-extrabold text-bit-green">CCF-A</strong>');
    return safe;
  }

  function sumCounts(groupObj) {
    return Object.values(groupObj || {}).reduce((acc, arr) => acc + (arr ? arr.length : 0), 0);
  }

  function partitionPapers(groups) {
    const journals = {};
    const conferences = {};
    Object.keys(groups || {}).forEach(k => {
      const arr = groups[k] || [];
      if (k.startsWith("期刊｜")) {
        journals[k.replace(/^期刊｜/, "")] = arr;
      } else if (k.startsWith("会议｜")) {
        conferences[k.replace(/^会议｜/, "")] = arr;
      } else {
        journals[k] = arr;
      }
    });
    return { journals, conferences };
  }

  // Render logic optimized for Journal/Conference split
  
  // ----------------------------
  // Ordering rules (per review comments)
  // - Journals/Conferences: first show 第一标注, then 第二标注, then 第三标注
  // - When mark is equal: order by venue level (heuristic priority list) then by year (desc)
  // ----------------------------

  function getMarkRank(text) {
    const t = (text || '');
    if (/第\s*一\s*标\s*注/i.test(t)) return 0;
    if (/第\s*二\s*标\s*注/i.test(t)) return 1;
    if (/第\s*三\s*标\s*注/i.test(t)) return 2;
    return 3; // unknown / not specified
  }

  function getCcfRank(text) {
    const t = (text || '');
    if (/CCF\s*[- ]?\s*A/i.test(t)) return 0;
    if (/CCF\s*[- ]?\s*B/i.test(t)) return 1;
    if (/CCF\s*[- ]?\s*C/i.test(t)) return 2;
    return 3;
  }

  function getYear(text) {
    const t = (text || '');
    const m = t.match(/(19|20)\d{2}/g);
    if (!m || m.length === 0) return 0;
    const y = parseInt(m[m.length - 1], 10);
    return Number.isFinite(y) ? y : 0;
  }

  // Heuristic venue priority:
  // Note: your data are keyed by venue already; we avoid web lookups and keep rules deterministic.
  const JOURNAL_PRIORITY = [
    /Transactions\s+on\s+Pattern\s+Analysis\s+and\s+Machine\s+Intelligence|TPAMI/i,
    /Transactions\s+on\s+Image\s+Processing|TIP/i,
    /Transactions\s+on\s+Knowledge\s+and\s+Data\s+Engineering|TKDE/i,
    /Transactions\s+on\s+Mobile\s+Computing|TMC/i,
    /Journal\s+on\s+Selected\s+Areas\s+in\s+Communications|JSAC/i,
    /Transactions\s+on\s+Intelligent\s+Transportation\s+Systems|TITS/i,
    /Proceedings\s+of\s+the\s+ACM\s+on\s+Interactive,\s*Mobile,\s*Wearable\s+and\s+Ubiquitous\s+Technologies|IMWUT/i,
    /Transactions\s+on\s+Sensor\s+Networks|TOSN/i,
    /Transactions\s+on\s+Knowledge\s+Discovery\s+from\s+Data|TKDD/i,
    /ACM\s+Transactions\s+on\s+Knowledge\s+Discovery\s+from\s+Data/i,
    /ACM\s+Transactions\s+on\s+Mobile\s+Computing/i,
    /Sensors\s+and\s+Actuators/i,
    /Measurement\s+Science\s+and\s+Technology/i,
    /Electron\s+Device\s+Letters|EDL/i,
    /ACS\s+Applied\s+Materials\s*&\s*Interfaces/i,
    /Advanced\s+Sensor\s+Research/i,
    /Internet\s+of\s+Things|IoT/i
  ];

  const CONF_PRIORITY = [
    /CVPR/i,
    /ICCV/i,
    /ECCV/i,
    /NeurIPS|NIPS/i,
    /ICML/i,
    /ICLR/i,
    /SIGKDD|KDD/i,
    /INFOCOM/i,
    /MobiCom/i,
    /ACM\s+MM|MM\b/i,
    /AAAI/i,
    /IJCAI/i,
    /ICDE/i,
    /ICDCS/i,
    /SenSys/i,
    /MobiHoc/i,
    /AAMAS/i,
    /IPSN/i,
    /Transducers/i,
    /IECON/i
  ];

  function getVenueRank(venue, isJournal) {
    const list = isJournal ? JOURNAL_PRIORITY : CONF_PRIORITY;
    for (let i = 0; i < list.length; i++) {
      if (list[i].test(venue)) return i;
    }
    return 999; // unknown venue goes later
  }

  function comparePaper(a, b, isJournal) {
    const ma = getMarkRank(a);
    const mb = getMarkRank(b);
    if (ma !== mb) return ma - mb;

    // Within same mark:
    // - Conferences: prefer higher CCF tier when available
    // - Journals: we do not have a reliable per-item tier field; use year desc then lexicographic
    if (!isJournal) {
      const ca = getCcfRank(a);
      const cb = getCcfRank(b);
      if (ca !== cb) return ca - cb;
    }

    const ya = getYear(a);
    const yb = getYear(b);
    if (ya !== yb) return yb - ya;

    return String(a).localeCompare(String(b), 'zh-Hans-CN', { sensitivity: 'base' });
  }

  // Render logic optimized for Journal/Conference split
  function renderPaperList(container, groups, query) {
    container.innerHTML = '';
    const q = normalize(query);
    const { journals, conferences } = partitionPapers(groups);

    // Helper to render a large section (e.g. "Journals")
    function renderSection(sectionTitle, bucket, colorClass, isJournal) {
        const venues = Object.keys(bucket).sort((a, b) => {
          const ra = getVenueRank(a, isJournal);
          const rb = getVenueRank(b, isJournal);
          if (ra !== rb) return ra - rb;
          return a.localeCompare(b, 'zh-Hans-CN', { sensitivity: 'base' });
        });

        let visibleCount = 0;

        // Wrapper for the whole section
        const sectionWrapper = document.createElement('div');
        sectionWrapper.className = "mb-8";

        // Section Title (e.g., "期刊")
        const titleEl = document.createElement('h3');
        titleEl.className = `text-lg font-bold text-gray-900 border-l-4 ${colorClass} pl-3 mb-4 uppercase tracking-wide`;
        titleEl.textContent = sectionTitle;
        sectionWrapper.appendChild(titleEl);

        let hasContent = false;

        venues.forEach(venue => {
            const all = (bucket[venue] || []);
            const items = all
              .filter(it => !q || normalize(it).includes(q))
              .slice()
              .sort((x, y) => comparePaper(x, y, isJournal));

            if (items.length === 0) return;
            hasContent = true;
            visibleCount += items.length;

            // Venue Group Wrapper
            const groupDiv = document.createElement('div');
            groupDiv.className = "mb-2";

            // Sticky Header for Venue (e.g., "INFOCOM")
            const vHeader = document.createElement('h4');
            vHeader.className = "sticky-venue-header text-sm font-bold text-gray-700 flex justify-between items-center cursor-default group";
            vHeader.innerHTML = `<span>${escapeHtml(venue)}</span>
                                 <span class="text-xs bg-gray-100 text-gray-500 py-0.5 px-2 rounded-full">${items.length}</span>`;
            groupDiv.appendChild(vHeader);

            // List Items
            const ol = document.createElement('ol');
            ol.className = "space-y-3 mt-2 mb-6 pl-2";

            items.forEach((it, idx) => {
                const li = document.createElement('li');
                li.className = "text-sm text-gray-600 leading-relaxed border-b border-gray-50 pb-2 last:border-0 break-words flex gap-2";
                li.innerHTML = `<span class="font-mono text-gray-400 select-none">${idx + 1}.</span>
                                <span>${formatPaperText(it)}</span>`;
                ol.appendChild(li);
            });
            groupDiv.appendChild(ol);
            sectionWrapper.appendChild(groupDiv);
        });

        if (hasContent) {
          container.appendChild(sectionWrapper);
        }
        return visibleCount;
    }

    const jCount = renderSection("期刊论文 (Journals)", journals, "border-bit-green", true);
    const cCount = renderSection("会议论文 (Conferences)", conferences, "border-blue-600", false);

    if (jCount + cCount === 0) {
        container.innerHTML = '<div class="text-center text-gray-400 py-10">未找到匹配的论文</div>';
    }
  }

  // Render logic for patent list (grant first, then application; unified tags)

  // Render logic for patent list (grant first, then application; unified tags)
  function parsePatent(raw) {
    const t = String(raw || '').trim();
    const compact = t.replace(/\s+/g, '');
    const hasStage = /实质审查阶段/.test(t);
    const isGranted = /\bCN\s*\d+\s*B\b/i.test(t) || /CN\d+B/i.test(compact) || /授权号|授权日期/.test(t);
    const status = isGranted ? 'granted' : 'pending';

    // Try parse a date for sorting (yyyy-mm-dd or yyyy.mm.dd)
    let dateScore = 0;
    const dm = t.match(/(19|20)\d{2}[-./](0?\d|1[0-2])[-./](0?\d|[12]\d|3[01])/);
    if (dm) {
      const s = dm[0].replace(/\./g, '-').replace(/\//g, '-');
      const parts = s.split('-').map(x => String(x).padStart(2, '0'));
      dateScore = parseInt(parts[0] + parts[1] + parts[2], 10);
    }

    // Normalize display text:
    let display = t
      .replace(/\[P\]/g, '')
      .replace(/（\s*实质审查阶段\s*）/g, '')
      .replace(/实质审查阶段/g, '')
      .replace(/\s+/g, ' ')
      .trim();

    return { raw: t, display, status, hasStage, dateScore };
  }

  function renderPatentList(container, items, query) {
    container.innerHTML = '';
    const q = normalize(query);

    const prepared = (items || [])
      .map(parsePatent)
      .filter(p => !q || normalize(p.raw).includes(q))
      .sort((a, b) => (b.dateScore - a.dateScore) || a.display.localeCompare(b.display, 'zh-Hans-CN', { sensitivity: 'base' }));

    if (prepared.length === 0) {
      container.innerHTML = '<div class="text-center text-gray-400 py-10">未找到匹配的专利</div>';
      return;
    }

    const ol = document.createElement('ol');
    ol.className = 'space-y-3';

    prepared.forEach((p, i) => {
      const li = document.createElement('li');
      li.className = 'text-sm text-gray-700 leading-relaxed border-b border-gray-100 pb-3 last:border-0 break-words flex gap-3';

      const idx = i + 1;

      // 不在条目中标注“已授权 / 申请中 / 实质审查”等状态信息，仅保留专利条目本身
      const cleaned = (p.display || '')
        .replace(/实质审查阶段/g, '')
        .replace(/实质审查/g, '')
        .replace(/申请中/g, '')
        .replace(/已授权/g, '')
        .replace(/\s+/g, ' ')
        .replace(/，\s*\)/g, '）')
        .replace(/\(\s*，/g, '(')
        .trim();

      li.innerHTML = `
        <span class="flex-shrink-0 w-6 h-6 rounded-full bg-blue-50 text-blue-700 border border-blue-200 text-xs flex items-center justify-center mt-0.5">${idx}</span>
        <div class="min-w-0">
          <div class="text-sm text-gray-700 leading-relaxed break-words">${escapeHtml(cleaned)}</div>
        </div>
      `;

      ol.appendChild(li);
    });

    container.appendChild(ol);
  }

function updateAcademicTotals() {
    const paperTotalEl = document.getElementById('paper-total');
    const patentTotalEl = document.getElementById('patent-total');
    if (paperTotalEl) paperTotalEl.textContent = sumCounts(paperGroups);
    if (patentTotalEl) patentTotalEl.textContent = (patents || []).length;
  }

  // ============================
  // Boot
  // ============================
  document.addEventListener('DOMContentLoaded', function () {
    updateAcademicTotals();

    const paperContainer = document.getElementById('paper-list');
    const patentContainer = document.getElementById('patent-list');
    const paperSearch = document.getElementById('paper-search');
    const patentSearch = document.getElementById('patent-search');

    if (paperContainer) {
      renderPaperList(paperContainer, paperGroups, '');
      if (paperSearch) {
        paperSearch.addEventListener('input', (e) => {
          renderPaperList(paperContainer, paperGroups, e.target.value || '');
        });
      }
    }

    if (patentContainer) {
      renderPatentList(patentContainer, patents, '');
      if (patentSearch) {
        patentSearch.addEventListener('input', (e) => {
          renderPatentList(patentContainer, patents, e.target.value || '');
        });
      }
    }
  });
})();
</script>
  
    <script id="project-overview-figure-size">
(function () {
  function applyProjectOverviewFigureSize() {
    var card = document.getElementById("projectOverviewFigureCard");
    var img = document.getElementById("projectOverviewFigureImg");
    if (!card || !img) return;

    var maxW = Number(window.PROJECT_OVERVIEW_FIGURE_MAX_WIDTH_REM || 0);
    var maxH = Number(window.PROJECT_OVERVIEW_FIGURE_MAX_HEIGHT_PX || 0);

    if (maxW > 0) card.style.maxWidth = maxW + "rem";
    if (maxH > 0) img.style.maxHeight = maxH + "px";
  }

  document.addEventListener("DOMContentLoaded", applyProjectOverviewFigureSize);
})();
    </script>

    <script id="exchange-carousel-script">
(function () {
  var items = [
    { img: "site_assets/images/com_01.png", alt: "学术交流照片 1", text: "项目组成员金海明（左二）、丁榕（左一）参与MOBICOM 2025会议" },
    { img: "site_assets/images/com_02.png", alt: "学术交流照片 2", text: "项目组成员杨兆星参与KDD 2024会议" },
    { img: "site_assets/images/com_03.png", alt: "学术交流照片 3", text: "项目组成员金海明、丁榕、祝宁参与IPSN 2024会议" },
    { img: "site_assets/images/com_04.png", alt: "学术交流照片 4", text: "项目组成员金海明、丁榕参与SenSys 2023会议" },
    { img: "site_assets/images/com_05.png", alt: "学术交流照片 5", text: "项目组成员谢斌辉、吕芳蕊线上参与CVPR 2022会议" },
    { img: "site_assets/images/com_06.png", alt: "学术交流照片 6", text: "项目组成员叶语霄参与ICDE 2023会议" },
    { img: "site_assets/images/com_07.png", alt: "学术交流照片 7", text: "香港城市大学吴大鹏教授访问北京理工大学" }
  ];

  function $(id) { return document.getElementById(id); }

  var imgEl, textEl, counterEl, prevBtn, nextBtn;
  var idx = 0;

  function render() {
    if (!imgEl || !textEl || !counterEl) return;
    var it = items[idx];
    imgEl.src = it.img;
    imgEl.alt = it.alt;
    textEl.textContent = it.text;
    counterEl.textContent = (idx + 1) + " / " + items.length;
  }

  function prev() {
    idx = (idx - 1 + items.length) % items.length;
    render();
  }
  function next() {
    idx = (idx + 1) % items.length;
    render();
  }

  document.addEventListener("DOMContentLoaded", function () {
    imgEl = $("exchangeImage");
    textEl = $("exchangeText");
    counterEl = $("exchangeCounter");
    prevBtn = $("exchangePrev");
    nextBtn = $("exchangeNext");

    if (!imgEl || !textEl || !counterEl || !prevBtn || !nextBtn) return;

    prevBtn.addEventListener("click", prev);
    nextBtn.addEventListener("click", next);

    // Keyboard support
    document.addEventListener("keydown", function (e) {
      if (e.key === "ArrowLeft") prev();
      if (e.key === "ArrowRight") next();
    });

    render();
  });
})();
    </script>

    <script id="talent-ui-script">
(function () {
  function byId(id) { return document.getElementById(id); }

  function setup(prefix) {
    var totalEl = byId("talent-" + prefix + "-total");
    var searchEl = byId("talent-" + prefix + "-search");
    var listWrap = byId("talent-" + prefix + "-list");
    if (!totalEl || !searchEl || !listWrap) return;

    var items = Array.prototype.slice.call(listWrap.querySelectorAll("li"));
    totalEl.textContent = String(items.length);

    function applyFilter() {
      var q = (searchEl.value || "").trim().toLowerCase();
      items.forEach(function (li) {
        var t = (li.textContent || "").toLowerCase();
        li.style.display = (!q || t.indexOf(q) !== -1) ? "" : "none";
      });
    }

    searchEl.addEventListener("input", applyFilter);
  }

  document.addEventListener("DOMContentLoaded", function () {
    setup("postdoc");
    setup("phd");
    setup("master");
  });
})();
    </script>

</body>
</html>