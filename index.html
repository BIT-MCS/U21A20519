<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8"/>
    <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
    <title>
      边缘环境群体智能感知与能力增强关键技术结项成果展示
    </title>
    <script src="https://cdn.tailwindcss.com">
  </script>
    <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@300;400;500;700&amp;display=swap" rel="stylesheet"/>
    <style>
   body { font-family: 'Noto Sans SC', sans-serif; }
        .bit-green { color: #006439; }
        .bg-bit-green { background-color: #006439; }
        .section-title { position: relative; display: inline-block; margin-bottom: 2rem; }
        .section-title::after { content: ''; display: block; width: 60px; height: 4px; background: #006439; margin-top: 8px; }
        .img-placeholder { background-color: #e2e8f0; display: flex; align-items: center; justify-content: center; color: #64748b; font-weight: bold; border: 2px dashed #cbd5e1; }
        .timeline-item { position: relative; padding-left: 1.5rem; border-left: 2px solid #e5e7eb; padding-bottom: 1.5rem; }
        .timeline-item::before { content: ''; position: absolute; left: -0.4rem; top: 0.2rem; width: 0.8rem; height: 0.8rem; background: #006439; border-radius: 50%; }

        /* -------- Visual readability improvements -------- */
        html { scroll-behavior: smooth; }
        body { -webkit-font-smoothing: antialiased; text-rendering: optimizeLegibility; font-size: 16px; line-height: 1.75; }
        @media (min-width: 768px) { body { font-size: 16.5px; } }
        @media (min-width: 1024px) { body { font-size: 17px; } }
        p, li { line-height: 1.75; }
        .text-bit-green { color: #006439; }
        .border-bit-green { border-color: #006439; }
        .hover\:text-bit-green:hover { color: #006439; }

        /* -------- Custom Scrollbar for Lists -------- */
        .custom-scrollbar::-webkit-scrollbar {
            width: 6px;
        }
        .custom-scrollbar::-webkit-scrollbar-track {
            background: #f1f1f1;
            border-radius: 4px;
        }
        .custom-scrollbar::-webkit-scrollbar-thumb {
            background: #cbd5e1;
            border-radius: 4px;
        }
        .custom-scrollbar::-webkit-scrollbar-thumb:hover {
            background: #94a3b8;
        }

        /* Venue headers within the paper list (not sticky; scrolls with content) */
        .sticky-venue-header {
            position: relative; /* keep in normal flow */
            top: auto;
            backdrop-filter: none;
            background-color: transparent;
            z-index: auto;
            padding-top: 0.35rem;
            padding-bottom: 0.35rem;
            margin-top: 0.25rem;
            border-bottom: 1px solid #e5e7eb;
        }

/* Long text wrapping */
        .break-words { overflow-wrap: anywhere; word-break: break-word; }
  
        /* -------- 
        /* -------- Reference-style ordered list: [1] [2] ... -------- */
        ol.ref-list { list-style: none; counter-reset: refitem; padding-left: 0; margin: 0; }
        ol.ref-list > li { position: relative; padding-left: 2.2rem; }
        ol.ref-list > li::before {
          counter-increment: refitem;
          content: "[" counter(refitem) "]";
          position: absolute;
          left: 0;
          top: 0;
          width: 1.8rem;
          text-align: right;
          color: #9ca3af;
          font-weight: 600;
        }
        /*------- Figure reference superscripts -------- */
        .fig-ref-sup { font-size: 0.75em; vertical-align: super; color: #006439; margin-left: 0.25rem; }
        .icon-btn { display: inline-flex; align-items: center; justify-content: center; width: 42px; height: 42px; border-radius: 9999px; border: 1px solid #e5e7eb; background: rgba(255,255,255,0.9); transition: transform 120ms ease, background 120ms ease; }
        .icon-btn-lg { width: 52px; height: 52px; }
        @media (min-width: 768px) { .icon-btn-lg { width: 56px; height: 56px; } }
        .icon-btn:hover { background: rgba(249,250,251,1); transform: translateY(-1px); }
        .icon-btn:active { transform: translateY(0px); }
        .icon-btn:focus { outline: none; box-shadow: 0 0 0 3px rgba(0,100,57,0.15); border-color: #006439; }
</style>
    <link href="site_assets/BIT.png" id="site-favicon" rel="icon"/>
    <script id="site-asset-config">
   window.SITE_ASSETS = window.SITE_ASSETS || {};
window.SITE_ASSETS.favicon = window.SITE_ASSETS.favicon || 'site_assets/BIT.png';
window.PROJECT_DEMO_VIDEO_URL = window.PROJECT_DEMO_VIDEO_URL || 'site_assets/videos/display_video.mp4';

// ======================== 视频展示配置（推荐：GitHub Releases 托管）========================
// 说明：GitHub 仓库本体禁止推送 >100 MiB 的单文件；500MB 视频不适合放在仓库里。
// 建议将视频作为 Release asset 上传（单文件 <2 GiB），然后把下方直链填进去。
// 直链格式：https://github.com/<org>/<repo>/releases/download/<tag>/<file>.mp4
// 例子：   https://github.com/BIT-MCS/Hangzhou/releases/download/v1/demo.mp4
window.PROJECT_DEMO_VIDEO_DIRECT_URL = 'https://github.com/BIT-MCS/Hangzhou/releases/download/v1/1080.mp4 ';

// 若视频无法播放，可提供一个“打开原视频/下载”的兜底链接（可填同一个 Release 直链或公开视频页）
window.PROJECT_DEMO_VIDEO_FALLBACK_OPEN = 'https://github.com/BIT-MCS/Hangzhou/releases/download/v1/1080.mp4 ';

// ======================== 项目概况“总体框架图”尺寸配置 =========================
// 说明：以下两个参数仅影响“项目概况”部分的“图片+边框整体”尺寸，便于你在不改动布局的情况下快速微调。
// - MAX_WIDTH_REM：整体最大宽度（单位 rem）。示例：80 = 80rem（约1280px，取决于根字体大小）
// - MAX_HEIGHT_PX：图片最大高度（单位 px）。
window.PROJECT_OVERVIEW_FIGURE_MAX_WIDTH_REM = window.PROJECT_OVERVIEW_FIGURE_MAX_WIDTH_REM || 84;
window.PROJECT_OVERVIEW_FIGURE_MAX_HEIGHT_PX = window.PROJECT_OVERVIEW_FIGURE_MAX_HEIGHT_PX || 560;
// ============================================================================

// =========================================================================================
// 说明：该链接使用 B 站移动端嵌入播放器（界面更简洁，通常不会触发点击跳转）。
  // 如需改用 PC 端播放器，可使用：https://player.bilibili.com/player.html?aid=115836425603516&bvid=BV1diiEBTE6D&cid=35184971540&p=1&autoplay=0&danmaku=0

window.SITE_ASSETS.achievementFallback = window.SITE_ASSETS.achievementFallback || 'site_assets/images/overview.png';
window.SITE_ASSETS.achievementImages = Object.assign({}, {
  "res01_method": "site_assets/images/res01_method.png",
  "res01_effect": "site_assets/images/res01_effect.png",
  "res02_method": "site_assets/images/res02_method.png",
  "res02_effect": "site_assets/images/res02_effect.png",
  "res03_method": "site_assets/images/res03_method.png",
  "res03_effect": "site_assets/images/res03_effect.png",
  "res04_method": "site_assets/images/res04_method.png",
  "res04_effect": "site_assets/images/res04_effect.png",
  "res05_method": "site_assets/images/res05_method.png",
  "res05_effect": "site_assets/images/res05_effect.png",
  "res06_method": "site_assets/images/res06_method.png",
  "res06_effect": "site_assets/images/res06_effect.png",
  "res07_method": "site_assets/images/res07_method.png",
  "res07_effect": "site_assets/images/res07_effect.png",
  "res08_method": "site_assets/images/res08_method.png",
  "res08_effect": "site_assets/images/res08_effect.png"
}, window.SITE_ASSETS.achievementImages || {});
  </script>
  </head>
  <body class="bg-gray-50 text-gray-800">
    <nav class="bg-white shadow-md fixed w-full z-50">
      <div class="container mx-auto px-6 h-20 flex justify-between items-center">
        <div class="flex items-center space-x-3">
          <div>
            <img class="w-14 h-14 rounded-full flex items-center justify-center text-white font-bold" src="site_assets/BIT.png" alt="Logo 1"/>
          </div>
          <div>
            <img class="w-14 h-14 rounded-full flex items-center justify-center text-white font-bold" src="site_assets/ZJU.png" alt="Logo 2"/>
          </div>
          <div>
            <img class="w-14 h-14 rounded-full flex items-center justify-center text-white font-bold" src="site_assets/SJTU.png" alt="Logo 3"/>
          </div>
        </div>
        <div class="hidden md:flex space-x-8 text-gray-600 font-medium">
          <a class="hover:text-bit-green transition" href="#info">
            项目概况
          </a>
          <a class="hover:text-bit-green transition" href="#achievements">学术贡献</a>
          <a class="hover:text-bit-green transition" href="#applications">
            应用演示
          </a>
          <a class="hover:text-bit-green transition" href="#exchange">
            学术交流
          </a>
          <a class="hover:text-bit-green transition" href="#talent">
            学生培养
          </a>
          <a class="hover:text-bit-green transition" href="#papers">
            学术成果
          </a>
        </div>
      </div>
    </nav>
    <header class="relative h-[500px] flex items-center justify-center bg-gray-900 text-white pt-20 overflow-hidden">
      <div class="absolute inset-0 bg-gradient-to-r from-green-900 to-black opacity-80 z-10">
      </div>
      <!-- Header background: three gate images (replace the src paths with your school gate photos) -->
      <!-- NOTE: Use flex + 1px overlap to eliminate hairline seams on some browsers/zoom levels -->
      <div class="absolute inset-0 z-0 flex bg-gray-900">
        <img alt="校门 1（可替换）" class="block w-1/3 h-full object-cover" src="site_assets/images/gate_3.png"/>
        <img alt="校门 2（可替换）" class="block w-1/3 h-full object-cover -ml-px" src="site_assets/images/gate_2.png"/>
        <img alt="校门 3（可替换）" class="block w-1/3 h-full object-cover -ml-px" src="site_assets/images/gate_1.png"/>
      </div>
      <div class="relative z-20 text-center container px-6">
        <span class="bg-bit-green px-3 py-1 text-sm rounded uppercase tracking-wider mb-4 inline-block">
          国家自然科学基金｜区域创新发展联合基金｜重点支持项目
        </span>
        <h1 class="text-4xl md:text-5xl font-bold mb-6 leading-tight">
          边缘环境群体智能感知与能力增强关键技术
        </h1>
        <p class="text-base text-gray-300 max-w-3xl mx-auto mb-2">
          Key Technologies for Intelligent Mobile Crowdsensing and Capability Enhancement on Edge
        </p>
        <div class="mt-4 max-w-5xl mx-auto text-gray-300">
          <div class="flex flex-col md:flex-row md:items-center md:justify-center gap-2 md:gap-4 text-base md:text-lg leading-relaxed">
            <span class="inline-flex items-center justify-center px-3 py-1 rounded-full bg-white/5 border border-white/10">
              牵头单位：北京理工大学
            </span>
            <span class="hidden md:inline text-gray-500">
              |
            </span>
            <span class="inline-flex items-center justify-center px-3 py-1 rounded-full bg-white/5 border border-white/10">
              参与单位：浙江大学、上海交通大学
            </span>
            <span class="hidden md:inline text-gray-500">
              |
            </span>
            <span class="inline-flex items-center justify-center px-3 py-1 rounded-full bg-white/5 border border-white/10">
              项目编号：U21A20519
            </span>
          </div>
        </div>
      </div>
    </header>
    
    <section class="py-20 bg-white" id="info">
      <div class="container mx-auto px-6">
        <h2 class="text-4xl font-bold text-gray-900 mb-2 section-title">01 项目概况</h2>
        <div class="mt-2">
          <div class="inline-flex flex-wrap items-center gap-x-2 gap-y-1 rounded-full bg-gray-50 border border-gray-200 px-4 py-2">
            <span class="text-sm text-gray-600">项目周期</span>
            <span class="text-sm font-semibold text-gray-900">2022年01月01日 - 2025年12月31日</span>
          </div>
        </div>

        <div class="mt-10 flex flex-col gap-10">
          <div class="max-w-5xl mx-auto">
            <p class="mb-4">
            本项目紧扣浙江省提升数字治理能力及反恐防暴应急处置的核心需求，聚焦复杂边缘环境中的“移动群体感知”与能力增强关键课题，成功突破了群体部署难、数据感知繁、计算能力弱三大技术瓶颈，解决了公共安全事件应急处置中跨场景适配、资源协同调度、复杂数据高效处理等核心问题。
            </p>
            <p class="mb-4">
            本网站为国家自然科学基金区域创新发展联合基金重点支持项目“边缘环境群体智能感知与能力增强关键技术”（项目编号：U21A20519）的结项成果展示平台。项目围绕<strong>“移动群体部署—移动群体感知—移动群体计算”</strong>主线，形成4大研究内容与8项关键技术创新突破，构建了覆盖传感器研制、算法建模到系统验证的完整技术体系。网站集成典型示范场景“杭州世纪中心异常包裹应急处置仿真”，直观展示人机协同移动群体感知与边缘智能在反恐防暴及公共安全事件处置中的全流程实证效果，并系统汇总项目论文、专利与软件著作权等学术与知识产权产出，为成果对外交流与推广提供便捷渠道。项目执行期间，累计发表论文47篇（期刊论文20篇、会议论文27篇），发表 TKDE、TMC、JSAC 等高水平期刊论文以及 INFOCOM、AAAI、CVPR 等 CCF-A 类国际顶级会议发表论文共20篇；申请/授权国家发明专利15项。
            </p>
            <p>
            项目相关技术研发形成的应急处置系统，严格遵循多项公共安全领域国家标准，为省级应急指挥平台技术支撑、市县级应急预案推演及跨部门救援协同提供关键技术支撑，有效提升省—市两级应急协同能力，为浙江全域应急响应智能化建设及反恐防暴工作提供坚实技术保障。
            </p>
          </div>

          <div id="projectOverviewFigureCard" class="bg-white p-4 md:p-6 rounded-xl border border-gray-200 shadow-sm w-auto mx-auto">
            <img alt="项目总图" id="projectOverviewFigureImg" class="w-auto h-auto mx-auto object-contain rounded-md border border-dashed border-gray-300 bg-white" data-asset="project_overview" onerror="this.style.display='none'; this.insertAdjacentHTML('afterend','&lt;div class=&quot;w-full rounded-md border border-dashed border-gray-300 bg-gray-50 text-gray-500 text-sm flex items-center justify-center py-16&quot;&gt;此处放置项目总图（请替换图片资源）&lt;/div&gt;');" src="site_assets/images/overview.png" style="max-height: 560px;">
            <p class="mt-3 text-center text-sm text-gray-500">图1：项目总体框架图</p>
          </div>

        </div>
      </div>
    </section>
    <section class="py-20 bg-gray-100" id="achievements">
      <div class="container mx-auto px-6">
        <h2 class="text-3xl font-bold text-gray-900 section-title">
          02 重要学术贡献
        </h2>
        <div class="space-y-16">
          <div class="bg-white/0">
            <div class="mb-5">
              <h3 class="text-xl font-bold text-gray-900">
                学术贡献一：大规模移动人机群体部署技术
              </h3>
              <p class="text-base text-gray-600 mt-2 leading-relaxed">提出了经验熵驱动的迭代趋优人机优选与分布鲁棒机群部署方法，构建了兼顾长期感知收益与群体公平性的合作马尔科夫博弈模型；设计了带充电预算约束的多任务协同轨迹规划技术，通过原始–对偶优化机制与多智能体强化学习框架（JDRL），有效解决了复杂动态环境下的资源受限调度与不确定性适应难题，实现了大规模人机群体的鲁棒协同与高效持续感知。</p>
            </div>
            <div class="space-y-12">
              <div class="bg-white rounded-xl shadow-lg overflow-hidden border border-gray-200">
                <div class="p-6 border-b border-gray-100">
                  <div class="flex items-center mb-2">
                    <span class="bg-bit-green text-white text-xs font-bold px-2 py-1 rounded mr-3">
                      成果 01
                    </span>
                    <h3 class="text-xl font-bold text-gray-800">
                      互补增强的最小经验熵鲁棒人机优选
                    </h3>
                  </div>
                  <p class="text-gray-600 text-base leading-relaxed mt-3">提出了基于经验熵驱动迭代趋优与分布鲁棒优化的移动人机群体协同部署技术。该技术以长期感知收益与群体公平性的联合博弈为基础，构建合作马尔科夫博弈模型与多智能体强化学习框架；结合演员–评论家网络结构与价值函数分解机制，推演多环境不确定性下的鲁棒决策边界，通过融合迭代趋优训练算法与增强贝尔曼算子，实现了公平性与效率的互补增强，大幅提升复杂动态环境下的样本效率与决策鲁棒性。基于该技术，群智感知平台可实现跨城市、多场景下人机资源的高效协同配置，在成都市、纽约市等真实城市感知数据集测试中，系统感知收益与经验熵指标分别较现有最优方法提升10.2%和11.9%；在环境分布偏移与感知需求剧烈变化的复杂工况下，平均感知收益提升8%–14%，有效解决了大规模感知任务中资源调度低效与不均衡的难题，为智慧城市治理与应急响应提供了核心算法支撑。</p>
                </div>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-0">
                  <div class="p-4 bg-gray-50 border-r border-gray-100">
                    <img alt="成果01 方法示意" class="h-64 w-full object-contain bg-white rounded" data-asset="res01_method" src="site_assets/images/placeholder.png"/>
                    <p class="text-center text-sm text-gray-500 mt-2">
                      图2-1：迭代趋优人群选择与部署策略框架 <sup class="fig-ref-sup">[1]</sup>
                    </p>
                  </div>
                  <div class="p-4 bg-gray-50">
                    <img alt="成果01 效果示意" class="h-64 w-full object-contain bg-white rounded" data-asset="res01_effect" src="site_assets/images/placeholder.png"/>
                    <p class="text-center text-sm text-gray-500 mt-2">
                      图2-2：分布式鲁棒机群选择框架 <sup class="fig-ref-sup">[5]</sup>
                    </p>
                  </div>
                </div>
                <div class="p-6 bg-white border-t border-gray-100">
                  <h4 class="text-sm font-bold text-gray-900 mb-3">
                    代表性学术成果
                  </h4>
                  <ul class="text-sm text-gray-700 space-y-4 leading-relaxed">
                    <li>
                      <ol class="mt-2 ref-list pl-0 space-y-2">
                        <li class="break-words"><strong class="font-semibold text-gray-900">(CCF-A)</strong> Jiahui Sun; Haiming Jin; Zhaoxing Yang; Lu Su; Xinbing Wang; Optimizing Long-Term Efficiency and Fairness in Ride-Hailing via Joint Order Dispatching and Driver Repositioning, ACM SIGKDD 2022, Washington, DC, USA, 2022-8-14至2022-8-18. 第一标注 </li>
                        <li class="break-words"><strong class="font-semibold text-gray-900">(CCF-A)</strong> Guiyun Fan; Haiming Jin; Yiran Zhao; Yiwen Song; Xiaoying Gan; Jiaxin Ding; Lu Su; Xinbing Wang; Joint Order Dispatch and Charging for Electric Self-Driving Taxi Systems, IEEE INFOCOM 2022, Virtual Conference, 2022-5-2至2022-5-5. EI. 第一标注</li>
                        <li class="break-words"><strong class="font-semibold text-gray-900">(CCF-A)</strong> Haoyi You; Beichen Yu; Haiming Jin; Zhaoxing Yang; Jiahui Sun; User-Oriented Robust Reinforcement Learning, AAAI 2023, Washington DC, USA, 2023-2-7至2023-2-14. 第一标注</li>
                        <li class="break-words"><strong class="font-semibold text-gray-900">(CCF-A)</strong> Zhaoxing Yang; Haiming Jin; Rong Ding; Haoyi You; Guiyun Fan; Xinbing Wang; Chenghu Zhou; DeCOM: Decomposed Policy for Constrained Cooperative Multi-Agent Reinforcement Learning, AAAI 2023, Washington DC, USA, 2023-2-7至2023-2-14. EI. 第一标注</li>
                        <li class="break-words"><strong class="font-semibold text-gray-900">(CCF-A)</strong> Jiahui Sun; Haiming Jin; Rong Ding; Guiyun Fan; Yifei Wei; Lu Su; Multi-Objective Order Dispatch for Urban Crowd Sensing with For-Hire Vehicles, IEEE INFOCOM 2023, New York City, NY, USA, 2023-5-17至2023-5-20. EI. 第一标注 </li>
                      </ol>
                    </li>
                  </ul>
                </div>
              </div>
              <div class="bg-white rounded-xl shadow-lg overflow-hidden border border-gray-200">
                <div class="p-6 border-b border-gray-100">
                  <div class="flex items-center mb-2">
                    <span class="bg-bit-green text-white text-xs font-bold px-2 py-1 rounded mr-3">
                      成果 02
                    </span>
                    <h3 class="text-xl font-bold text-gray-800">
                      智能协同的分布式动态群体轨迹规划
                    </h3>
                  </div>
                  <p class="text-gray-600 text-base leading-relaxed mt-3">提出了基于多任务约束多智能体强化学习与原始–对偶优化的移动机群协同轨迹规划技术。该技术以带充电预算约束的合作马尔科夫博弈模型为基础，构建涵盖移动、感知与充电行为的联合决策空间；结合分布式多智能体强化学习（MARL）框架推演群体协同策略，通过融合原始–对偶优化机制动态调节充电约束权重，实现了在严格满足系统长期能量预算约束前提下的多任务覆盖效率最大化 。基于该技术，无人机群可实现复杂动态城市环境下的持续自主感知与调度，在真实应急事件数据场景下，长期感知效益较现有策略提升12%–25% ；对多任务并发与频繁切换等复杂工况，能够保持稳定的预算控制与覆盖性能，未出现明显的预算违背或覆盖退化现象，为智慧城市应急响应与大规模人机协同提供了关键技术支撑 。</p>
                </div>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-0">
                  <div class="p-4 bg-gray-50 border-r border-gray-100">
                    <img alt="成果02 方法示意" class="h-64 w-full object-contain bg-white rounded" data-asset="res02_method" src="site_assets/images/placeholder.png"/>
                    <p class="text-center text-sm text-gray-500 mt-2">
                      图2-3：多任务约束多智能体强化学习群体轨迹规划策略框架 <sup class="fig-ref-sup">[2]</sup>
                    </p>
                  </div>
                  <div class="p-4 bg-gray-50">
                    <img alt="成果02 效果示意" class="h-64 w-full object-contain bg-white rounded" data-asset="res02_effect" src="site_assets/images/placeholder.png"/>
                    <p class="text-center text-sm text-gray-500 mt-2">
                      图2-4：不同预算下策略训练收敛曲线对比图 <sup class="fig-ref-sup">[2]</sup>
                    </p>
                  </div>
                </div>
                <div class="p-6 bg-white border-t border-gray-100">
                  <h4 class="text-sm font-bold text-gray-900 mb-3">
                    代表性学术成果
                  </h4>
                  <ul class="text-sm text-gray-700 space-y-4 leading-relaxed">
                    <li>
                      <ol class="mt-2 ref-list pl-0 space-y-2">
                        <li class="break-words"><strong class="font-semibold text-gray-900">(CCF-A)</strong> Jiahui Sun; Haiming Jin; Zhaoxing Yang; Lu Su; Optimizing Long-Term Efficiency and Fairness in Ride-Hailing under Budget Constraint via Joint Order Dispatching and Driver Repositioning, IEEE Transactions on Knowledge and Data Engineering, 2024, 36(7)：1-14. SCIE. 第一标注</li>
                        <li class="break-words"><strong class="font-semibold text-gray-900">(CCF-A)</strong> Zhangxing Yang; Haiming Jin; Guiyun Fan; Min Lu; Yiran Liu; Xinlang Yue; Hao Pan; Zhe Xu; Guobin Wu;Qun Li; Xiaotong Wang; Jiecheng Guo; Rethinking Order Dispatching in Online Ride-Hailing Platforms, ACM SIGKDD 2024, Barcelona, Spain, 2024-8-25至2024-8-29. EI. 第一标注</li>
                        <li class="break-words"><strong class="font-semibold text-gray-900">(CCF-A)</strong> Guiyun Fan; Rong Ding; Xiaocheng Wang; Yichen Zhu; Haiming Jin; m3ASL: ASL Gesture Recognition with Moving mmWave Radar, INFOCOM 2025, London, United Kingdom, 2025-5-19至2025-5-22. EI. 第一标注</li>
                        <li class="break-words"><strong class="font-semibold text-gray-900">(CCF-A)</strong> Jiaxi Lv; Guiyun Fan; Xinyue Fu; Jiahui Sun; Rong Ding; Haiming Jin; mmWave-Based Relay Reflector Reconstruction for LiDAR-Free Around-Corner Human Sensing, INFOCOM 2025, London, United Kingdom, 2025-5-19至2025-5-22. EI. 第一标注</li>
                        <li class="break-words">Jiahui Sun; Guiyun Fan; Haiming Jin; Yiwen Song; Tianyuan Liu; Chenhao Ying; Yuan Luo; Jie Li; Multi-Task-Oriented UAV Crowd Sensing with Charging Budget Constraint, ACM MOBIHOC 2024, Athens, Greece, 2024-10-14至2024-10-17. EI. 第一标注</li>
                      </ol>
                    </li>
                  </ul>
                </div>
              </div>
            </div>
          </div>
          <div class="bg-white/0">
            <div class="mb-5">
              <h3 class="text-xl font-bold text-gray-900">
                学术贡献二：面向场景迁移的多模数据融合与压缩感知
              </h3>
              <p class="text-base text-gray-600 mt-2 leading-relaxed">提出了语言-视觉联合学习范式（BorLan）与基于区域纯度及预测不确定性的主动迁移学习方法（RIPU），通过显式语义对齐与跨域采样策略显著提升了少样本条件下的模型泛化能力；构建了因果启发的表征学习框架与内存超参数自适应集成优化机制，实现了任务驱动的高鲁棒特征压缩与资源受限下的感知模型快速重训练，攻克了边缘侧多模态数据跨场景适配难与响应迟缓的瓶颈。</p>
            </div>
            <div class="space-y-12">
              <div class="bg-white rounded-xl shadow-lg overflow-hidden border border-gray-200">
                <div class="p-6 border-b border-gray-100">
                  <div class="flex items-center mb-2">
                    <span class="bg-bit-green text-white text-xs font-bold px-2 py-1 rounded mr-3">
                      成果 03
                    </span>
                    <h3 class="text-xl font-bold text-gray-800">
                      面向场景模型迁移的多模态数据融合
                    </h3>
                  </div>
                  <p class="text-gray-600 text-base leading-relaxed mt-3">提出了基于语言-视觉联合学习范式与主动迁移学习的多模态数据融合技术。该技术以视觉-文本表征的显式语义对齐机制为基础，提取跨模态本征特征并构建统一的语言-视觉关联模型（BorLan）；结合分布感知知识迁移策略反演图像表征在多维文本分布中的演化规律，通过融合基于区域纯度与预测不确定性的跨域采样算法（RIPU），大幅提升了少样本及零样本条件下的模型迁移精度与多变场景适配能力。基于该技术，智能感知系统可实现复杂开放环境下语义信息的深度融合与高效标注，在跨域语义分割感知任务中（GTAV 到 Cityscapes），平均分割准确率较同期最优方法提升 2%；在极低样本标注仍能保持高精度感知性能，有效解决了传统视觉模型在面对非结构化复杂环境时泛化性差的瓶颈问题，为反恐防暴工作中未知目标识别与跨区域快速部署提供了核心算法支撑。</p>
                </div>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-0">
                  <div class="p-4 bg-gray-50 border-r border-gray-100">
                    <img alt="成果03 方法示意" class="h-64 w-full object-contain bg-white rounded" data-asset="res03_method" src="site_assets/images/placeholder.png"/>
                    <p class="text-center text-sm text-gray-500 mt-2">
                      图2-5：感知模型的跨场景迁移框架 <sup class="fig-ref-sup">[1]</sup>
                    </p>
                  </div>
                  <div class="p-4 bg-gray-50">
                    <img alt="成果03 效果示意" class="h-64 w-full object-contain bg-white rounded" data-asset="res03_effect" src="site_assets/images/placeholder.png"/>
                    <p class="text-center text-sm text-gray-500 mt-2">
                      图2-6：跨场景语义分割效果 <sup class="fig-ref-sup">[2]</sup>
                    </p>
                  </div>
                </div>
                <div class="p-6 bg-white border-t border-gray-100">
                  <h4 class="text-sm font-bold text-gray-900 mb-3">
                    代表性学术成果
                  </h4>
                  <ul class="text-sm text-gray-700 space-y-4 leading-relaxed">
                    <li>
                      <ol class="mt-2 ref-list pl-0 space-y-2">
                        <li class="break-words"><strong class="font-semibold text-gray-900">(CCF-A)</strong> Binhui Xie; Longhui Yuan; Shuang Li; Chi Harold Liu; Xinjing Cheng; Towards Fewer Annotations: Active Learning via Region Impurity and Prediction Uncertainty for Domain Adaptive Semantic Segmentation, IEEE CVPR 2022, New Orleans, 2022-6-19至2022-6-24. 第一标注</li>
                        <li class="break-words"> 叶语霄; 刘驰; 王昊, 一种保障元宇宙应用信息质量的无人群体感知方法，2023-8-2，中国， 202311056761.4.</li>
                      </ol>
                    </li>
                  </ul>
                </div>
              </div>
              <div class="bg-white rounded-xl shadow-lg overflow-hidden border border-gray-200">
                <div class="p-6 border-b border-gray-100">
                  <div class="flex items-center mb-2">
                    <span class="bg-bit-green text-white text-xs font-bold px-2 py-1 rounded mr-3">
                      成果 04
                    </span>
                    <h3 class="text-xl font-bold text-gray-800">
                      数据/算法复杂度降维的基于GAN异常共生压缩感知
                    </h3>
                  </div>
                  <p class="text-gray-600 text-base leading-relaxed mt-3">提出了基于因果启发表征学习与生成对抗网络（GAN）的共生压缩感知技术。该技术以因果干预机制与掩码对抗生成模块为基础，通过迭代筛选非因果冗余维度并强化新颖因果特征，构建了任务驱动的轻量化特征压缩模型（CIRL）；结合在线轻量级估算模块反演模型重训练阶段的资源消耗规律，融合内存超参数自适应集成优化算法，实现了在内存最优规则下的感知模型快速迭代。基于该技术，部署于单兵侦察终端的轻量化模型，可实现海量多模态数据的高效降维与实时处理。PACS数据集下该技术在保证泛化性能达 90.12% 的前提下，实现特征压缩率超 50%；在持续域自适应场景中，同精度下训练内存消耗降低 4.1 倍，训练时间减少 5.3 倍，有效解决了边缘侧设备因算力与带宽受限导致的多模态情报响应迟缓问题，保障了系统在突发事件下对高风险目标的秒级感知与精准溯源能力。</p>
                </div>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-0">
                  <div class="p-4 bg-gray-50 border-r border-gray-100">
                    <img alt="成果04 方法示意" class="h-64 w-full object-contain bg-white rounded" data-asset="res04_method" src="site_assets/images/placeholder.png"/>
                    <p class="text-center text-sm text-gray-500 mt-2">
                      图2-7：因果启发的表征学习框架 <sup class="fig-ref-sup">[1]</sup>
                    </p>
                  </div>
                  <div class="p-4 bg-gray-50">
                    <img alt="成果04 效果示意" class="h-64 w-full object-contain bg-white rounded" data-asset="res04_effect" src="site_assets/images/placeholder.png"/>
                    <p class="text-center text-sm text-gray-500 mt-2">
                      图2-8：内存超参数自适应的集成优化方法 <sup class="fig-ref-sup">[5]</sup>
                    </p>
                  </div>
                </div>
                <div class="p-6 bg-white border-t border-gray-100">
                  <h4 class="text-sm font-bold text-gray-900 mb-3">
                    代表性学术成果
                  </h4>
                  <ul class="text-sm text-gray-700 space-y-4 leading-relaxed">
                    <li>
                      <ol class="mt-2 ref-list pl-0 space-y-2">
                        <li class="break-words"><strong class="font-semibold text-gray-900">(CCF-A)</strong> Fangrui Lv; Jian Liang; Shuang Li; Bin Zang; Chi Harold Liu; Ziteng Wang; Di Liu; Causality Inspired Representation Learning for Domain Generalization, IEEE CVPR 2022, New Orleans, 2022-6-19至2022-6-24. EI. 第一标注</li>
                        <li class="break-words"><strong class="font-semibold text-gray-900">(CCF-A)</strong> Yuxiao Ye; Chi Harold Liu; Zipeng Dai; Jianxin Zhao; Ye Yuan; Guoren Wang; Jian Tang; Exploring both Individuality and Cooperation for Air-Ground Spatial Crowdsourcing by Multi-Agent Deep Reinforcement Learning, I EEE ICDE 2023, Anaheim, CA, 2023-4-3至2023-4-7. EI. 第一标注</li>
                        <li class="break-words"><strong class="font-semibold text-gray-900">(CCF-A)</strong> Yu Wang; Jingfei Wu; Xingyuan Hua; Chi Harold Liu; Guozheng Li; Jianxin Zhao; Ye Yuan; Guoren Wang; Air-Ground Spatial Crowdsourcing with UAV Carriers by Geometric Graph Convolutional Multi-Agent Deep Reinforcement Learning, IEEE ICDE 2023, Anaheim, CA, 2023-4-3至2023-4-7. EI. 第一标注</li>
                        <li class="break-words"><strong class="font-semibold text-gray-900">(CCF-A, SCI Q1)</strong> Yinuo Zhao; Chi Harold Liu; Tianjiao Yi; Guozheng Li; Dapeng Wu; Energy-Efficient Ground-Air-Space Vehicular Crowdsensing by Hierarchical Multi-Agent Deep Reinforcement Learning With Diffusion Models, IEEE Journal on Selected Areas in Communications, 2024, 42 (12): 3566-3580. SCIE. 第二标注</li>
                        <li class="break-words"> 徐奕东; 韩锐; 刘驰, 一种面向深度学习模型的边缘端重训练内存配置优化方法，2023-10-26，中国，202311396860.7.</li>
                      </ol>
                    </li>
                  </ul>
                </div>
              </div>
            </div>
          </div>
          <div class="bg-white/0">
            <div class="mb-5">
              <h3 class="text-xl font-bold text-gray-900">
                学术贡献三：边缘异构设备联邦学习与群体特征识别
              </h3>
              <p class="text-base text-gray-600 mt-2 leading-relaxed">提出了基于边缘异构设备匹配与多目标优化的联邦学习协同计算技术，利用子梯度下降与模型蒸馏机制，解决了非独立同分布数据下的异构终端协同训练难题；研发了基于改进 Butterworth Van Dyke（m-BVD）模型与虚拟传感阵列的群体特征识别方法，实现了对混合气体多模态信号的特征解耦与高精度分类，有效提升了资源受限边缘网络中的协作识别精度与通信效率。</p>
            </div>
            <div class="space-y-12">
              <div class="bg-white rounded-xl shadow-lg overflow-hidden border border-gray-200">
                <div class="p-6 border-b border-gray-100">
                  <div class="flex items-center mb-2">
                    <span class="bg-bit-green text-white text-xs font-bold px-2 py-1 rounded mr-3">
                      成果 05
                    </span>
                    <h3 class="text-xl font-bold text-gray-800">
                      基于异构设备资源多目标优化的联邦学习技术
                    </h3>
                  </div>
                  <p class="text-gray-600 text-base leading-relaxed mt-3">提出了基于边缘异构设备匹配与多目标优化的联邦学习协同计算技术。该技术以多智能体协同博弈与知识蒸馏机制为基础，构建适应动态网络的分布式训练架构；结合子梯度下降优化算法与模型蒸馏调整策略，反演异构终端在非独立同分布数据下的梯度更新规律，通过融合通信开销约束与精度增益模型，大幅提升了资源受限条件下的模型迁移效率与识别性能。基于该技术，反恐防暴协同作战系统可实现多源异构情报的隐私保护训练与联合推理，在移动终端数量动态变化的复杂网络环境下，图像分类与目标识别准确度较现有去中心化方法（如 PENS）平均提升 6%；有效解决了反恐侦察中因设备性能差异大、通信带宽窄导致的协同识别精度低的问题，为跨区域、多部门协同的联合情报分析提供了高可靠的算法支撑。</p>
                </div>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-0">
                  <div class="p-4 bg-gray-50 border-r border-gray-100">
                    <img alt="成果05 方法示意" class="h-64 w-full object-contain bg-white rounded" data-asset="res05_method" src="site_assets/images/placeholder.png"/>
                    <p class="text-center text-sm text-gray-500 mt-2">
                      图2-9：基于边缘异构设备匹配与多目标优化的联邦学习技术示意图 <sup class="fig-ref-sup">[1]</sup>
                    </p>
                  </div>
                  <div class="p-4 bg-gray-50">
                    <img alt="成果05 效果示意" class="h-64 w-full object-contain bg-white rounded" data-asset="res05_effect" src="site_assets/images/placeholder.png"/>
                    <p class="text-center text-sm text-gray-500 mt-2">
                      图2-10：基于边缘异构设备匹配与多目标优化的联邦学习技术成果示意图 <sup class="fig-ref-sup">[1]</sup>
                    </p>
                  </div>
                </div>
                <div class="p-6 bg-white border-t border-gray-100">
                  <h4 class="text-sm font-bold text-gray-900 mb-3">
                    代表性学术成果
                  </h4>
                  <ul class="text-sm text-gray-700 space-y-4 leading-relaxed">
                    <li>
                      <ol class="mt-2 ref-list pl-0 space-y-2">
                        <li class="break-words"> Jianxin Zhao; Xinyu Chang; Yanhao Feng; Chi Harold Liu; Ningbo Liu; Participant Selection for Federated Learning With Heterogeneous Data in Intelligent Transport System, IEEE Transactions on Intelligent Transportation Systems, 2023, 24(1): 1106-1115. 第一标注</li>
                      </ol>
                    </li>
                  </ul>
                </div>
              </div>
              <div class="bg-white rounded-xl shadow-lg overflow-hidden border border-gray-200">
                <div class="p-6 border-b border-gray-100">
                  <div class="flex items-center mb-2">
                    <span class="bg-bit-green text-white text-xs font-bold px-2 py-1 rounded mr-3">
                      成果 06
                    </span>
                    <h3 class="text-xl font-bold text-gray-800">
                      群体高阶张量建模与时空动态特征识别
                    </h3>
                  </div>
                  <p class="text-gray-600 text-base leading-relaxed mt-3">提出了基于群体高阶张量建模与时空动态特征识别的目标有害物质特征气体精准识别技术。该技术以分子特异性吸附与质量负载效应的协同作用为基础，提取目标气体分子的多维本征特征并构建群体高阶张量模型；结合扩散模型反演其在复杂环境中的动态演化规律，通过融合时空动态特征匹配与自适应阈值优化算法，大幅提升开放环境识别精度与复杂场景溯源能力。基于该技术，小型化移动感知终端可实现复杂环境中多目标特征气体的高灵敏定性定量检测，在典型应用场景下可实现不少于8种挥发性有机化合物（VOCs）的精准识别，准确率达98.68%；对具有高化学相似性的VOCs二元混合物与三元混合物分类准确率分别达94.29%和92.50%，同时能够识别爆炸物挥发性气体等有毒有害气体，为反恐防暴工作提供技术支撑，对保障公共安全具有重要的实际应用价值。</p>
                </div>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-0">
                  <div class="p-4 bg-gray-50 border-r border-gray-100">
                    <img alt="成果06 方法示意" class="h-64 w-full object-contain bg-white rounded" data-asset="res06_method" src="site_assets/images/placeholder.png"/>
                    <p class="text-center text-sm text-gray-500 mt-2">
                      图2-11：基于单芯片FBAR的特征提取方法 <sup class="fig-ref-sup">[1]</sup>
                    </p>
                  </div>
                  <div class="p-4 bg-gray-50">
                    <img alt="成果06 效果示意" class="h-64 w-full object-contain bg-white rounded" data-asset="res06_effect" src="site_assets/images/placeholder.png"/>
                    <p class="text-center text-sm text-gray-500 mt-2">
                      图2-12：基于多模态感知与特征识别的多气体分类能力 <sup class="fig-ref-sup">[2]</sup>
                    </p>
                  </div>
                </div>
                <div class="p-6 bg-white border-t border-gray-100">
                  <h4 class="text-sm font-bold text-gray-900 mb-3">
                    代表性学术成果
                  </h4>
                  <ul class="text-sm text-gray-700 space-y-4 leading-relaxed">
                    <li>
                      <ol class="mt-2 ref-list pl-0 space-y-2">
                        <li class="break-words"><strong class="font-semibold text-gray-900">(SCI Q1)</strong> Zhiqiang Ma; Mengyao Fu; Chenyang Gao; Shuyu Fan; Haozhen Chi; Wei Li; Dibo Hou; Yunqi Cao; Trenched microwave resonator integrated with porous PDMS for detection and classification of VOCs with enhanced performance, Journal of Hazardous Materials, 2024, 472: 134553. SCIE. 第一标注</li>
                        <li class="break-words"><strong class="font-semibold text-gray-900">(SCI Q1)</strong> Mengyao Fu; Zhiqiang Ma; Chenyang Gao; Yi Shen; Xiaoyan Song; Dibo Hou; Yunqi Cao. Detection of Volatile Organic Compounds and Their Mixtures Using an E-nose with Cascaded QCM-based Multi-Virtual Sensor Array, Measurement Science and Technology, 2025, 36, 115109.  SCIE 第一标注</li>
                        <li class="break-words"><strong class="font-semibold text-gray-900">(SCI Q1)</strong> Yunqi Cao; Mengyao Fu; Shuyu Fan; Chenyang Gao; Zhiqiang Ma; Dibo Hou; Hydrophobic MOF/PDMS-Based QCM Sensors for VOCs Identification and Quantitative Detection in High-Humidity Environments, ACS Applied Materials & Interfaces, 2024, 16(6): 7721–7731. SCIE. 第二标注</li>
                        <li class="break-words"> Mengyao Fu; Dongsheng Li; Chenyang Gao; Zhiqiang Ma; Dibo Hou; Yunqi Cao. MOF/PDMS Hybrid Nanofilm-Based QCM for VOC Selective Virtual Sensing in High-Humidity Environments, 2023 22nd International Conference on Solid-State Sensors, Actuators and Microsystems (Transducers), Kyoto, 2023-6-25至2023-6-29，EI.第二标注</li>
                      </ol>
                    </li>
                  </ul>
                </div>
              </div>
            </div>
          </div>
          <div class="bg-white/0">
            <div class="mb-5">
              <h3 class="text-xl font-bold text-gray-900">
                学术贡献四：面向泛在边缘环境的感知与计算系统
              </h3>
              <p class="text-base text-gray-600 mt-2 leading-relaxed">提出了基于薄膜体声波谐振器（FBAR）阵列的微型化多模态生化感知终端，突破了高灵敏度痕量检测与混合物分辨技术；构建了面向公共安全事件应急处置的“部署—感知—计算”一体化移动群体智能协同系统，集成人机资源优选、边缘深度压缩与端—边—云协同计算能力，在数字孪生与实战演练中验证了从分钟级资源编组到秒级精准溯源的全流程闭环处置效能。</p>
            </div>
            <div class="space-y-12">
              <div class="bg-white rounded-xl shadow-lg overflow-hidden border border-gray-200">
                <div class="p-6 border-b border-gray-100">
                  <div class="flex items-center mb-2">
                    <span class="bg-bit-green text-white text-xs font-bold px-2 py-1 rounded mr-3">
                      成果 07
                    </span>
                    <h3 class="text-xl font-bold text-gray-800">
                      基于MEMS阵列的多模态生化类危险品终端传感器研发
                    </h3>
                  </div>
                  <p class="text-gray-600 text-base leading-relaxed mt-3">研发了一种基于薄膜体声波谐振器（FBAR）的生化威胁原位检测传感器。结合改进 Butterworth Van Dyke（m-BVD）模型，构建了高选择性虚拟传感阵列，实现了对复杂混合特征气体的多通道特征解耦与高分辨识别。基于该技术，研发的微型化探测终端具备约 1.25 GHz 的自然谐振频率与超过 1400 的品质因数（Q 值），性能指标优于同类研究 1.5–2 倍；在典型反恐防暴场景下，可实现对爆炸物前体及有毒挥发性有机物（VOCs）的 ppb 级痕量检测，对具有高化学相似性的 VOCs 二元混合物与三元混合物分类准确率分别达 94.29% 和 92.50%。该终端可在复杂开放环境中实现痕量目标气体的有效检测，为公共场所生化威胁的早期预警与溯源提供核心传感硬件支撑，助力反恐防暴场景下的目标锁定与应急处置。</p>
                </div>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-0">
                  <div class="p-4 bg-gray-50 border-r border-gray-100">
                    <img alt="成果07 方法示意" class="h-64 w-full object-contain bg-white rounded" data-asset="res07_method" src="site_assets/images/placeholder.png"/>
                    <p class="text-center text-sm text-gray-500 mt-2">
                      图2-13：基于FBAR技术MEMS多模态传感器原理图 <sup class="fig-ref-sup">[1]</sup>
                    </p>
                  </div>
                  <div class="p-4 bg-gray-50">
                    <img alt="成果07 效果示意" class="h-64 w-full object-contain bg-white rounded" data-asset="res07_effect" src="site_assets/images/placeholder.png"/>
                    <p class="text-center text-sm text-gray-500 mt-2">
                      图2-14：MEMS传感器检测原理及其SEM图像 <sup class="fig-ref-sup">[2]</sup>
                    </p>
                  </div>
                </div>
                <div class="p-6 bg-white border-t border-gray-100">
                  <h4 class="text-sm font-bold text-gray-900 mb-3">
                    代表性学术成果
                  </h4>
                  <ul class="text-sm text-gray-700 space-y-4 leading-relaxed">
                    <li>
                      <ol class="mt-2 ref-list pl-0 space-y-2">
                        <li class="break-words"> Mengyao Fu; Zhiqiang Ma; Chenyang Gao; Yongping Ye; Wei Li; Dibo Hou; Yunqi Cao. A Multi-Functional VOC Sensor Based on Cascaded Quartz Crystal Resonators, IEEE Electron Device Letters, 2025, 46(3): 476-479. SCIE 第一标注</li>
                        <li class="break-words"> Chengyang Gao; Shuyu Fan; Wei Li; Yongbing Wang; Qianwen Xia; Dibo Hou; Yunqi Cao; A high-performance miniaturized frequency shift detection system for QCM-based mass sensing, Advanced Sensor Research, 2024, 0(0): 2400148. SCIE. 第一标注</li>
                        <li class="break-words"> Chenyang Gao; Mengyao Fu; Zhiqiang Ma; Shuyu Fan; Dibo Hou; Yunqi Cao; Metal-organic framework (MOF) based film bulk acoustic resonator (FBAR) sensor for volatile organic compounds (VOCs) detection, IEEE IECON 2024, Chicago, USA, 2024-11-3至2024-11-6. EI. 第一标注</li>
                        <li class="break-words"><strong class="font-semibold text-gray-900">(SCI Q1)</strong> Chenyang Gao; Mengyao Fu; Shuyu Fan; Zhiqiang Ma; Yongkui Tang; Dibo Hou; Yunqi Cao. High-performance virtual sensors array based on a single-chip FBAR for volatile organic compounds (VOCs) detection and classification, Sensors and Actuators:B. Chemical, 2025, 422: 136687. SCIE 第二标注</li>
                        <li class="break-words"> Chenyang Gao; Shuyu Fan; Haozhen Chi; Yipei Yao; Dibo Hou; Yunqi Cao; A high-sensitivity frequency shift detector for QCM-based miniaturized sensing system, CAC 2024, Qingdao, China, 2024-11-1至2024-11-3. EI 第二标注</li>
                      </ol>
                    </li>
                  </ul>
                </div>
              </div>
              <div class="bg-white rounded-xl shadow-lg overflow-hidden border border-gray-200">
                <div class="p-6 border-b border-gray-100">
                  <div class="flex items-center mb-2">
                    <span class="bg-bit-green text-white text-xs font-bold px-2 py-1 rounded mr-3">
                      成果 08
                    </span>
                    <h3 class="text-xl font-bold text-gray-800">
                      面向反恐防暴等泛在边缘环境的移动群体感知与计算系统
                    </h3>
                  </div>
                  <p class="text-gray-600 text-base leading-relaxed mt-3">提出了面向公共安全事件应急处置的“部署—感知—计算”一体化移动群体智能协同系统。该系统以数字孪生与端—边—云协同架构为基础，集成人机资源优选调度与车机协同轨迹规划模型；结合边缘侧多模态数据深度压缩与联邦学习在线优化技术，构建了全流程闭环的敏捷响应体系，实现了在低带宽、强动态边缘环境下的高效资源编排与精准情报处理。基于该系统，指挥中心可在突发暴恐事件中实现无人机/车与警力资源的分钟级编组与盲区覆盖巡查，实测数据显示，在保障任务关键信息完整的前提下，系统可将 1080p 视频回传内存占用降低 53%–54%，并通过协同计算在 4 分钟内完成从感知到决策的全流程处置，识别准确率突破 92% ，显著提升了高风险环境下对隐匿目标的快速锁定与应急处突能力。</p>
                </div>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-0">
                  <div class="p-4 bg-gray-50 border-r border-gray-100">
                    <img alt="成果08 方法示意" class="h-64 w-full object-contain bg-white rounded" data-asset="res08_method" src="site_assets/images/placeholder.png"/>
                    <p class="text-center text-sm text-gray-500 mt-2">
                      图2-15：系统整体架构与模块交互
                    </p>
                  </div>
                  <div class="p-4 bg-gray-50">
                    <img alt="成果08 效果示意" class="h-64 w-full object-contain bg-white rounded" data-asset="res08_effect" src="site_assets/images/placeholder.png"/>
                    <p class="text-center text-sm text-gray-500 mt-2">
                      图2-16：反恐防暴场景系统运行界面
                    </p>
                  </div>
                </div>
                <div class="p-6 bg-white border-t border-gray-100">
                  <h4 class="text-sm font-bold text-gray-900 mb-3">
                    代表性学术成果
                  </h4>
                  <ul class="text-sm text-gray-700 space-y-4 leading-relaxed">
                    <li>
                      <ol class="mt-2 ref-list pl-0 space-y-2">
                        <li class="break-words"><strong class="font-semibold text-gray-900">(CCF-A)</strong> Yu Wang; Jingfei Wu; Xingyuan Hua; Chi Harold Liu; Guozheng Li; Jianxin Zhao; Ye Yuan; Guoren Wang; Air-Ground Spatial Crowdsourcing with UAV Carriers by Geometric Graph Convolutional Multi-Agent Deep Reinforcement Learning, IEEE ICDE 2023, Anaheim, CA, 2023-4-3至2023-4-7. EI. 第一标注</li>
                        <li class="break-words"> Jiahui Sun; Guiyun Fan; Haiming Jin; Yiwen Song; Tianyuan Liu; Chenhao Ying; Yuan Luo; Jie Li; Multi-Task-Oriented UAV Crowd Sensing with Charging Budget Constraint, ACM MOBIHOC 2024, Athens, Greece, 2024-10-14至2024-10-17. EI. 第一标注</li>
                        <li class="break-words"><strong class="font-semibold text-gray-900">(CCF-A)</strong> Chenhao Ying; Fuyuan Xia; David S. L. Wei; Xinchun Yu; Yibin Xu; Weiting Zhang; Xikun Jiang; Haiming Jin; Yuan Luo; Tao Zhang; Dacheng Tao; BIT-FL: Blockchain-Enabled Incentivized and Secure Federated Learning Framework, IEEE Transactions on Mobile Computing, 2025, 24(2)：1212-1229. SCIE, EI. 第三标注</li>
                      </ol>
                    </li>
                  </ul>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>
    <section class="py-20 bg-white" id="applications">
      <div class="container mx-auto px-6">
        <h2 class="text-3xl font-bold text-gray-900 section-title">
          03 应用演示
        </h2>
        <div class="space-y-8">
          <div class="w-full max-w-5xl mx-auto">
            <div class="aspect-video bg-gray-900 rounded-lg flex items-center justify-center relative shadow-2xl overflow-hidden">
              <video class="w-full h-full bg-black" id="demoVideo" controls preload="metadata" playsinline>
                <source id="demoVideoSource" src="" type="video/mp4" />
                您的浏览器不支持 HTML5 video 标签。
              </video>
              <div id="demoVideoPlaceholder" class="absolute inset-0 flex items-center justify-center bg-gray-900/95 text-gray-200 text-sm px-6 text-center">
                演示视频将以外部直链方式播放（推荐：GitHub Releases 作为 Release asset 托管）。若当前网络环境无法加载或链接尚未配置，请
                <a id="demoVideoOpenLink" class="text-blue-300 underline ml-1" href="#" target="_blank" rel="noopener">点击打开/下载视频</a>。
              </div>
            </div>
          </div>
        </div>
          <div class="w-full max-w-5xl mx-auto">
            <h3 class="text-2xl font-bold mb-4 text-gray-800"> </h3>
            <h3 class="text-2xl font-bold mb-4 text-gray-800">
              杭州世纪中心异常包裹应急处置仿真
            </h3>
            <div class="prose text-gray-600 leading-relaxed text-base">
              <p class="mb-3">
                本次演示基于浙江省杭州市“世纪中心”周边街区构建仿真场景，模拟夜间发现疑似爆炸物包裹后的应急处置闭环。系统在接收警情后自动生成处置目标与双线任务（“包裹排查与处置”与“嫌疑人追踪与封控”），联动多警力单位、无人机与无人车集群完成资源优选调度、协同轨迹规划、现场侦查与目标跟踪。在边缘侧，系统对视频流进行低时延压缩回传（环境和目标视频传输量分别降低约53%与54%），并通过联邦学习在线自适应提升识别模型在当前场景与光照条件下的准确性；最终融合视觉轨迹特征与气体组分分类结果，完成爆炸物指纹比对与嫌疑目标关联分析，生成处置报告并给出收网指引。本演示所依托的核心技术载体——面向公共安全事件应急处置的边侧移动群体智能感知与协同计算系统，已获得浙江省应急管理数字与技术中心的高度评价与充分认可。
              </p>
              <p class="mb-2 font-bold text-gray-800">
                处置流程关键节点：
              </p>
              <ul class="space-y-2 mb-4 list-disc pl-4">
                <li>
                  <span class="font-semibold text-bit-green">
                    T+10s 警情研判：
                  </span>
                  系统接收警情并启动爆炸物响应预案，自动生成处置目标与双线任务（包裹处置与嫌疑人追踪）。
                </li>
                <li>
                  <span class="font-semibold text-bit-green">
                    T+25s 人机资源优选与智能调度：
                  </span>
                  综合距离、到场时延、载荷能力与协同约束，在多警局与多平台中优选无人机与无人车编组并给出出动方案。
                </li>
                <li>
                  <span class="font-semibold text-bit-green">
                    T+90s 车—机协同轨迹规划与到场侦查：
                  </span>
                  计算无碰撞航迹与地面路线，设备抵达后开展现场视频侦查与目标跟踪，形成初步风险评估。
                </li>
                <li>
                  <span class="font-semibold text-bit-green">
                    T+180s 低时延压缩回传：
                  </span>
                  对环境与目标感知视频流执行边缘压缩，传输量分别降低约53%与54%，保障链路拥塞条件下的实时回传。
                </li>
                <li>
                  <span class="font-semibold text-bit-green">
                    T+240s 联邦学习在线自适应：
                  </span>
                  在不交换原始视频数据的前提下启动联邦学习与轻量更新，快速提升识别模型对当前场景的适配性（精度曲线收敛至0.92+）。
                </li>
                <li>
                  <span class="font-semibold text-bit-green">
                    T+300s 多模态精细锁定与报告输出：
                  </span>
                  融合视觉轨迹特征与气体组分分类结果完成爆炸物指纹比对并关联嫌疑人B，协助警力封控收网，同时自动生成处置报告与过程留痕。
                </li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </section>

    
    <section class="py-20 bg-gray-50" id="exchange">
      <div class="container mx-auto px-6">
        <h2 class="text-3xl font-bold text-gray-900 section-title">
          04 学术交流
        </h2>

        <div class="max-w-6xl mx-auto space-y-6">
          <!-- Carousel (side navigation) -->
          <div class="flex items-stretch gap-3 md:gap-4">
            <button id="exchangePrev" class="icon-btn icon-btn-lg shrink-0 self-center" type="button" aria-label="上一条">
              <span class="text-gray-700 text-2xl leading-none">‹</span>
            </button>

            <div class="group flex-1 min-w-0 bg-white rounded-xl shadow-sm border border-gray-100 overflow-hidden transition-shadow duration-200 hover:shadow-md">
              <div class="relative">
                <img id="exchangeImage" class="w-full h-[280px] sm:h-[360px] md:h-[550px] object-cover transition-transform duration-300 ease-out group-hover:scale-[1.01]" src="site_assets/images/placeholder.png" alt="学术交流照片"/>
                <div class="absolute inset-x-0 bottom-0 bg-gradient-to-t from-black/55 to-transparent h-28"></div>

                <div class="absolute left-4 top-4 inline-flex items-center gap-2 px-3 py-1 rounded-full bg-white/90 backdrop-blur-md border border-white/30 text-xs text-gray-700">
                  <span class="font-semibold" id="exchangeCounter">1 / 7</span>
                </div>
              </div>

              <div class="p-5 md:p-6">
                <p id="exchangeText" class="text-gray-800 text-base leading-relaxed">
                  参加国内外重要学术会议并作专题报告
                </p>
              </div>
            </div>

            <button id="exchangeNext" class="icon-btn icon-btn-lg shrink-0 self-center" type="button" aria-label="下一条">
              <span class="text-gray-700 text-2xl leading-none">›</span>
            </button>
          </div>

          <!-- Collapsible full list -->
          <details class="bg-white rounded-xl shadow-sm border border-gray-100 overflow-hidden">
            <summary class="cursor-pointer select-none px-5 py-4 font-semibold text-gray-900">
              学术交流列表
            </summary>
            <div class="px-5 pb-5">
              <ul class="space-y-6 text-gray-700 leading-relaxed">
                <li class="rounded-lg border border-gray-100 bg-gray-50/50 p-4">
                  <div class="font-semibold text-gray-900">参加国际学术会议</div>
                  <ol class="list-decimal pl-5 mt-3 space-y-2 text-gray-700 leading-relaxed marker:text-gray-400">
                    <li>2025年11月，项目组成员金海明、丁榕参加了在香港的2025年MOBICOM会议。</li>
                    <li>2025年5月，项目组成员金海明、范桂云参加了在英国伦敦的2025年INFOCOM会议。</li>
                    <li>2024年10月，项目组成员金海明参加了在希腊雅典的2024年MOBIHOC会议。</li>
                    <li>2024年8月，项目组成员杨兆星参加了在西班牙巴塞罗那的2024年KDD会议。</li>
                    <li>2024年5月，项目组成员金海明、丁榕、祝宁之参加了在香港的2024年IPSN会议。</li>
                    <li>2024年5月，项目组成员杨兆星参加了在新西兰奥克兰的2024年AAMAS会议。</li>
                    <li>2023年11月，项目组成员金海明、丁榕参加了在土耳其伊斯坦布尔的2023年SenSys会议。</li>
                    <li>2023年7月，项目组成员杨兆星参加了在香港的2023年ICDCS会议。</li>
                    <li>2023年5月，项目组成员金海明参加了在美国新泽西的2023年INFOCOM会议。</li>
                    <li>2023年2月，项目组成员杨兆星线上参加了2023年AAAI会议。</li>
                    <li>2022年5月，项目组成员范桂云参加了在线举办的2022年INFOCOM会议。</li>
                    <li>2022年6月，项目组成员谢斌辉线上参加了2022年CVPR会议。</li>
                    <li>2022年6月，项目组成员吕芳蕊线上参加了2022年CVPR会议。</li>
                    <li>2023年4月，项目组成员叶语霄参加了2023年ICDE会议。</li>
                    <li>2023年4月，项目组成员王宇线上参加了2023年ICDE会议。</li>
                    <li>2023年6月，项目组成员傅梦瑶参加了在日本的2023年Transducers会议。</li>
                    <li>2023年10月，项目组成员范舒羽参加了在新加坡的2023年IECON会议。</li>
                    <li>2024年11月，项目组成员高晨阳线上参加了在芝加哥的2024年IECON会议。</li>
                    <li>2024年10月，项目组成员曹云琦研究员受邀参加了在日本神户的2024年IEEE SENSORS会议，并担任分会场主席。</li>
                  </ol>
                </li>
                <li class="rounded-lg border border-gray-100 bg-gray-50/50 p-4">
                  <div class="font-semibold text-gray-900">学术互访</div>
                  <ol class="list-decimal pl-5 mt-3 space-y-2 text-gray-700 leading-relaxed marker:text-gray-400">
                    <li>2025年12月22日-25日，美国纽约州立大学布法罗分校谢亚雄教授访问上海交通大学。</li>
                    <li>2025年11月15日-20日，新加坡南洋理工大学Chee Wei Tan教授访问上海交通大学。</li>
                    <li>2023年5月，赴美国与普渡大学的宿陆老师课题组交流，并对项目相关移动群体感知问题进行讨论。</li>
                    <li>2022年，邀请华盛顿大学Akshay Gadre教授、香港中文大学邢国良教授、北京大学许辰人教授做线上学术报告。</li>
                    <li>2024年6月27日，邀请香港城市大学吴大鹏教授访问北京理工大学，深入开展线下学术研讨会议，并对项目相关问题进行讨论。</li>
                    <li>2025年6月，赴美国密歇根州立大学与Xiaobo Tan教授（IEEE Fellow、ASME Fellow）与Yiming Deng教授（ASNT Fellow）课题组交流，对本项目多模态传感器问题进行深入探讨。</li>
                  </ol>
                </li>
              </ul>
            </div>
          </details>
        </div>
      </div>
    </section>

    
    <section class="py-20 bg-white" id="talent">
      <div class="container mx-auto px-6">
        <h2 class="text-3xl font-bold text-gray-900 section-title">
          05 学生培养
        </h2>

        <div class="w-full">
          <div class="grid grid-cols-1 md:grid-cols-3 gap-8 md:gap-12">
            <!-- Postdoc -->
            <div class="flex flex-col h-full">
              <div class="bg-green-50 p-6 rounded-xl border border-green-100 text-center mb-6">
                <div class="text-4xl font-bold text-bit-green mb-1">
                  <span id="talent-postdoc-total">1</span>
                </div>
                <div class="text-sm font-medium text-gray-600">
                  博士后培养人数（名）
                </div>
              </div>

              <div class="bg-white rounded-xl border border-gray-200 shadow-sm flex flex-col" style="height: 520px;">
                <div class="p-5 border-b border-gray-100 bg-gray-50/50 shrink-0">
                  <h3 class="text-xl font-bold text-gray-900 mb-3">博士培养情况</h3>
                </div>
                <div class="flex-1 overflow-y-auto min-h-0 custom-scrollbar p-5" id="talent-phd-list">
                  <div class="space-y-5">
                    <div class="rounded-lg border border-gray-100 bg-gray-50/60 p-4">
                      <div class="text-sm font-semibold text-gray-900 mb-3">博士后</div>
                        <ol class="list-decimal pl-5 space-y-2 text-sm text-gray-700 leading-relaxed marker:text-gray-400">
                          <li>培养上海交通大学博士后范桂云，在站期间获得国自然青年基金资助，出站后赴同济大学任助理教授。</li>
                        </ol>
                    </div>

                    <div class="rounded-lg border border-gray-100 bg-gray-50/60 p-4">
                      <div class="text-sm font-semibold text-gray-900 mb-3">博士研究生</div>
                        <ol class="list-decimal pl-5 space-y-3 text-sm text-gray-700 leading-relaxed marker:text-gray-400">
                          <li>培养北京理工大学博士研究生谢斌辉，获得2024年北京理工大学“优秀博士学位论文育苗基金”、2023年博士研究生国家奖学金，毕业后赴腾讯就业。</li>
                          <li>培养北京理工大学博士研究生赵一诺，获得2020年硕士研究生国家奖学金，毕业后赴香港城市大学进站从事博士后研究。</li>
                          <li>培养上海交通大学博士研究生杨兆星，于2024年获得国家奖学金。</li>
                          <li>培养上海交通大学博士研究生丁榕，于2021-2025年获得吴文俊人工智能荣誉博士奖学金。</li>
                          <li>培育上海交通大学博士研究生孙嘉徽，毕业后赴中国移动研究院就业。</li>
                          <li>培养上海交通大学博士研究生欧俊杰，毕业后赴百度就业。</li>
                          <li>培养上海交通大学博士研究生朱一晨，毕业后赴华为就业。</li>
                          <li>培养浙江大学博士研究生周禹杉，获CSC资助前往南洋理工大学交流。</li>
                          <li>培养浙江大学博士研究生高晨阳，获2025年国家奖学金。</li>
                          <li>培养浙江大学博士研究生范舒羽，获得2024年浙江大学优秀博士生资助项目。</li>
                          <li>培养浙江大学博士研究生池豪镇，毕业后赴浙江科技大学担任讲师。</li>
                          <li>培养浙江大学博士研究生傅梦瑶，毕业后赴中国移动杭州研发中心就业。</li>
                          <li>培养浙江大学博士研究生马志强、单绮玮。</li>
                        </ol>
                    </div>
                  </div>
                </div>
              </div>
            </div>

            <!-- PhD -->
            <div class="flex flex-col h-full">
              <div class="bg-indigo-50 p-6 rounded-xl border border-indigo-100 text-center mb-6">
                <div class="text-4xl font-bold text-indigo-800 mb-1">
                  <span id="talent-phd-total">14</span>
                </div>
                <div class="text-sm font-medium text-gray-600">
                  博士研究生培养人数（名）
                </div>
              </div>

              <div class="bg-white rounded-xl border border-gray-200 shadow-sm flex flex-col" style="height: 520px;">
                <div class="p-5 border-b border-gray-100 bg-gray-50/50 shrink-0">
                  <h3 class="text-xl font-bold text-gray-900 mb-3">硕士培养情况</h3>
                </div>
                <div class="flex-1 overflow-y-auto min-h-0 custom-scrollbar p-5" id="talent-master-list">
                  <ol class="list-decimal pl-5 space-y-3 text-sm text-gray-700 leading-relaxed marker:text-gray-400">
                    <li>培养北京理工大学硕士研究生王宇，获得2023年度中国电子学会硕士学位论文。</li>
                    <li>培养北京理工大学硕士研究生吕芳蕊，获得2021年硕士研究生国家奖学金，毕业后赴清华大学攻读博士学位。</li>
                    <li>培养北京理工大学硕士研究生徐奕东，于2024年毕业，毕业后赴中海油研究总院就业。</li>
                    <li>培养北京理工大学硕士毕业生常欣煜，与2024年毕业，毕业后赴字节跳动就业。</li>
                    <li>培养上海交通大学硕士研究生王孝成，于2024年获得上海市优秀毕业生。</li>
                    <li>培养上海交通大学硕士研究生农汉琦，于2024年获得上海市优秀毕业生。</li>
                    <li>培养上海交通大学硕士研究生吕嘉溪，毕业后赴拼多多就业。</li>
                    <li>培养上海交通大学硕士研究生余北辰，毕业后赴中兴就业。</li>
                    <li>培养浙江大学硕士研究生苏珊茜、汪舒迅、毕研成。</li>
                  </ol>
                </div>
              </div>
            </div>

            <!-- Master -->
            <div class="flex flex-col h-full">
              <div class="bg-amber-50 p-6 rounded-xl border border-amber-100 text-center mb-6">
                <div class="text-4xl font-bold text-amber-800 mb-1">
                  <span id="talent-master-total">13</span>
                </div>
                <div class="text-sm font-medium text-gray-600">
                  硕士研究生培养人数（名）
                </div>
              </div>

              <div class="bg-white rounded-xl border border-gray-200 shadow-sm flex flex-col" style="height: 520px;">
                <div class="p-5 border-b border-gray-100 bg-gray-50/50 shrink-0">
                  <h3 class="text-xl font-bold text-gray-900 mb-3">学科竞赛获奖情况</h3>
                </div>
                <div class="flex-1 overflow-y-auto min-h-0 custom-scrollbar p-5" id="talent-postdoc-list">
                  <ol class="list-decimal pl-5 space-y-2 text-sm text-gray-700 leading-relaxed marker:text-gray-400">
                    <li>北京理工大学刘驰教授指导项目“城市环境无人群体空地协同感知技术与仿真平台”（参与学生：叶语霄、刘嘉辉、焦鹏屹）获2022年“中国高校计算机大赛——人工智能创意赛”全国总决赛特等奖。</li>
                    <li>北京理工大学博士研究生赵一诺，获得 ICLR 2022国际比赛“Generalizable Policy Learning in the Physical World”第一名。</li>
                    <li>浙江大学曹云琦教授指导项目“面向白酒检测的射频式机器嗅觉（电子鼻）系统”（参与学生：毕研成、傅梦瑶、马志强、高晨阳、付逸飞）获第九届中国（国际）传感器创新创业大赛决赛高校组创新应用类三等奖。</li>
                    <li>浙江大学曹云琦教授指导项目“'Micro-SmartCar'面向大型动力设备的微型智能检修机器人”（参与学生：于浩洋、洪德隆、付逸飞）获2025年中国大学生智能装备创新设计大赛(区域赛)一等奖。</li>
                    <li>浙江大学曹云琦教授指导项目“基于自感知密封垫片的螺栓法兰密封状态智能监测系统”（参与学生：付逸飞、洪德隆、于浩洋）获2025年中国大学生智能装备创新设计大赛(区域赛)一等奖。</li>
                    <li>浙江大学曹云琦研究员指导项目“针对大型发电设备检修的微小型机器人应用研究”（参与学生：单绮玮、汪舒迅、张逸诚、陈炫）获2024年第十九届“挑战杯”全国大学生课外学术科技作品竞赛“揭榜挂帅”专项赛一等奖。</li>
                  </ol>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="py-20 bg-white" id="papers">
      <div class="container mx-auto px-6">
        <h2 class="text-3xl font-bold text-gray-900 section-title">
          06 学术成果
        </h2>

        <div class="grid grid-cols-1 lg:grid-cols-2 gap-8 md:gap-12">
          <div class="flex flex-col h-full">
            <div class="bg-green-50 p-6 rounded-xl border border-green-100 text-center mb-6">
              <div class="text-4xl font-bold text-bit-green mb-1">
                <span id="paper-total">47</span>
              </div>
              <div class="text-sm font-medium text-gray-600">
                发表高水平论文 (篇)
              </div>
            </div>

            <div class="bg-white rounded-xl border border-gray-200 shadow-sm flex flex-col" style="height: 800px;">
              <div class="p-5 border-b border-gray-100 bg-gray-50/50 shrink-0">
                <h3 class="text-xl font-bold text-gray-900 mb-3">论文发表</h3>
                <input class="w-full px-3 py-2 rounded border border-gray-300 bg-white text-base focus:outline-none focus:ring-2 focus:ring-green-600/20 focus:border-green-600 transition" id="paper-search" placeholder="搜索论文..." type="search"/>
              </div>

              <div class="flex-1 overflow-y-auto min-h-0 custom-scrollbar p-5" id="paper-list">
              </div>
            </div>
          </div>

          <div class="flex flex-col h-full">
            <div class="bg-blue-50 p-6 rounded-xl border border-blue-100 text-center mb-6">
              <div class="text-4xl font-bold text-blue-800 mb-1">
                <span id="patent-total">15</span>
              </div>
              <div class="text-sm font-medium text-gray-600">
                专利申请与授权 (项)
              </div>
            </div>

            <div class="bg-white rounded-xl border border-gray-200 shadow-sm flex flex-col" style="height: 800px;">
              <div class="p-5 border-b border-gray-100 bg-gray-50/50 shrink-0">
                <h3 class="text-xl font-bold text-gray-900 mb-3">专利申请与授权</h3>
                <input class="w-full px-3 py-2 rounded border border-gray-300 bg-white text-base focus:outline-none focus:ring-2 focus:ring-blue-600/20 focus:border-blue-600 transition" id="patent-search" placeholder="搜索专利..." type="search"/>
              </div>

              <div class="flex-1 overflow-y-auto min-h-0 custom-scrollbar p-5" id="patent-list">
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <footer class="bg-gray-900 text-gray-400 py-10">
      <div class="container mx-auto px-6 text-center">
        <p class="mb-2">
          Copyright © 2025 北京理工大学 LINC All Rights Reserved.
        </p>
        <p class="text-sm">
          地址：北京市海淀区中关村南大街5号
        </p>
      </div>
    </footer>
    <script>
(function () {
  function $(id) { return document.getElementById(id); }

  var video = null;
  var placeholder = null;
  var openLink = null;

  function ensure() {
    video = $("demoVideo");
    placeholder = $("demoVideoPlaceholder");
    openLink = $("demoVideoOpenLink");
  }

  function showPlaceholder(show) {
    if (!placeholder) return;
    placeholder.style.display = show ? "flex" : "none";
  }

  function setOpenLink(url) {
    if (!openLink) return;
    if (!url) {
      openLink.removeAttribute("href");
      return;
    }
    openLink.href = url;
  }

  function setVideoSource(url) {
    ensure();
    if (!video) return;

    if (!url) {
      try { video.removeAttribute("src"); video.load(); } catch (e) {}
      showPlaceholder(true);
      return;
    }

    // 先显示占位，等 loadeddata 再隐藏
    showPlaceholder(true);

    try { video.pause(); } catch (e) {}
    video.src = url;
    try { video.load(); } catch (e) {}

    // 尝试自动预热（不自动播放，避免浏览器策略拦截）
    // 注意：preload=metadata 只拉取元数据，不会马上下载整段视频
  }

  document.addEventListener("DOMContentLoaded", function () {
    ensure();

    var direct = (window.PROJECT_DEMO_VIDEO_DIRECT_URL || "").trim();
    var local = (window.PROJECT_DEMO_VIDEO_URL || "").trim();
    var chosen = direct || local;

    var fallbackOpen = (window.PROJECT_DEMO_VIDEO_FALLBACK_OPEN || "").trim();
    setOpenLink(fallbackOpen || chosen);

    setVideoSource(chosen);

    if (video) {
      video.addEventListener("loadeddata", function () {
        showPlaceholder(false);
      });
      video.addEventListener("error", function () {
        // 加载失败：保持占位层，并建议用户点击打开/下载
        showPlaceholder(true);
      });
    }
  });
})();
</script>
    <script id="site-asset-apply">
   (function () {
  try {
    var cfg = window.SITE_ASSETS || {};
    var faviconLink = document.getElementById('site-favicon');
    if (faviconLink && cfg.favicon) faviconLink.href = cfg.favicon;

    var fallback = cfg.achievementFallback || 'site_assets/images/placeholder.png';
    var map = cfg.achievementImages || {};
    document.querySelectorAll('img[data-asset]').forEach(function (img) {
      var key = img.getAttribute('data-asset');
      var src = map[key] || fallback;
      img.src = src;
      img.onerror = function () { img.src = fallback; };
    });
  } catch (e) {
  }
})();
  </script>
    <script id="outputs-render-script">
(function () {
  // ============================
  // Data (from Final Report Template)
  // ============================
  const paperGroups = {
  "期刊｜IEEE Journal on Selected Areas in Communications": [
    "(CCF-A, SCI Q1) Yinuo Zhao; Chi Harold Liu; Tianjiao Yi; Guozheng Li; Dapeng Wu; Energy-Efficient Ground-Air-Space Vehicular Crowdsensing by Hierarchical Multi-Agent Deep Reinforcement Learning With Diffusion Models, IEEE Journal on Selected Areas in Communications, 2024, 42(12): 3566-3580. SCIE. 第二标注"
  ],

  "期刊｜IEEE Transactions on Knowledge and Data Engineering": [
    "(CCF-A) Jiahui Sun; Haiming Jin; Zhaoxing Yang; Lu Su; Optimizing Long-Term Efficiency and Fairness in Ride-Hailing under Budget Constraint via Joint Order Dispatching and Driver Repositioning, IEEE Transactions on Knowledge and Data Engineering, 2024, 36(7): 1-14. SCIE. 第一标注"
  ],

  "期刊｜IEEE Transactions on Mobile Computing": [
    "(CCF-A) Chenhao Ying; Fuyuan Xia; David S. L. Wei; Xinchun Yu; Yibin Xu; Weiting Zhang; Xikun Jiang; Haiming Jin; Yuan Luo; Tao Zhang; Dacheng Tao; BIT-FL: Blockchain-Enabled Incentivized and Secure Federated Learning Framework, IEEE Transactions on Mobile Computing, 2025, 24(2): 1212-1229. SCIE, EI. 第三标注"
  ],

  "期刊｜Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT)": [
    "(CCF-A) Rong Ding; Haiming Jin; Dong Xiang; Xiaocheng Wang; Yongkui Zhang; Dingman Shen; Lu Su; Wentian Hao; Mingyuan Tao; Xinbing Wang; Chenghu Zhou; Soil Moisture Sensing with UAV-Mounted IR-UWB Radar and Deep Learning, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT), 2023, 7(1): 1-25. EI. 第二标注"
  ],

  "期刊｜Journal of Hazardous Materials": [
    "Zhiqiang Ma; Mengyao Fu; Chenyang Gao; Shuyu Fan; Haozhen Chi; Wei Li; Dibo Hou; Yunqi Cao; Trenched microwave resonator integrated with porous PDMS for detection and classification of VOCs with enhanced performance, Journal of Hazardous Materials, 2024, 472: 134553. SCIE. 第一标注"
  ],

  "期刊｜Energy Conversion and Management": [
    "(SCI Q1) Shuyu Fan; Yongkui Tang; Lurui Zhao; Hai Liu; Yufeng Wang; Dibo Hou; Yunqi Cao; Design optimization of microfabricated coils for volume-limited miniaturized broadband electromagnetic vibration energy harvester, Energy Conversion and Management, 2022, 271(1). SCIE. 第一标注"
  ],

  "期刊｜ACS Applied Materials & Interfaces": [
    "(SCI Q1) Yunqi Cao; Mengyao Fu; Shuyu Fan; Chenyang Gao; Zhiqiang Ma; Dibo Hou; Hydrophobic MOF/PDMS-Based QCM Sensors for VOCs Identification and Quantitative Detection in High-Humidity Environments, ACS Applied Materials & Interfaces, 2024, 16(6): 7721-7731. SCIE. 第二标注"
  ],

  "期刊｜Nano Research": [
    "(SCI Q1) Yunqi Cao; Hongyang Shi; Xiaobo Tan; Nelson Sepúlveda; Nanogenerator-based bidirectional pressure sensor array and its demonstration in underwater invasive species detection, Nano Research, 2023, 16: 11822-11831. SCIE. 第一标注"
  ],

  "期刊｜Cell Reports Physical Science": [
    "(SCI Q1) Yunqi Cao; Shuyu Fan; Yongkui Tang; Qiwei Shan; Chenyang Gao; Nelson Sepúlveda; Dibo Hou; Guangxin Zhang; Human-motion adaptability enhancement of wearable electromagnetic vibration energy harvesters toward self-sustained body sensor networks, Cell Reports Physical Science, 2024, 5(9). SCIE. 第一标注"
  ],

  "期刊｜Sensors and Actuators B: Chemical": [
    "Chenyang Gao; Mengyao Fu; Shuyu Fan; Zhiqiang Ma; Yongkui Tang; Dibo Hou; Yunqi Cao; High-performance virtual sensors array based on a single-chip FBAR for volatile organic compounds (VOCs) detection and classification, Sensors and Actuators B: Chemical, 2025, 422: 136687. SCIE. 第二标注"
  ],

  "期刊｜IEEE/ASME Transactions on Mechatronics": [
    "(SCI Q1) Shuyu Fan; Haozhen Chi; Yipei Yao; Chenyang Gao; Dibo Hou; Wei Li; Yunqi Cao; A High-Power-Density Ultralow-Frequency Energy Harvester Based on a Magnetic Rotor With Built-In Eccentricity and Ferromagnetic Fillers, IEEE/ASME Transactions on Mechatronics, 2025. (Early Access) SCIE. 第二标注"
  ],

  "期刊｜IEEE Transactions on Instrumentation and Measurement": [
    "(SCI Q1) Shuyu Fan; Mengyao Fu; Yushan Zhou; Dibo Hou; Guangxin Zhang; Yunqi Cao; Ultralow-frequency biomechanical energy scavenging and human activity recognition at different positions using a multifunctional wearable energy harvester, IEEE Transactions on Instrumentation and Measurement, 2024, 73. SCIE. 第一标注"
  ],

  "期刊｜IEEE Transactions on Electron Devices": [
    "Yushan Zhou; Shuyu Fan; Ziying Zhu; Shanqian Su; Dibo Hou; Hongjian Zhang; Yunqi Cao; Enabling High-Sensitivity Calorimetric Flow Sensor Using Vanadium Dioxide Phase-Change Material With Predictable Hysteretic Behavior, IEEE Transactions on Electron Devices, 2025, 72(3): 1360-1367. SCIE. 第二标注"
  ],

  "期刊｜IEEE Transactions on Intelligent Transportation Systems": [
    "Jianxin Zhao; Xinyu Chang; Yanhao Feng; Chi Harold Liu; Ningbo Liu; Participant Selection for Federated Learning With Heterogeneous Data in Intelligent Transport System, IEEE Transactions on Intelligent Transportation Systems, 2023, 24(1): 1106-1115. 第一标注"
  ],

  "期刊｜IEEE Electron Device Letters": [
    "Mengyao Fu; Zhiqiang Ma; Chenyang Gao; Yongping Ye; Wei Li; Dibo Hou; Yunqi Cao; A Multi-Functional VOC Sensor Based on Cascaded Quartz Crystal Resonators, IEEE Electron Device Letters, 2025, 46(3): 476-479. SCIE. 第一标注"
  ],

  "期刊｜IEEE Sensors Letters": [
    "Yunqi Cao; Hongyang Shi; Xiaobo Tan; Nelson Sepúlveda; Enabling Negative Pressure Sensing Through Ferroelectret Device, IEEE Sensors Letters, 2022, 6(8). SCIE, EI. 第一标注"
  ],

  "期刊｜Measurement Science and Technology": [
    "Mengyao Fu; Zhiqiang Ma; Chenyang Gao; Yi Shen; Xiaoyan Song; Dibo Hou; Yunqi Cao; Detection of Volatile Organic Compounds and Their Mixtures Using an E-nose with Cascaded QCM-based Multi-Virtual Sensor Array, Measurement Science and Technology, 2025, 36: 115109. SCIE. 第一标注"
  ],

  "期刊｜Advanced Intelligent Systems": [
    "Qiwei Shan; Yunqi Cao; Haozhen Chi; Shuyu Fan; Ziying Zhu; Dibo Hou; A Star-Nose-Inspired Bionic Soft Robot for Nonvisual Spatial Detection and Reconstruction, Advanced Intelligent Systems, 2025, 7: 2400601. SCIE. 第二标注"
  ],

  "期刊｜Advanced Sensor Research": [
    "Chengyang Gao; Shuyu Fan; Wei Li; Yongbing Wang; Qianwen Xia; Dibo Hou; Yunqi Cao; A high-performance miniaturized frequency shift detection system for QCM-based mass sensing, Advanced Sensor Research, 2024, 0(0): 2400148. SCIE. 第一标注"
  ],

  "期刊｜ACM Transactions on Knowledge Discovery from Data": [
    "(SCI Q1) Junjie Ou; Haiming Jin; Xiaocheng Wang; Hao Jiang; Xinbing Wang; Chenghu Zhou; STA-TCN: Spatial-Temporal Attention over Temporal Convolutional Network for Next Point-of-Interest Recommendation, ACM Transactions on Knowledge Discovery from Data, 2023, 17(9): 1-19. SCIE, EI. 第三标注"
  ],

  // =========================
  // 会议（按知名度/影响力降序）
  // =========================

  "会议｜IEEE CVPR": [
    "(CCF-A) Binhui Xie; Longhui Yuan; Shuang Li; Chi Harold Liu; Xinjing Cheng; Towards Fewer Annotations: Active Learning via Region Impurity and Prediction Uncertainty for Domain Adaptive Semantic Segmentation, IEEE CVPR 2022, New Orleans, USA, 2022-06-19 to 2022-06-24. 第一标注",
    "(CCF-A) Fangrui Lv; Jian Liang; Shuang Li; Bin Zang; Chi Harold Liu; Ziteng Wang; Di Liu; Causality Inspired Representation Learning for Domain Generalization, IEEE CVPR 2022, New Orleans, USA, 2022-06-19 to 2022-06-24. EI. 第一标注"
  ],

  "会议｜ACM SIGKDD": [
    "(CCF-A) Jiahui Sun; Haiming Jin; Zhaoxing Yang; Lu Su; Xinbing Wang; Optimizing Long-Term Efficiency and Fairness in Ride-Hailing via Joint Order Dispatching and Driver Repositioning, ACM SIGKDD 2022, Washington, DC, USA, 2022-08-14 to 2022-08-18. 第一标注",
    "(CCF-A) Zhangxing Yang; Haiming Jin; Guiyun Fan; Min Lu; Yiran Liu; Xinlang Yue; Hao Pan; Zhe Xu; Guobin Wu; Qun Li; Xiaotong Wang; Jiecheng Guo; Rethinking Order Dispatching in Online Ride-Hailing Platforms, ACM SIGKDD 2024, Barcelona, Spain, 2024-08-25 to 2024-08-29. EI. 第一标注"
  ],

  "会议｜ACM MobiCom": [
    "(CCF-A) Rong Ding; Haiming Jin; Ningzhi Zhu; Zijie Chen; Yi Fu; Fengyuan Zhu; Guiyun Fan; Xiaohua Tian; Linghe Kong; Bluetooth-Enabled Transparent RF Sensing, ACM MobiCom 2025, Hong Kong, China, 2025-11-04 to 2025-11-08. EI. 第一标注"
  ],

  "会议｜IEEE INFOCOM": [
    "(CCF-A) Guiyun Fan; Haiming Jin; Yiran Zhao; Yiwen Song; Xiaoying Gan; Jiaxin Ding; Lu Su; Xinbing Wang; Joint Order Dispatch and Charging for Electric Self-Driving Taxi Systems, IEEE INFOCOM 2022, Virtual Conference, 2022-05-02 to 2022-05-05. EI. 第一标注",
    "(CCF-A) Jiahui Sun; Haiming Jin; Rong Ding; Guiyun Fan; Yifei Wei; Lu Su; Multi-Objective Order Dispatch for Urban Crowd Sensing with For-Hire Vehicles, IEEE INFOCOM 2023, New York City, NY, USA, 2023-05-17 to 2023-05-20. EI. 第一标注",
    "(CCF-A) Guiyun Fan; Rong Ding; Xiaocheng Wang; Yichen Zhu; Haiming Jin; m3ASL: ASL Gesture Recognition with Moving mmWave Radar, IEEE INFOCOM 2025, London, United Kingdom, 2025-05-19 to 2025-05-22. EI. 第一标注",
    "(CCF-A) Jiaxi Lv; Guiyun Fan; Xinyue Fu; Jiahui Sun; Rong Ding; Haiming Jin; mmWave-Based Relay Reflector Reconstruction for LiDAR-Free Around-Corner Human Sensing, IEEE INFOCOM 2025, London, United Kingdom, 2025-05-19 to 2025-05-22. EI. 第一标注",
    "(CCF-A) Zhaoxing Yang; Guiyun Fan; Anjie Cao; Yuchen Guo; Wenlong Li; Tianyuan Liu; Haiming Jin; Learning to Accelerate Traffic Allocation over Large-Scale Networks, IEEE INFOCOM 2025, London, United Kingdom, 2025-05-19 to 2025-05-22. EI. 第一标注",
    "(CCF-A) Rong Ding; Haiming Jin; Dingman Shen; Rotation Speed Sensing with mmWave Radar, IEEE INFOCOM 2023, New York City, NY, USA, 2023-05-17 to 2023-05-20. EI. 第二标注"
  ],

  "会议｜AAAI": [
    "(CCF-A) Haoyi You; Beichen Yu; Haiming Jin; Zhaoxing Yang; Jiahui Sun; User-Oriented Robust Reinforcement Learning, AAAI 2023, Washington, DC, USA, 2023-02-07 to 2023-02-14. 第一标注",
    "(CCF-A) Zhaoxing Yang; Haiming Jin; Rong Ding; Haoyi You; Guiyun Fan; Xinbing Wang; Chenghu Zhou; DeCOM: Decomposed Policy for Constrained Cooperative Multi-Agent Reinforcement Learning, AAAI 2023, Washington, DC, USA, 2023-02-07 to 2023-02-14. EI. 第一标注"
  ],

  "会议｜IJCAI": [
    "(CCF-A) Yichen Zhu; Jian Yuan; Bo Jiang; Tao Lin; Haiming Jin; Xinbing Wang; Chenghu Zhou; Prediction with Incomplete Data under Agnostic Mask Distribution Shift, IJCAI 2023, Macao, S.A.R., 2023-08-19 to 2023-08-25. EI. 第三标注"
  ],

  "会议｜IEEE ICDE": [
    "(CCF-A) Yuxiao Ye; Chi Harold Liu; Zipeng Dai; Jianxin Zhao; Ye Yuan; Guoren Wang; Jian Tang; Exploring both Individuality and Cooperation for Air-Ground Spatial Crowdsourcing by Multi-Agent Deep Reinforcement Learning, IEEE ICDE 2023, Anaheim, CA, USA, 2023-04-03 to 2023-04-07. EI. 第一标注",
    "(CCF-A) Yu Wang; Jingfei Wu; Xingyuan Hua; Chi Harold Liu; Guozheng Li; Jianxin Zhao; Ye Yuan; Guoren Wang; Air-Ground Spatial Crowdsourcing with UAV Carriers by Geometric Graph Convolutional Multi-Agent Deep Reinforcement Learning, IEEE ICDE 2023, Anaheim, CA, USA, 2023-04-03 to 2023-04-07. EI. 第一标注"
  ],

  "会议｜IEEE ICDCS": [
    "Haiming Jin; Yifei Wei; Zhaoxing Yang; Zirui Liu; Guiyun Fan; Multi-Intersection Management for Connected Autonomous Vehicles by Reinforcement Learning, IEEE ICDCS 2023, Hong Kong, China, 2023-07-18 to 2023-07-21. EI. 第二标注"
  ],

  "会议｜ACM SenSys": [
    "Rong Ding; Haiming Jin; Jianrong Ding; Xiaocheng Wang; Guiyun Fan; Fengyuan Zhu; Xiaohua Tian; Linghe Kong; Push the Limit of Single-Chip mmWave Radar-Based Egomotion Estimation with Moving Objects in FoV, ACM SenSys 2023, Istanbul, Türkiye, 2023-11-13 to 2023-11-15. EI. 第一标注"
  ],

  "会议｜ACM MobiHoc": [
    "Jiahui Sun; Guiyun Fan; Haiming Jin; Yiwen Song; Tianyuan Liu; Chenhao Ying; Yuan Luo; Jie Li; Multi-Task-Oriented UAV Crowd Sensing with Charging Budget Constraint, ACM MobiHoc 2024, Athens, Greece, 2024-10-14 to 2024-10-17. EI. 第一标注"
  ],

  "会议｜AAMAS": [
    "Zhaoxing Yang; Haiming Jin; Yao Tang; Guiyun Fan; Risk-Aware Constrained Reinforcement Learning with Non-Stationary Policies, AAMAS 2024, Auckland, New Zealand, 2024-05-06 to 2024-05-10. EI. 第一标注"
  ],

  "会议｜Transducers": [
    "Mengyao Fu; Dongsheng Li; Chenyang Gao; Zhiqiang Ma; Dibo Hou; Yunqi Cao; MOF/PDMS Hybrid Nanofilm-Based QCM for VOC Selective Virtual Sensing in High-Humidity Environments, 2023 22nd International Conference on Solid-State Sensors, Actuators and Microsystems (Transducers), Kyoto, Japan, 2023-06-25 to 2023-06-29. EI. 第二标注"
  ],

  "会议｜IEEE IECON": [
    "Shuyu Fan; Haozhen Chi; Chenyang Gao; Wangdi Du; Dibo Hou; Yunqi Cao; A Brake Pair Misalignment Detection Scheme Based on a Battery-Free Electromagnetic-Based Gap Sensor, IEEE IECON 2023, Singapore, 2023-10-16 to 2023-10-19. EI. 第一标注",
    "Chenyang Gao; Mengyao Fu; Zhiqiang Ma; Shuyu Fan; Dibo Hou; Yunqi Cao; Metal-organic framework (MOF) based film bulk acoustic resonator (FBAR) sensor for volatile organic compounds (VOCs) detection, IEEE IECON 2024, Chicago, IL, USA, 2024-11-03 to 2024-11-06. EI. 第一标注"
  ],

  "会议｜CPCC": [
    "Shanqian Su; Minghao Ding; Ziying Zhu; Yushan Zhou; Shuyu Fan; Dibo Hou; Yunqi Cao; Microfluidic-Based Coplanar Capacitive Micro-Displacement Sensors with High Sensitivity and Large Measurement Range, CPCC 2025, Yibin, Sichuan, China, 2025-07-25 to 2025-07-27. EI. 第二标注",
    "Shuxun Wang; Haozhen Chi; Shuyu Fan; Yicheng Zhang; Yunqi Cao; Dibo Hou; IoT-Enabled Capacitive Sensing System for Real-Time Detection of Minor Leaks in Bolted Flange Connections, CPCC 2025, Yibin, Sichuan, China, 2025-07-25 to 2025-07-27. EI. 第二标注",
    "Yancheng Bi; Zhiqiang Ma; Zhen Zhou; Chenyang Gao; Xiaoyan Song; Dibo Hou; Yunqi Cao; A False Alarm-Free Dual-Wavelength Optical Smoke Detector for High-Humidity Underground Pipeline Galleries, CPCC 2025, Yibin, Sichuan, China, 2025-07-25 to 2025-07-27. EI. 第二标注"
  ],

  "会议｜CAC": [
    "Chenyang Gao; Shuyu Fan; Haozhen Chi; Yipei Yao; Dibo Hou; Yunqi Cao; A high-sensitivity frequency shift detector for QCM-based miniaturized sensing system, CAC 2024, Qingdao, China, 2024-11-01 to 2024-11-03. EI. 第二标注"
  ]
};


  const patents = [
  "孙嘉徽; 金海明; 范桂云, 无人机群智感知调度方法、系统、设备及介质，2022-6-1，中国,202211445408.0.",
  "金海明; 范桂云; 张永奎; 王孝诚, 一种基于智能小车和 IR-UWB 雷达的沙地浅埋垃圾检测方法及系统，2023-8-10，中国,202311008795.6.",
  "金海明; 丁榕; 范桂云; 沈定满, 一种基于 FMCW 毫米波雷达的旋转物体转速感知方法和系统，2023-5-15，中国,202310547197.X.",
  "金海明; 丁榕; 范桂云; 王孝诚; 张永奎, 一种土壤湿度感知方法、系统、设备及介质，2023-3-2，中国,202310202422.6.",
  "金海明; 丁榕; 范桂云; 王孝诚, 一种基于 FMCW 毫米波雷达和惯性测量单元的自位姿估计方法和系统，2023-11-7，中国,202311479645.3.",
  "金海明; 范桂云; 吕嘉溪, 基于毫米波雷达的中继反射面重建方法和系统，2024-12-27，中国,202411951313.5.",
  "余北辰；金海明；范桂云，基于非视距感知增强的移动机器人转角导航方法及系统，申请号：CN202511742901.2",
  "金海明；范桂云；丁榕，低功耗、全栈式、多功能无线射频感知系统及方法，申请号：CN202510298821.6",
  "叶语霄; 刘驰; 王昊, 一种保障元宇宙应用信息质量的无人群体感知方法，2023-8-2，中国, 202311056761.4.",
  "徐奕东; 韩锐; 刘驰, 一种面向深度学习模型的边缘端重训练内存配置优化方法，2023-10-26，中国, 202311396860.7.",
  "曹云琦; 傅梦瑶; 高晨阳等, 一种面向高湿度环境的基于石英晶体微天平的挥发性有机化合物传感器，2024-11-26，中国, CN116482187B.",
  "曹云琦; 马志强; 傅梦瑶等, 基于互补开口谐振环结构的挥发性有机物液体、气体传感器及其检测方法，2024-10-01，中国, CN117705828B.",
  "曹云琦; 高晨阳; 范舒羽; 池豪镇; 侯迪波, 一种基于锁相环的谐振器频移检测装置，2025-04-01，中国, CN118631246B.",
  "曹云琦; 姚一培; 范舒羽; 侯迪波; 张光新, 一种能源自持的集成化微型气象监测系统，2025-09-05，中国, CN118837974B.",
  "曹云琦; 傅梦瑶; 高晨阳等, 一种基于级联结构的物理虚拟混合式挥发性有机化合物传感阵列，申请号：202411558186.2"
];



  // ============================
  // Patent Groups（便于你手动按“授权/申请”分类填写）
  // ============================
  // 说明：
  // 1) 你可以直接在下方两个数组中分别填写“授权专利 / 申请专利”条目；
  // 2) 若两个数组都为空，将自动使用上方 patents[] 的历史数据并按规则拆分展示；
  // 3) 展示时会做轻量清洗与排序（按日期优先），如需保持手动顺序，可在 renderPatentGroups 中删除 sort。
  const patentGroups = {
    "授权专利": [
      "孙嘉徽; 金海明; 范桂云; 无人机群智感知调度方法、系统、设备及介质, 2025-08-22, 中国, ZL202211445408.0.",
      "金海明; 丁榕; 范桂云; 沈定满; 一种基于 FMCW 毫米波雷达的旋转物体转速感知方法和系统, 2025-08-19, 中国, ZL202310547197.X.",
      "金海明; 丁榕; 范桂云; 王孝诚; 张永奎; 一种土壤湿度感知方法、系统、设备及介质, 2025-08-19, 中国, ZL202310202422.6.",
      "曹云琦; 傅梦瑶; 高晨阳; 等; 一种面向高湿度环境的基于石英晶体微天平的挥发性有机化合物传感器, 2024-11-26, 中国, ZL202310204707.3.",
      "曹云琦; 马志强; 傅梦瑶; 等; 基于互补开口谐振环结构的挥发性有机物液体、气体传感器及其检测方法, 2024-10-01, 中国, ZL202311710893.4.",
      "曹云琦; 高晨阳; 范舒羽; 池豪镇; 侯迪波; 一种基于锁相环的谐振器频移检测装置, 2025-04-01, 中国, ZL202410794766.5.",
      "曹云琦; 姚一培; 范舒羽; 侯迪波; 张光新; 一种能源自持的集成化微型气象监测系统, 2025-09-05, 中国, ZL202410801077.2."
      // "发明人; 专利名称, 授权日期 YYYY-MM-DD, 国家/地区, 授权号 ZLXXXXXXXXXXXX.X."
    ],

    "申请专利": [
      "金海明; 范桂云; 张永奎; 王孝诚; 一种基于智能小车和 IR-UWB 雷达的沙地浅埋垃圾检测方法及系统, 2023-08-10, 中国, 202311008795.6.",
      "叶语霄; 刘驰; 王昊; 一种保障元宇宙应用信息质量的无人群体感知方法, 2023-08-02, 中国, 202311056761.4.",
      "金海明; 丁榕; 范桂云; 王孝诚; 一种基于 FMCW 毫米波雷达和惯性测量单元的自位姿估计方法和系统, 2023-11-07, 中国, 202311479645.3.",
      "徐奕东; 韩锐; 刘驰; 一种面向深度学习模型的边缘端重训练内存配置优化方法, 2023-10-26, 中国, 202311396860.7.",
      "曹云琦; 傅梦瑶; 高晨阳; 等; 一种基于级联结构的物理虚拟混合式挥发性有机化合物传感阵列, 2024-11-04, 中国, 202411558186.2.",
      "金海明; 范桂云; 吕嘉溪; 基于毫米波雷达的中继反射面重建方法和系统, 2024-12-27, 中国, 202411951313.5.",
      "金海明; 范桂云; 丁榕; 低功耗、全栈式、多功能无线射频感知系统及方法, 2025-03-13, 中国, 202510298821.6.",
      "余北辰; 金海明; 范桂云; 基于非视距感知增强的移动机器人转角导航方法及系统, 2025-11-25, 中国, 202511742901.2."
      // "发明人; 专利名称, 申请日期 YYYY-MM-DD, 国家/地区, 申请号 XXXXXXXXXXXXX.X."
    ]
  };



  // ============================
  // Helpers
  // ============================
  function normalize(str) {
    return (str || '').toLowerCase();
  }

  function escapeHtml(str) {
    return String(str)
      .replace(/&/g, "&amp;")
      .replace(/</g, "&lt;")
      .replace(/>/g, "&gt;")
      .replace(/"/g, "&quot;")
      .replace(/'/g, "&#39;");
  }

function formatPaperText(str) {
  let safe = escapeHtml(str);

  // 1) 先规范化写法，避免后续匹配遗漏
  safe = safe.replace(/\bCCF\s*[- ]\s*A\b/gi, "CCF-A");
  safe = safe.replace(/\bSCI\s*Q1\b/gi, "SCI Q1");

  const wrapStrong = (txt) =>
    `<strong class="font-extrabold text-bit-green">${txt}</strong>`;

  // 2) 将包含 (CCF-A)、(CCF-A, SCI Q1)、(SCI Q1) 等的括号整体加粗
  //    - 支持中英文括号
  //    - 括号内部允许任意文本，但只要包含 CCF-A 或 SCI Q1 就整体加粗
  safe = safe.replace(/([（(])\s*([^()（）]*?)\s*([)）])/g, (m, left, inner, right) => {
    if (!/\b(?:CCF-A|SCI Q1)\b/i.test(inner)) return m;

    // 可选：统一括号内逗号/空格的排版，让展示更规范
    const normalizedInner = inner
      .replace(/\s*[,，]\s*/g, ", ")
      .replace(/\s+/g, " ")
      .trim();

    return wrapStrong(`${left}${normalizedInner}${right}`);
  });

  // 3) （可选）括号外的 CCF-A / SCI Q1 也加粗
  //    为避免出现嵌套 <strong>，只处理不在 strong 块内的片段
  const parts = safe.split(/(<strong[^>]*>[\s\S]*?<\/strong>)/i);
  for (let i = 0; i < parts.length; i++) {
    if (/^<strong\b/i.test(parts[i])) continue;
    parts[i] = parts[i]
      .replace(/\bCCF-A\b/g, wrapStrong("CCF-A"))
      .replace(/\bSCI Q1\b/g, wrapStrong("SCI Q1"));
  }

  return parts.join("");
}


  function sumCounts(groupObj) {
    return Object.values(groupObj || {}).reduce((acc, arr) => acc + (arr ? arr.length : 0), 0);
  }

  function partitionPapers(groups) {
    const journals = {};
    const conferences = {};
    Object.keys(groups || {}).forEach(k => {
      const arr = groups[k] || [];
      if (k.startsWith("期刊｜")) {
        journals[k.replace(/^期刊｜/, "")] = arr;
      } else if (k.startsWith("会议｜")) {
        conferences[k.replace(/^会议｜/, "")] = arr;
      } else {
        journals[k] = arr;
      }
    });
    return { journals, conferences };
  }

  // Render logic optimized for Journal/Conference split
  
  // ----------------------------
  // Ordering rules (per review comments)
  // - Journals/Conferences: first show 第一标注, then 第二标注, then 第三标注
  // - When mark is equal: order by venue level (heuristic priority list) then by year (desc)
  // ----------------------------

  function getMarkRank(text) {
    const t = (text || '');
    if (/第\s*一\s*标\s*注/i.test(t)) return 0;
    if (/第\s*二\s*标\s*注/i.test(t)) return 1;
    if (/第\s*三\s*标\s*注/i.test(t)) return 2;
    return 3; // unknown / not specified
  }

  function getCcfRank(text) {
    const t = (text || '');
    if (/CCF\s*[- ]?\s*A/i.test(t)) return 0;
    if (/CCF\s*[- ]?\s*B/i.test(t)) return 1;
    if (/CCF\s*[- ]?\s*C/i.test(t)) return 2;
    return 3;
  }

  function getYear(text) {
    const t = (text || '');
    const m = t.match(/(19|20)\d{2}/g);
    if (!m || m.length === 0) return 0;
    const y = parseInt(m[m.length - 1], 10);
    return Number.isFinite(y) ? y : 0;
  }

  // Heuristic venue priority:
  // Note: your data are keyed by venue already; we avoid web lookups and keep rules deterministic.
  const JOURNAL_PRIORITY = [
    /Transactions\s+on\s+Pattern\s+Analysis\s+and\s+Machine\s+Intelligence|TPAMI/i,
    /Transactions\s+on\s+Image\s+Processing|TIP/i,
    /Transactions\s+on\s+Knowledge\s+and\s+Data\s+Engineering|TKDE/i,
    /Transactions\s+on\s+Mobile\s+Computing|TMC/i,
    /Journal\s+on\s+Selected\s+Areas\s+in\s+Communications|JSAC/i,
    /Transactions\s+on\s+Intelligent\s+Transportation\s+Systems|TITS/i,
    /Proceedings\s+of\s+the\s+ACM\s+on\s+Interactive,\s*Mobile,\s*Wearable\s+and\s+Ubiquitous\s+Technologies|IMWUT/i,
    /Transactions\s+on\s+Sensor\s+Networks|TOSN/i,
    /Transactions\s+on\s+Knowledge\s+Discovery\s+from\s+Data|TKDD/i,
    /ACM\s+Transactions\s+on\s+Knowledge\s+Discovery\s+from\s+Data/i,
    /IEEE\s+Transactions\s+on\s+Mobile\s+Computing/i,
    /Sensors\s+and\s+Actuators/i,
    /Measurement\s+Science\s+and\s+Technology/i,
    /Electron\s+Device\s+Letters|EDL/i,
    /ACS\s+Applied\s+Materials\s*&\s*Interfaces/i,
    /Advanced\s+Sensor\s+Research/i,
    /Internet\s+of\s+Things|IoT/i
  ];

  const CONF_PRIORITY = [
    /CVPR/i,
    /ICCV/i,
    /ECCV/i,
    /NeurIPS|NIPS/i,
    /ICML/i,
    /ICLR/i,
    /SIGKDD|KDD/i,
    /INFOCOM/i,
    /MobiCom/i,
    /ACM\s+MM|MM\b/i,
    /AAAI/i,
    /IJCAI/i,
    /ICDE/i,
    /ICDCS/i,
    /SenSys/i,
    /MobiHoc/i,
    /AAMAS/i,
    /IPSN/i,
    /Transducers/i,
    /IECON/i
  ];

  function getVenueRank(venue, isJournal) {
    const list = isJournal ? JOURNAL_PRIORITY : CONF_PRIORITY;
    for (let i = 0; i < list.length; i++) {
      if (list[i].test(venue)) return i;
    }
    return 999; // unknown venue goes later
  }

  function comparePaper(a, b, isJournal) {
    const ma = getMarkRank(a);
    const mb = getMarkRank(b);
    if (ma !== mb) return ma - mb;

    // Within same mark:
    // - Conferences: prefer higher CCF tier when available
    // - Journals: we do not have a reliable per-item tier field; use year desc then lexicographic
    if (!isJournal) {
      const ca = getCcfRank(a);
      const cb = getCcfRank(b);
      if (ca !== cb) return ca - cb;
    }

    const ya = getYear(a);
    const yb = getYear(b);
    if (ya !== yb) return yb - ya;

    return String(a).localeCompare(String(b), 'zh-Hans-CN', { sensitivity: 'base' });
  }

  // Render logic optimized for Journal/Conference split
  function renderPaperList(container, groups, query) {
    container.innerHTML = '';
    const q = normalize(query);
    const { journals, conferences } = partitionPapers(groups);

    // Helper to render a large section (e.g. "Journals")
    function renderSection(sectionTitle, bucket, colorClass, isJournal) {
        const venues = Object.keys(bucket).sort((a, b) => {
          const ra = getVenueRank(a, isJournal);
          const rb = getVenueRank(b, isJournal);
          if (ra !== rb) return ra - rb;
          return a.localeCompare(b, 'zh-Hans-CN', { sensitivity: 'base' });
        });

        let visibleCount = 0;

        // Wrapper for the whole section
        const sectionWrapper = document.createElement('div');
        sectionWrapper.className = "mb-8";

        // Section Title (e.g., "期刊")
        const titleEl = document.createElement('h3');
        titleEl.className = `text-lg font-bold text-gray-900 border-l-4 ${colorClass} pl-3 mb-4 uppercase tracking-wide`;
        titleEl.textContent = sectionTitle;
        sectionWrapper.appendChild(titleEl);

        let hasContent = false;

        venues.forEach(venue => {
            const all = (bucket[venue] || []);
            const items = all
              .filter(it => !q || normalize(it).includes(q))
              .slice()
              .sort((x, y) => comparePaper(x, y, isJournal));

            if (items.length === 0) return;
            hasContent = true;
            visibleCount += items.length;

            // Venue Group Wrapper
            const groupDiv = document.createElement('div');
            groupDiv.className = "mb-2";

            // Sticky Header for Venue (e.g., "INFOCOM")
            const vHeader = document.createElement('h4');
            vHeader.className = "sticky-venue-header text-sm font-bold text-gray-700 flex justify-between items-center cursor-default group";
            vHeader.innerHTML = `<span>${escapeHtml(venue)}</span>
                                 <span class="text-xs bg-gray-100 text-gray-500 py-0.5 px-2 rounded-full">${items.length}</span>`;
            groupDiv.appendChild(vHeader);

            // List Items
            const ol = document.createElement('ol');
            // Use native ordered-list markers for a more standard 1, 2, 3 numbering presentation
            ol.className = "list-decimal pl-6 space-y-3 mt-2 mb-6 marker:text-gray-400";

            items.forEach((it) => {
                const li = document.createElement('li');
                li.className = "text-sm text-gray-600 leading-relaxed border-b border-gray-50 pb-2 last:border-0 break-words";
                li.innerHTML = formatPaperText(it);
                ol.appendChild(li);
            });
groupDiv.appendChild(ol);
            sectionWrapper.appendChild(groupDiv);
        });

        if (hasContent) {
          container.appendChild(sectionWrapper);
        }
        return visibleCount;
    }

    const jCount = renderSection("期刊论文 (Journals)", journals, "border-bit-green", true);
    const cCount = renderSection("会议论文 (Conferences)", conferences, "border-blue-600", false);

    if (jCount + cCount === 0) {
        container.innerHTML = '<div class="text-center text-gray-400 py-10">未找到匹配的论文</div>';
    }
  }

  // Render logic for patent list (grant first, then application; unified tags)

  // Render logic for patent list (grant first, then application; unified tags)
  function parsePatent(raw) {
    const t = String(raw || '').trim();
    const compact = t.replace(/\s+/g, '');
    const hasStage = /实质审查阶段/.test(t);
    const isGranted = /\bCN\s*\d+\s*B\b/i.test(t) || /CN\d+B/i.test(compact) || /授权号|授权日期/.test(t);
    const status = isGranted ? 'granted' : 'pending';

    // Try parse a date for sorting (yyyy-mm-dd or yyyy.mm.dd)
    let dateScore = 0;
    const dm = t.match(/(19|20)\d{2}[-./](0?\d|1[0-2])[-./](0?\d|[12]\d|3[01])/);
    if (dm) {
      const s = dm[0].replace(/\./g, '-').replace(/\//g, '-');
      const parts = s.split('-').map(x => String(x).padStart(2, '0'));
      dateScore = parseInt(parts[0] + parts[1] + parts[2], 10);
    }

    // Normalize display text:
    let display = t
      .replace(/\[P\]/g, '')
      .replace(/（\s*实质审查阶段\s*）/g, '')
      .replace(/实质审查阶段/g, '')
      .replace(/\s+/g, ' ')
      .trim();

    return { raw: t, display, status, hasStage, dateScore };
  }

  
  function resolvePatentGroups() {
    const manualGranted = (patentGroups && Array.isArray(patentGroups["授权专利"])) ? patentGroups["授权专利"] : [];
    const manualPending = (patentGroups && Array.isArray(patentGroups["申请专利"])) ? patentGroups["申请专利"] : [];
    const hasManual = (manualGranted.length + manualPending.length) > 0;
    if (hasManual) return { "授权专利": manualGranted, "申请专利": manualPending };

    const granted = [];
    const pending = [];
    (patents || []).forEach((raw) => {
      const p = parsePatent(raw);
      (p.status === 'granted' ? granted : pending).push(p.raw);
    });
    return { "授权专利": granted, "申请专利": pending };
  }

  function renderPatentGroups(container, groups, query) {
    container.innerHTML = '';
    const q = normalize(query);

    const order = ["授权专利", "申请专利"];
    let hasAny = false;

    order.forEach((groupName) => {
      const rawItems = (groups && Array.isArray(groups[groupName])) ? groups[groupName] : [];
      const prepared = (rawItems || [])
        .map(parsePatent)
        .filter(p => !q || normalize(p.raw).includes(q))
        .sort((a, b) => (b.dateScore - a.dateScore) || a.display.localeCompare(b.display, 'zh-Hans-CN', { sensitivity: 'base' }));

      // 搜索状态下：该分组无匹配则隐藏
      if (q && prepared.length === 0) return;

      hasAny = true;

      const sectionWrapper = document.createElement('div');
      sectionWrapper.className = "mb-8";

      // Patent grouping title UI aligned with the paper list's "期刊论文 / 会议论文" section headers
      const colorClass = (groupName === "授权专利") ? "border-bit-green" : "border-blue-600";

      const titleEl = document.createElement('h3');
      titleEl.className = `text-lg font-bold text-gray-900 border-l-4 ${colorClass} pl-3 mb-4 uppercase tracking-wide flex justify-between items-center`;
      titleEl.innerHTML = `<span>${escapeHtml(groupName)}</span>
                           <span class="text-xs bg-gray-100 text-gray-500 py-0.5 px-2 rounded-full">${prepared.length}</span>`;
      sectionWrapper.appendChild(titleEl);

      // 非搜索状态下：空分组也展示一个“占位提示”，便于你直接往对应数组里填条目
      if (!q && prepared.length === 0) {
        const hint = document.createElement('div');
        hint.className = 'text-xs text-gray-400 py-4';
        hint.textContent = '（暂无条目：请在上方 patentGroups 中逐条添加）';
        sectionWrapper.appendChild(hint);
        container.appendChild(sectionWrapper);
        return;
      }

      if (prepared.length === 0) return;

      const ol = document.createElement('ol');
      ol.className = 'space-y-3 mt-2 mb-2';

      prepared.forEach((p, i) => {
        const li = document.createElement('li');
        li.className = 'text-sm text-gray-700 leading-relaxed border-b border-gray-100 pb-3 last:border-0 break-words flex gap-3';

        const idx = i + 1;

        // 不在条目中标注“已授权 / 申请中 / 实质审查”等状态信息，仅保留专利条目本身
        const cleaned = (p.display || '')
          .replace(/实质审查阶段/g, '')
          .replace(/实质审查/g, '')
          .replace(/申请中/g, '')
          .replace(/已授权/g, '')
          .replace(/\s+/g, ' ')
          .replace(/，\s*\)/g, '）')
          .replace(/\(\s*，/g, '(')
          .trim();

        li.innerHTML = `
          <span class="flex-shrink-0 w-6 h-6 rounded-full bg-blue-50 text-blue-700 border border-blue-200 text-xs flex items-center justify-center mt-0.5">${idx}</span>
          <div class="min-w-0">
            <div class="text-sm text-gray-700 leading-relaxed break-words">${escapeHtml(cleaned)}</div>
          </div>
        `;

        ol.appendChild(li);
      });

      sectionWrapper.appendChild(ol);
      container.appendChild(sectionWrapper);
    });

    if (!hasAny) {
      container.innerHTML = '<div class="text-center text-gray-400 py-10">未找到匹配的专利</div>';
    }
  }

function updateAcademicTotals() {
    const paperTotalEl = document.getElementById('paper-total');
    const patentTotalEl = document.getElementById('patent-total');
    if (paperTotalEl) paperTotalEl.textContent = sumCounts(paperGroups);

    const pg = resolvePatentGroups();
    if (patentTotalEl) patentTotalEl.textContent = sumCounts(pg);
  }


  // ============================
  // Boot
  // ============================
  document.addEventListener('DOMContentLoaded', function () {
    updateAcademicTotals();

    const paperContainer = document.getElementById('paper-list');
    const patentContainer = document.getElementById('patent-list');
    const paperSearch = document.getElementById('paper-search');
    const patentSearch = document.getElementById('patent-search');

    if (paperContainer) {
      renderPaperList(paperContainer, paperGroups, '');
      if (paperSearch) {
        paperSearch.addEventListener('input', (e) => {
          renderPaperList(paperContainer, paperGroups, e.target.value || '');
        });
      }
    }

    if (patentContainer) {
      const resolvedPatentGroups = resolvePatentGroups();
      renderPatentGroups(patentContainer, resolvedPatentGroups, '');
      if (patentSearch) {
        patentSearch.addEventListener('input', (e) => {
          renderPatentGroups(patentContainer, resolvedPatentGroups, e.target.value || '');
        });
      }
    }
  });
})();
</script>
  
    <script id="project-overview-figure-size">
(function () {
  function applyProjectOverviewFigureSize() {
    var card = document.getElementById("projectOverviewFigureCard");
    var img = document.getElementById("projectOverviewFigureImg");
    if (!card || !img) return;

    var maxW = Number(window.PROJECT_OVERVIEW_FIGURE_MAX_WIDTH_REM || 0);
    var maxH = Number(window.PROJECT_OVERVIEW_FIGURE_MAX_HEIGHT_PX || 0);

    if (maxW > 0) card.style.maxWidth = maxW + "rem";
    if (maxH > 0) img.style.maxHeight = maxH + "px";
  }

  document.addEventListener("DOMContentLoaded", applyProjectOverviewFigureSize);
})();
    </script>

    <script id="exchange-carousel-script">
(function () {
  var items = [
    { img: "site_assets/images/com_01.png", alt: "学术交流照片 1", text: "项目组成员金海明（左二）、丁榕（左一）参与MOBICOM 2025会议" },
    { img: "site_assets/images/com_02.png", alt: "学术交流照片 2", text: "项目组成员杨兆星参与KDD 2024会议" },
    { img: "site_assets/images/com_03.png", alt: "学术交流照片 3", text: "项目组成员金海明、丁榕、祝宁参与IPSN 2024会议" },
    { img: "site_assets/images/com_04.png", alt: "学术交流照片 4", text: "项目组成员金海明、丁榕参与SenSys 2023会议" },
    { img: "site_assets/images/com_05.png", alt: "学术交流照片 5", text: "项目组成员谢斌辉、吕芳蕊线上参与CVPR 2022会议" },
    { img: "site_assets/images/com_06.png", alt: "学术交流照片 6", text: "项目组成员叶语霄参与ICDE 2023会议" },
    { img: "site_assets/images/com_07.png", alt: "学术交流照片 7", text: "香港城市大学吴大鹏教授访问北京理工大学" }
  ];

  function $(id) { return document.getElementById(id); }

  var imgEl, textEl, counterEl, prevBtn, nextBtn;
  var idx = 0;

  function render() {
    if (!imgEl || !textEl || !counterEl) return;
    var it = items[idx];
    imgEl.src = it.img;
    imgEl.alt = it.alt;
    textEl.textContent = it.text;
    counterEl.textContent = (idx + 1) + " / " + items.length;
  }

  function prev() {
    idx = (idx - 1 + items.length) % items.length;
    render();
  }
  function next() {
    idx = (idx + 1) % items.length;
    render();
  }

  document.addEventListener("DOMContentLoaded", function () {
    imgEl = $("exchangeImage");
    textEl = $("exchangeText");
    counterEl = $("exchangeCounter");
    prevBtn = $("exchangePrev");
    nextBtn = $("exchangeNext");

    if (!imgEl || !textEl || !counterEl || !prevBtn || !nextBtn) return;

    prevBtn.addEventListener("click", prev);
    nextBtn.addEventListener("click", next);

    // Keyboard support
    document.addEventListener("keydown", function (e) {
      if (e.key === "ArrowLeft") prev();
      if (e.key === "ArrowRight") next();
    });

    render();
  });
})();
    </script>

    <script id="talent-ui-script">
(function () {
  function byId(id) { return document.getElementById(id); }

  function setup(prefix) {
    var totalEl = byId("talent-" + prefix + "-total");
    var searchEl = byId("talent-" + prefix + "-search");
    var listWrap = byId("talent-" + prefix + "-list");
    if (!totalEl || !searchEl || !listWrap) return;

    var items = Array.prototype.slice.call(listWrap.querySelectorAll("li"));
    totalEl.textContent = String(items.length);

    function applyFilter() {
      var q = (searchEl.value || "").trim().toLowerCase();
      items.forEach(function (li) {
        var t = (li.textContent || "").toLowerCase();
        li.style.display = (!q || t.indexOf(q) !== -1) ? "" : "none";
      });
    }

    searchEl.addEventListener("input", applyFilter);
  }

  document.addEventListener("DOMContentLoaded", function () {
    setup("postdoc");
    setup("phd");
    setup("master");
  });
})();
    </script>

</body>
</html>